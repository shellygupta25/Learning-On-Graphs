{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8f6506e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 14:58:52.385285: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-22 14:58:52.387185: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-22 14:58:52.427298: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-22 14:58:52.428200: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-22 14:58:53.277962: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from stellargraph import StellarGraph\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import warnings\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import time\n",
    "import pickle\n",
    "from stellargraph.data import UniformRandomMetaPathWalk\n",
    "from gensim.models import Word2Vec\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a034df",
   "metadata": {},
   "source": [
    "# Final code from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e60c77d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user set params\n",
    "dir_path = \"WSJ split data files\"\n",
    "dbname = \"WSJ\"\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4187738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = train_df[\"src\"].append(train_df[\"dest\"]).unique()\n",
    "len(all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85931fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = pd.Series(list(all_nodes))\n",
    "nodes_entity = all_nodes[all_nodes.between(5000, 99999)].unique()\n",
    "nodes_users = all_nodes[all_nodes>=100000].unique()\n",
    "nodes_events = all_nodes[all_nodes<5000].unique()\n",
    "nodes_entity = pd.DataFrame(index=list(nodes_entity))\n",
    "nodes_users = pd.DataFrame(index=list(nodes_users))\n",
    "nodes_events = pd.DataFrame(index=list(nodes_events))\n",
    "pickle.dump(nodes_entity,open(\"nodes_entity.pickle\",\"wb\"))\n",
    "pickle.dump(nodes_events,open(\"nodes_events.pickle\",\"wb\"))\n",
    "pickle.dump(nodes_users,open(\"nodes_users.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bade5186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#other params \n",
    "dimensions = 64\n",
    "num_walks = 1\n",
    "walk_length = 100\n",
    "context_window_size = 10\n",
    "num_iter = 1\n",
    "workers = multiprocessing.cpu_count()\n",
    "user_metapaths = [\n",
    "    #entity metapaths\n",
    "    [\"entity\",\"entity\"],\n",
    "    [\"entity\", \"events\", \"entity\"],\n",
    "    [\"entity\", \"events\", \"entity\", \"entity\"],\n",
    "    [\"entity\", \"events\", \"events\", \"entity\"],\n",
    "    [\"entity\", \"user\", \"entity\"],\n",
    "    [\"entity\", \"user\", \"entity\", \"entity\"],\n",
    "    [\"entity\", \"user\", \"user\", \"entity\"],\n",
    "    [\"entity\", \"user\", \"events\", \"entity\"],\n",
    "    [\"entity\", \"events\", \"user\", \"entity\"],\n",
    "    [\"entity\", \"user\", \"events\", \"entity\", \"entity\"],\n",
    "    [\"entity\", \"events\", \"user\", \"entity\", \"entity\"],\n",
    "    #events metapath\n",
    "    [\"events\", \"events\"],\n",
    "    [\"events\", \"entity\", \"events\"],\n",
    "    [\"events\", \"entity\", \"events\", \"events\"],\n",
    "    [\"events\", \"entity\", \"entity\", \"events\"],\n",
    "    [\"events\", \"user\", \"events\"],\n",
    "    [\"events\", \"user\", \"events\", \"events\"],\n",
    "    [\"events\", \"user\", \"user\", \"events\"],\n",
    "    [\"events\", \"entity\", \"user\", \"events\"],\n",
    "    [\"events\", \"user\", \"entity\", \"events\"],\n",
    "    [\"events\", \"entity\", \"user\", \"events\", \"events\"],\n",
    "    [\"events\", \"user\", \"entity\", \"events\", \"events\"],\n",
    "    #user metapath\n",
    "    [\"user\", \"user\"],\n",
    "    [\"user\", \"events\", \"user\"],\n",
    "    [\"user\", \"events\", \"user\", \"user\"],\n",
    "    [\"user\", \"events\", \"events\", \"user\"],\n",
    "    [\"user\", \"entity\", \"user\"],\n",
    "    [\"user\", \"entity\", \"user\", \"user\"],\n",
    "    [\"user\", \"entity\", \"entity\", \"user\"],\n",
    "    [\"user\", \"entity\", \"events\", \"user\"],\n",
    "    [\"user\", \"events\", \"entity\", \"user\"],\n",
    "    [\"user\", \"entity\", \"events\", \"user\", \"user\"],\n",
    "    [\"user\", \"events\", \"entity\", \"user\", \"user\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd849135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " Test file no :  1\n",
      "Graph ready\n",
      "Number of random walks for 'Train Graph': 93896\n",
      "time taken for training walks :  859.9173460006714\n",
      "time taken for training word2vec :  19.719265699386597\n",
      "time taken for getting node embeddings :  3.814697265625e-06\n",
      "x_train and x_test are ready\n",
      "Epoch 1/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.4050 - accuracy: 0.8286 - val_loss: 0.3852 - val_accuracy: 0.8365\n",
      "Epoch 2/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3764 - accuracy: 0.8429 - val_loss: 0.3721 - val_accuracy: 0.8459\n",
      "Epoch 3/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3696 - accuracy: 0.8457 - val_loss: 0.3693 - val_accuracy: 0.8456\n",
      "Epoch 4/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3659 - accuracy: 0.8479 - val_loss: 0.3655 - val_accuracy: 0.8490\n",
      "Epoch 5/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3639 - accuracy: 0.8487 - val_loss: 0.3665 - val_accuracy: 0.8486\n",
      "Epoch 6/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3626 - accuracy: 0.8493 - val_loss: 0.3686 - val_accuracy: 0.8448\n",
      "Epoch 7/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3614 - accuracy: 0.8499 - val_loss: 0.3627 - val_accuracy: 0.8515\n",
      "Epoch 8/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3599 - accuracy: 0.8506 - val_loss: 0.3625 - val_accuracy: 0.8486\n",
      "Epoch 9/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3588 - accuracy: 0.8511 - val_loss: 0.3627 - val_accuracy: 0.8489\n",
      "Epoch 10/100\n",
      "64092/64092 [==============================] - 176s 3ms/step - loss: 0.3578 - accuracy: 0.8516 - val_loss: 0.3599 - val_accuracy: 0.8516\n",
      "Epoch 11/100\n",
      "64092/64092 [==============================] - 154s 2ms/step - loss: 0.3569 - accuracy: 0.8523 - val_loss: 0.3595 - val_accuracy: 0.8521\n",
      "Epoch 12/100\n",
      "64092/64092 [==============================] - 152s 2ms/step - loss: 0.3562 - accuracy: 0.8525 - val_loss: 0.3587 - val_accuracy: 0.8506\n",
      "Epoch 13/100\n",
      "64092/64092 [==============================] - 144s 2ms/step - loss: 0.3556 - accuracy: 0.8529 - val_loss: 0.3592 - val_accuracy: 0.8524\n",
      "Epoch 14/100\n",
      "64092/64092 [==============================] - 128s 2ms/step - loss: 0.3552 - accuracy: 0.8531 - val_loss: 0.3559 - val_accuracy: 0.8524\n",
      "Epoch 15/100\n",
      "64092/64092 [==============================] - 128s 2ms/step - loss: 0.3547 - accuracy: 0.8532 - val_loss: 0.3611 - val_accuracy: 0.8484\n",
      "Epoch 16/100\n",
      "64092/64092 [==============================] - 128s 2ms/step - loss: 0.3543 - accuracy: 0.8534 - val_loss: 0.3627 - val_accuracy: 0.8470\n",
      "Epoch 17/100\n",
      "64092/64092 [==============================] - 129s 2ms/step - loss: 0.3540 - accuracy: 0.8535 - val_loss: 0.3561 - val_accuracy: 0.8519\n",
      "Epoch 18/100\n",
      "64092/64092 [==============================] - 130s 2ms/step - loss: 0.3536 - accuracy: 0.8538 - val_loss: 0.3558 - val_accuracy: 0.8518\n",
      "Epoch 19/100\n",
      "64092/64092 [==============================] - 130s 2ms/step - loss: 0.3534 - accuracy: 0.8538 - val_loss: 0.3586 - val_accuracy: 0.8494\n",
      "Epoch 20/100\n",
      "64092/64092 [==============================] - 131s 2ms/step - loss: 0.3533 - accuracy: 0.8538 - val_loss: 0.3551 - val_accuracy: 0.8526\n",
      "Epoch 21/100\n",
      "64092/64092 [==============================] - 130s 2ms/step - loss: 0.3530 - accuracy: 0.8539 - val_loss: 0.3562 - val_accuracy: 0.8525\n",
      "Epoch 22/100\n",
      "64092/64092 [==============================] - 131s 2ms/step - loss: 0.3528 - accuracy: 0.8540 - val_loss: 0.3588 - val_accuracy: 0.8499\n",
      "Epoch 23/100\n",
      "64092/64092 [==============================] - 149s 2ms/step - loss: 0.3527 - accuracy: 0.8539 - val_loss: 0.3555 - val_accuracy: 0.8530\n",
      "Epoch 24/100\n",
      "64092/64092 [==============================] - 150s 2ms/step - loss: 0.3525 - accuracy: 0.8541 - val_loss: 0.3557 - val_accuracy: 0.8524\n",
      "Epoch 25/100\n",
      "64092/64092 [==============================] - 150s 2ms/step - loss: 0.3524 - accuracy: 0.8540 - val_loss: 0.3594 - val_accuracy: 0.8529\n",
      "Epoch 26/100\n",
      "64092/64092 [==============================] - 165s 3ms/step - loss: 0.3523 - accuracy: 0.8542 - val_loss: 0.3546 - val_accuracy: 0.8532\n",
      "Epoch 27/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3521 - accuracy: 0.8542 - val_loss: 0.3571 - val_accuracy: 0.8523\n",
      "Epoch 28/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3520 - accuracy: 0.8542 - val_loss: 0.3560 - val_accuracy: 0.8529\n",
      "Epoch 29/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3519 - accuracy: 0.8544 - val_loss: 0.3559 - val_accuracy: 0.8518\n",
      "Epoch 30/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3517 - accuracy: 0.8544 - val_loss: 0.3558 - val_accuracy: 0.8530\n",
      "Epoch 31/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3515 - accuracy: 0.8546 - val_loss: 0.3558 - val_accuracy: 0.8538\n",
      "Epoch 32/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3515 - accuracy: 0.8544 - val_loss: 0.3576 - val_accuracy: 0.8518\n",
      "Epoch 33/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3514 - accuracy: 0.8546 - val_loss: 0.3549 - val_accuracy: 0.8524\n",
      "Epoch 34/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3513 - accuracy: 0.8546 - val_loss: 0.3554 - val_accuracy: 0.8531\n",
      "Epoch 35/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3511 - accuracy: 0.8545 - val_loss: 0.3534 - val_accuracy: 0.8537\n",
      "Epoch 36/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3510 - accuracy: 0.8547 - val_loss: 0.3564 - val_accuracy: 0.8536\n",
      "Epoch 37/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3509 - accuracy: 0.8548 - val_loss: 0.3544 - val_accuracy: 0.8522\n",
      "Epoch 38/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3509 - accuracy: 0.8547 - val_loss: 0.3549 - val_accuracy: 0.8524\n",
      "Epoch 39/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3509 - accuracy: 0.8546 - val_loss: 0.3534 - val_accuracy: 0.8534\n",
      "Epoch 40/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3507 - accuracy: 0.8550 - val_loss: 0.3552 - val_accuracy: 0.8523\n",
      "Epoch 41/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3507 - accuracy: 0.8547 - val_loss: 0.3555 - val_accuracy: 0.8538\n",
      "Epoch 42/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3507 - accuracy: 0.8549 - val_loss: 0.3530 - val_accuracy: 0.8541\n",
      "Epoch 43/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3506 - accuracy: 0.8548 - val_loss: 0.3551 - val_accuracy: 0.8521\n",
      "Epoch 44/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3504 - accuracy: 0.8551 - val_loss: 0.3537 - val_accuracy: 0.8531\n",
      "Epoch 45/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3504 - accuracy: 0.8550 - val_loss: 0.3558 - val_accuracy: 0.8517\n",
      "Epoch 46/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3504 - accuracy: 0.8550 - val_loss: 0.3569 - val_accuracy: 0.8513\n",
      "Epoch 47/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3504 - accuracy: 0.8550 - val_loss: 0.3558 - val_accuracy: 0.8528\n",
      "Epoch 48/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3504 - accuracy: 0.8550 - val_loss: 0.3585 - val_accuracy: 0.8515\n",
      "Epoch 49/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3503 - accuracy: 0.8550 - val_loss: 0.3561 - val_accuracy: 0.8526\n",
      "Epoch 50/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3503 - accuracy: 0.8549 - val_loss: 0.3544 - val_accuracy: 0.8534\n",
      "Epoch 51/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3502 - accuracy: 0.8550 - val_loss: 0.3544 - val_accuracy: 0.8542\n",
      "Epoch 52/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3502 - accuracy: 0.8550 - val_loss: 0.3545 - val_accuracy: 0.8532\n",
      "Epoch 53/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3501 - accuracy: 0.8550 - val_loss: 0.3541 - val_accuracy: 0.8538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3501 - accuracy: 0.8552 - val_loss: 0.3590 - val_accuracy: 0.8511\n",
      "Epoch 55/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3500 - accuracy: 0.8551 - val_loss: 0.3554 - val_accuracy: 0.8527\n",
      "Epoch 56/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3499 - accuracy: 0.8553 - val_loss: 0.3589 - val_accuracy: 0.8522\n",
      "Epoch 57/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3500 - accuracy: 0.8553 - val_loss: 0.3567 - val_accuracy: 0.8530\n",
      "Epoch 58/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3500 - accuracy: 0.8553 - val_loss: 0.3531 - val_accuracy: 0.8537\n",
      "Epoch 59/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3499 - accuracy: 0.8552 - val_loss: 0.3558 - val_accuracy: 0.8511\n",
      "Epoch 60/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3499 - accuracy: 0.8550 - val_loss: 0.3539 - val_accuracy: 0.8543\n",
      "Epoch 61/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3498 - accuracy: 0.8552 - val_loss: 0.3572 - val_accuracy: 0.8517\n",
      "Epoch 62/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3498 - accuracy: 0.8552 - val_loss: 0.3547 - val_accuracy: 0.8533\n",
      "Epoch 63/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3498 - accuracy: 0.8552 - val_loss: 0.3539 - val_accuracy: 0.8534\n",
      "Epoch 64/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3497 - accuracy: 0.8552 - val_loss: 0.3539 - val_accuracy: 0.8527\n",
      "Epoch 65/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3497 - accuracy: 0.8552 - val_loss: 0.3545 - val_accuracy: 0.8523\n",
      "Epoch 66/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3497 - accuracy: 0.8552 - val_loss: 0.3554 - val_accuracy: 0.8536\n",
      "Epoch 67/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3497 - accuracy: 0.8551 - val_loss: 0.3572 - val_accuracy: 0.8515\n",
      "Epoch 68/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3498 - accuracy: 0.8552 - val_loss: 0.3551 - val_accuracy: 0.8524\n",
      "Epoch 69/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3497 - accuracy: 0.8553 - val_loss: 0.3545 - val_accuracy: 0.8541\n",
      "Epoch 70/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3496 - accuracy: 0.8553 - val_loss: 0.3536 - val_accuracy: 0.8533\n",
      "Epoch 71/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3496 - accuracy: 0.8554 - val_loss: 0.3531 - val_accuracy: 0.8542\n",
      "Epoch 72/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3496 - accuracy: 0.8552 - val_loss: 0.3559 - val_accuracy: 0.8523\n",
      "Epoch 73/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3495 - accuracy: 0.8552 - val_loss: 0.3538 - val_accuracy: 0.8547\n",
      "Epoch 74/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3496 - accuracy: 0.8553 - val_loss: 0.3535 - val_accuracy: 0.8543\n",
      "Epoch 75/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3494 - accuracy: 0.8554 - val_loss: 0.3532 - val_accuracy: 0.8542\n",
      "Epoch 76/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3496 - accuracy: 0.8551 - val_loss: 0.3563 - val_accuracy: 0.8518\n",
      "Epoch 77/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3495 - accuracy: 0.8553 - val_loss: 0.3575 - val_accuracy: 0.8518\n",
      "Epoch 78/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3494 - accuracy: 0.8554 - val_loss: 0.3549 - val_accuracy: 0.8521\n",
      "Epoch 79/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3494 - accuracy: 0.8554 - val_loss: 0.3546 - val_accuracy: 0.8541\n",
      "Epoch 80/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3495 - accuracy: 0.8553 - val_loss: 0.3560 - val_accuracy: 0.8533\n",
      "Epoch 81/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3493 - accuracy: 0.8550 - val_loss: 0.3546 - val_accuracy: 0.8531\n",
      "Epoch 82/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3495 - accuracy: 0.8552 - val_loss: 0.3532 - val_accuracy: 0.8540\n",
      "Epoch 83/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3493 - accuracy: 0.8555 - val_loss: 0.3548 - val_accuracy: 0.8532\n",
      "Epoch 84/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3493 - accuracy: 0.8556 - val_loss: 0.3564 - val_accuracy: 0.8517\n",
      "Epoch 85/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3493 - accuracy: 0.8554 - val_loss: 0.3540 - val_accuracy: 0.8539\n",
      "Epoch 86/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3493 - accuracy: 0.8553 - val_loss: 0.3546 - val_accuracy: 0.8539\n",
      "Epoch 87/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3494 - accuracy: 0.8553 - val_loss: 0.3531 - val_accuracy: 0.8543\n",
      "Epoch 88/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3492 - accuracy: 0.8554 - val_loss: 0.3536 - val_accuracy: 0.8543\n",
      "Epoch 89/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3492 - accuracy: 0.8551 - val_loss: 0.3561 - val_accuracy: 0.8528\n",
      "Epoch 90/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3493 - accuracy: 0.8554 - val_loss: 0.3539 - val_accuracy: 0.8543\n",
      "Epoch 91/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3492 - accuracy: 0.8555 - val_loss: 0.3592 - val_accuracy: 0.8492\n",
      "Epoch 92/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3492 - accuracy: 0.8555 - val_loss: 0.3535 - val_accuracy: 0.8535\n",
      "Epoch 93/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3492 - accuracy: 0.8554 - val_loss: 0.3547 - val_accuracy: 0.8543\n",
      "Epoch 94/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3492 - accuracy: 0.8556 - val_loss: 0.3558 - val_accuracy: 0.8525\n",
      "Epoch 95/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3493 - accuracy: 0.8554 - val_loss: 0.3535 - val_accuracy: 0.8543\n",
      "Epoch 96/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3492 - accuracy: 0.8555 - val_loss: 0.3565 - val_accuracy: 0.8542\n",
      "Epoch 97/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3491 - accuracy: 0.8554 - val_loss: 0.3524 - val_accuracy: 0.8547\n",
      "Epoch 98/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3492 - accuracy: 0.8553 - val_loss: 0.3520 - val_accuracy: 0.8547\n",
      "Epoch 99/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3491 - accuracy: 0.8554 - val_loss: 0.3570 - val_accuracy: 0.8522\n",
      "Epoch 100/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3491 - accuracy: 0.8557 - val_loss: 0.3532 - val_accuracy: 0.8546\n",
      "time taken for training :  17584.974200487137\n",
      "time taken for per epoch :  175.84974200487136\n",
      "\n",
      "\n",
      "\n",
      " Test file no :  2\n",
      "Graph ready\n",
      "Number of random walks for 'Train Graph': 93896\n",
      "time taken for training walks :  1203.7500460147858\n",
      "time taken for training word2vec :  20.94305419921875\n",
      "time taken for getting node embeddings :  0.001506805419921875\n",
      "x_train and x_test are ready\n",
      "Epoch 1/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.4087 - accuracy: 0.8255 - val_loss: 0.3905 - val_accuracy: 0.8355\n",
      "Epoch 2/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3820 - accuracy: 0.8391 - val_loss: 0.3792 - val_accuracy: 0.8412\n",
      "Epoch 3/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3748 - accuracy: 0.8426 - val_loss: 0.3737 - val_accuracy: 0.8432\n",
      "Epoch 4/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3715 - accuracy: 0.8439 - val_loss: 0.3771 - val_accuracy: 0.8434\n",
      "Epoch 5/100\n",
      "64092/64092 [==============================] - 180s 3ms/step - loss: 0.3698 - accuracy: 0.8448 - val_loss: 0.3755 - val_accuracy: 0.8421\n",
      "Epoch 6/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3686 - accuracy: 0.8454 - val_loss: 0.3713 - val_accuracy: 0.8446\n",
      "Epoch 7/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3678 - accuracy: 0.8460 - val_loss: 0.3688 - val_accuracy: 0.8454\n",
      "Epoch 8/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3669 - accuracy: 0.8460 - val_loss: 0.3696 - val_accuracy: 0.8452\n",
      "Epoch 9/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3663 - accuracy: 0.8462 - val_loss: 0.3733 - val_accuracy: 0.8430\n",
      "Epoch 10/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3658 - accuracy: 0.8466 - val_loss: 0.3665 - val_accuracy: 0.8467\n",
      "Epoch 11/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3653 - accuracy: 0.8469 - val_loss: 0.3723 - val_accuracy: 0.8440\n",
      "Epoch 12/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3650 - accuracy: 0.8474 - val_loss: 0.3690 - val_accuracy: 0.8442\n",
      "Epoch 13/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3646 - accuracy: 0.8472 - val_loss: 0.3693 - val_accuracy: 0.8456\n",
      "Epoch 14/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3644 - accuracy: 0.8474 - val_loss: 0.3657 - val_accuracy: 0.8482\n",
      "Epoch 15/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3640 - accuracy: 0.8475 - val_loss: 0.3664 - val_accuracy: 0.8466\n",
      "Epoch 16/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3637 - accuracy: 0.8475 - val_loss: 0.3695 - val_accuracy: 0.8462\n",
      "Epoch 17/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3632 - accuracy: 0.8481 - val_loss: 0.3680 - val_accuracy: 0.8451\n",
      "Epoch 18/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3630 - accuracy: 0.8480 - val_loss: 0.3670 - val_accuracy: 0.8452\n",
      "Epoch 19/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3627 - accuracy: 0.8482 - val_loss: 0.3656 - val_accuracy: 0.8454\n",
      "Epoch 20/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3626 - accuracy: 0.8483 - val_loss: 0.3694 - val_accuracy: 0.8468\n",
      "Epoch 21/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3622 - accuracy: 0.8483 - val_loss: 0.3667 - val_accuracy: 0.8450\n",
      "Epoch 22/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3619 - accuracy: 0.8486 - val_loss: 0.3676 - val_accuracy: 0.8456\n",
      "Epoch 23/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3617 - accuracy: 0.8486 - val_loss: 0.3644 - val_accuracy: 0.8480\n",
      "Epoch 24/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3616 - accuracy: 0.8487 - val_loss: 0.3647 - val_accuracy: 0.8468\n",
      "Epoch 25/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3616 - accuracy: 0.8488 - val_loss: 0.3660 - val_accuracy: 0.8461\n",
      "Epoch 26/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3613 - accuracy: 0.8485 - val_loss: 0.3653 - val_accuracy: 0.8485\n",
      "Epoch 27/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3613 - accuracy: 0.8488 - val_loss: 0.3651 - val_accuracy: 0.8467\n",
      "Epoch 28/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3612 - accuracy: 0.8489 - val_loss: 0.3656 - val_accuracy: 0.8451\n",
      "Epoch 29/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3610 - accuracy: 0.8490 - val_loss: 0.3638 - val_accuracy: 0.8485\n",
      "Epoch 30/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3609 - accuracy: 0.8489 - val_loss: 0.3656 - val_accuracy: 0.8469\n",
      "Epoch 31/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3609 - accuracy: 0.8493 - val_loss: 0.3641 - val_accuracy: 0.8487\n",
      "Epoch 32/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3609 - accuracy: 0.8492 - val_loss: 0.3666 - val_accuracy: 0.8469\n",
      "Epoch 33/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3607 - accuracy: 0.8491 - val_loss: 0.3636 - val_accuracy: 0.8481\n",
      "Epoch 34/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3607 - accuracy: 0.8491 - val_loss: 0.3655 - val_accuracy: 0.8461\n",
      "Epoch 35/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3606 - accuracy: 0.8492 - val_loss: 0.3658 - val_accuracy: 0.8472\n",
      "Epoch 36/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3605 - accuracy: 0.8493 - val_loss: 0.3626 - val_accuracy: 0.8481\n",
      "Epoch 37/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3604 - accuracy: 0.8493 - val_loss: 0.3627 - val_accuracy: 0.8484\n",
      "Epoch 38/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3603 - accuracy: 0.8492 - val_loss: 0.3625 - val_accuracy: 0.8483\n",
      "Epoch 39/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3604 - accuracy: 0.8495 - val_loss: 0.3627 - val_accuracy: 0.8480\n",
      "Epoch 40/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3602 - accuracy: 0.8495 - val_loss: 0.3661 - val_accuracy: 0.8470\n",
      "Epoch 41/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3602 - accuracy: 0.8493 - val_loss: 0.3633 - val_accuracy: 0.8475\n",
      "Epoch 42/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3602 - accuracy: 0.8496 - val_loss: 0.3622 - val_accuracy: 0.8480\n",
      "Epoch 43/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3601 - accuracy: 0.8495 - val_loss: 0.3639 - val_accuracy: 0.8467\n",
      "Epoch 44/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3600 - accuracy: 0.8495 - val_loss: 0.3649 - val_accuracy: 0.8474\n",
      "Epoch 45/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3599 - accuracy: 0.8496 - val_loss: 0.3636 - val_accuracy: 0.8480\n",
      "Epoch 46/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3599 - accuracy: 0.8497 - val_loss: 0.3627 - val_accuracy: 0.8477\n",
      "Epoch 47/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3599 - accuracy: 0.8496 - val_loss: 0.3631 - val_accuracy: 0.8479\n",
      "Epoch 48/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3599 - accuracy: 0.8498 - val_loss: 0.3628 - val_accuracy: 0.8475\n",
      "Epoch 49/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3596 - accuracy: 0.8498 - val_loss: 0.3642 - val_accuracy: 0.8479\n",
      "Epoch 50/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3596 - accuracy: 0.8498 - val_loss: 0.3644 - val_accuracy: 0.8463\n",
      "Epoch 51/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3596 - accuracy: 0.8498 - val_loss: 0.3627 - val_accuracy: 0.8469\n",
      "Epoch 52/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3597 - accuracy: 0.8499 - val_loss: 0.3640 - val_accuracy: 0.8467\n",
      "Epoch 53/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3595 - accuracy: 0.8499 - val_loss: 0.3639 - val_accuracy: 0.8470\n",
      "Epoch 54/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3595 - accuracy: 0.8499 - val_loss: 0.3628 - val_accuracy: 0.8487\n",
      "Epoch 55/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3594 - accuracy: 0.8500 - val_loss: 0.3624 - val_accuracy: 0.8478\n",
      "Epoch 56/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3595 - accuracy: 0.8497 - val_loss: 0.3675 - val_accuracy: 0.8467\n",
      "Epoch 57/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3594 - accuracy: 0.8500 - val_loss: 0.3623 - val_accuracy: 0.8485\n",
      "Epoch 58/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3593 - accuracy: 0.8498 - val_loss: 0.3640 - val_accuracy: 0.8473\n",
      "Epoch 59/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3593 - accuracy: 0.8499 - val_loss: 0.3646 - val_accuracy: 0.8490\n",
      "Epoch 60/100\n",
      "64092/64092 [==============================] - 181s 3ms/step - loss: 0.3592 - accuracy: 0.8499 - val_loss: 0.3649 - val_accuracy: 0.8469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "64092/64092 [==============================] - 180s 3ms/step - loss: 0.3591 - accuracy: 0.8502 - val_loss: 0.3630 - val_accuracy: 0.8480\n",
      "Epoch 62/100\n",
      "64092/64092 [==============================] - 179s 3ms/step - loss: 0.3593 - accuracy: 0.8500 - val_loss: 0.3619 - val_accuracy: 0.8490\n",
      "Epoch 63/100\n",
      "64092/64092 [==============================] - 178s 3ms/step - loss: 0.3592 - accuracy: 0.8500 - val_loss: 0.3646 - val_accuracy: 0.8489\n",
      "Epoch 64/100\n",
      "64092/64092 [==============================] - 179s 3ms/step - loss: 0.3591 - accuracy: 0.8498 - val_loss: 0.3642 - val_accuracy: 0.8483\n",
      "Epoch 65/100\n",
      "64092/64092 [==============================] - 179s 3ms/step - loss: 0.3591 - accuracy: 0.8498 - val_loss: 0.3627 - val_accuracy: 0.8481\n",
      "Epoch 66/100\n",
      "64092/64092 [==============================] - 181s 3ms/step - loss: 0.3591 - accuracy: 0.8501 - val_loss: 0.3647 - val_accuracy: 0.8465\n",
      "Epoch 67/100\n",
      "64092/64092 [==============================] - 181s 3ms/step - loss: 0.3592 - accuracy: 0.8499 - val_loss: 0.3620 - val_accuracy: 0.8484\n",
      "Epoch 68/100\n",
      "64092/64092 [==============================] - 181s 3ms/step - loss: 0.3590 - accuracy: 0.8503 - val_loss: 0.3627 - val_accuracy: 0.8480\n",
      "Epoch 69/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3589 - accuracy: 0.8499 - val_loss: 0.3679 - val_accuracy: 0.8441\n",
      "Epoch 70/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3590 - accuracy: 0.8501 - val_loss: 0.3648 - val_accuracy: 0.8456\n",
      "Epoch 71/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3590 - accuracy: 0.8501 - val_loss: 0.3685 - val_accuracy: 0.8471\n",
      "Epoch 72/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3589 - accuracy: 0.8502 - val_loss: 0.3616 - val_accuracy: 0.8486\n",
      "Epoch 73/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3590 - accuracy: 0.8502 - val_loss: 0.3632 - val_accuracy: 0.8478\n",
      "Epoch 74/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3590 - accuracy: 0.8502 - val_loss: 0.3620 - val_accuracy: 0.8486\n",
      "Epoch 75/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3590 - accuracy: 0.8504 - val_loss: 0.3625 - val_accuracy: 0.8486\n",
      "Epoch 76/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3589 - accuracy: 0.8506 - val_loss: 0.3627 - val_accuracy: 0.8493\n",
      "Epoch 77/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3589 - accuracy: 0.8502 - val_loss: 0.3635 - val_accuracy: 0.8486\n",
      "Epoch 78/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3589 - accuracy: 0.8502 - val_loss: 0.3619 - val_accuracy: 0.8479\n",
      "Epoch 79/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3588 - accuracy: 0.8501 - val_loss: 0.3624 - val_accuracy: 0.8491\n",
      "Epoch 80/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3588 - accuracy: 0.8502 - val_loss: 0.3657 - val_accuracy: 0.8469\n",
      "Epoch 81/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3589 - accuracy: 0.8503 - val_loss: 0.3641 - val_accuracy: 0.8464\n",
      "Epoch 82/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3588 - accuracy: 0.8504 - val_loss: 0.3633 - val_accuracy: 0.8476\n",
      "Epoch 83/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3587 - accuracy: 0.8503 - val_loss: 0.3665 - val_accuracy: 0.8478\n",
      "Epoch 84/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3588 - accuracy: 0.8504 - val_loss: 0.3649 - val_accuracy: 0.8489\n",
      "Epoch 85/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3588 - accuracy: 0.8502 - val_loss: 0.3632 - val_accuracy: 0.8481\n",
      "Epoch 86/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3588 - accuracy: 0.8500 - val_loss: 0.3617 - val_accuracy: 0.8484\n",
      "Epoch 87/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3587 - accuracy: 0.8502 - val_loss: 0.3642 - val_accuracy: 0.8470\n",
      "Epoch 88/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3587 - accuracy: 0.8504 - val_loss: 0.3637 - val_accuracy: 0.8476\n",
      "Epoch 89/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3587 - accuracy: 0.8503 - val_loss: 0.3665 - val_accuracy: 0.8475\n",
      "Epoch 90/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3588 - accuracy: 0.8505 - val_loss: 0.3669 - val_accuracy: 0.8454\n",
      "Epoch 91/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3587 - accuracy: 0.8504 - val_loss: 0.3650 - val_accuracy: 0.8470\n",
      "Epoch 92/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3586 - accuracy: 0.8504 - val_loss: 0.3624 - val_accuracy: 0.8482\n",
      "Epoch 93/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3587 - accuracy: 0.8506 - val_loss: 0.3658 - val_accuracy: 0.8481\n",
      "Epoch 94/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3585 - accuracy: 0.8505 - val_loss: 0.3660 - val_accuracy: 0.8461\n",
      "Epoch 95/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3587 - accuracy: 0.8505 - val_loss: 0.3684 - val_accuracy: 0.8446\n",
      "Epoch 96/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3588 - accuracy: 0.8505 - val_loss: 0.3624 - val_accuracy: 0.8492\n",
      "Epoch 97/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3586 - accuracy: 0.8505 - val_loss: 0.3633 - val_accuracy: 0.8484\n",
      "Epoch 98/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3587 - accuracy: 0.8505 - val_loss: 0.3637 - val_accuracy: 0.8487\n",
      "Epoch 99/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3586 - accuracy: 0.8505 - val_loss: 0.3650 - val_accuracy: 0.8453\n",
      "Epoch 100/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3585 - accuracy: 0.8504 - val_loss: 0.3658 - val_accuracy: 0.8473\n",
      "time taken for training :  18261.932912826538\n",
      "time taken for per epoch :  182.61932912826538\n",
      "\n",
      "\n",
      "\n",
      " Test file no :  3\n",
      "Graph ready\n",
      "Number of random walks for 'Train Graph': 93896\n",
      "time taken for training walks :  1162.9949898719788\n",
      "time taken for training word2vec :  20.754770040512085\n",
      "time taken for getting node embeddings :  0.0011093616485595703\n",
      "x_train and x_test are ready\n",
      "Epoch 1/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.4153 - accuracy: 0.8227 - val_loss: 0.3967 - val_accuracy: 0.8331\n",
      "Epoch 2/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3902 - accuracy: 0.8354 - val_loss: 0.3856 - val_accuracy: 0.8367\n",
      "Epoch 3/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3810 - accuracy: 0.8397 - val_loss: 0.3812 - val_accuracy: 0.8409\n",
      "Epoch 4/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3753 - accuracy: 0.8423 - val_loss: 0.3739 - val_accuracy: 0.8426\n",
      "Epoch 5/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3727 - accuracy: 0.8437 - val_loss: 0.3743 - val_accuracy: 0.8429\n",
      "Epoch 6/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3708 - accuracy: 0.8449 - val_loss: 0.3730 - val_accuracy: 0.8433\n",
      "Epoch 7/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3695 - accuracy: 0.8454 - val_loss: 0.3711 - val_accuracy: 0.8452\n",
      "Epoch 8/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3682 - accuracy: 0.8460 - val_loss: 0.3716 - val_accuracy: 0.8453\n",
      "Epoch 9/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3673 - accuracy: 0.8464 - val_loss: 0.3682 - val_accuracy: 0.8464\n",
      "Epoch 10/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3666 - accuracy: 0.8467 - val_loss: 0.3686 - val_accuracy: 0.8450\n",
      "Epoch 11/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3661 - accuracy: 0.8470 - val_loss: 0.3710 - val_accuracy: 0.8446\n",
      "Epoch 12/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3657 - accuracy: 0.8471 - val_loss: 0.3679 - val_accuracy: 0.8459\n",
      "Epoch 13/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3653 - accuracy: 0.8473 - val_loss: 0.3672 - val_accuracy: 0.8458\n",
      "Epoch 14/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3649 - accuracy: 0.8477 - val_loss: 0.3666 - val_accuracy: 0.8457\n",
      "Epoch 15/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3646 - accuracy: 0.8477 - val_loss: 0.3672 - val_accuracy: 0.8454\n",
      "Epoch 16/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3644 - accuracy: 0.8478 - val_loss: 0.3676 - val_accuracy: 0.8458\n",
      "Epoch 17/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3641 - accuracy: 0.8480 - val_loss: 0.3672 - val_accuracy: 0.8467\n",
      "Epoch 18/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3638 - accuracy: 0.8479 - val_loss: 0.3674 - val_accuracy: 0.8468\n",
      "Epoch 19/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3637 - accuracy: 0.8480 - val_loss: 0.3687 - val_accuracy: 0.8450\n",
      "Epoch 20/100\n",
      "64092/64092 [==============================] - 179s 3ms/step - loss: 0.3634 - accuracy: 0.8483 - val_loss: 0.3700 - val_accuracy: 0.8447\n",
      "Epoch 21/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3630 - accuracy: 0.8484 - val_loss: 0.3675 - val_accuracy: 0.8459\n",
      "Epoch 22/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3629 - accuracy: 0.8486 - val_loss: 0.3654 - val_accuracy: 0.8472\n",
      "Epoch 23/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3628 - accuracy: 0.8487 - val_loss: 0.3669 - val_accuracy: 0.8468\n",
      "Epoch 24/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3625 - accuracy: 0.8488 - val_loss: 0.3651 - val_accuracy: 0.8462\n",
      "Epoch 25/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3624 - accuracy: 0.8489 - val_loss: 0.3645 - val_accuracy: 0.8479\n",
      "Epoch 26/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3622 - accuracy: 0.8489 - val_loss: 0.3655 - val_accuracy: 0.8463\n",
      "Epoch 27/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3621 - accuracy: 0.8488 - val_loss: 0.3711 - val_accuracy: 0.8457\n",
      "Epoch 28/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3619 - accuracy: 0.8489 - val_loss: 0.3661 - val_accuracy: 0.8470\n",
      "Epoch 29/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3617 - accuracy: 0.8493 - val_loss: 0.3669 - val_accuracy: 0.8453\n",
      "Epoch 30/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3616 - accuracy: 0.8491 - val_loss: 0.3655 - val_accuracy: 0.8476\n",
      "Epoch 31/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3614 - accuracy: 0.8490 - val_loss: 0.3639 - val_accuracy: 0.8477\n",
      "Epoch 32/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3612 - accuracy: 0.8492 - val_loss: 0.3642 - val_accuracy: 0.8473\n",
      "Epoch 33/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3612 - accuracy: 0.8492 - val_loss: 0.3642 - val_accuracy: 0.8465\n",
      "Epoch 34/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3611 - accuracy: 0.8493 - val_loss: 0.3651 - val_accuracy: 0.8480\n",
      "Epoch 35/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3609 - accuracy: 0.8495 - val_loss: 0.3646 - val_accuracy: 0.8457\n",
      "Epoch 36/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3609 - accuracy: 0.8493 - val_loss: 0.3633 - val_accuracy: 0.8463\n",
      "Epoch 37/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3607 - accuracy: 0.8493 - val_loss: 0.3621 - val_accuracy: 0.8484\n",
      "Epoch 38/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3605 - accuracy: 0.8497 - val_loss: 0.3634 - val_accuracy: 0.8481\n",
      "Epoch 39/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3604 - accuracy: 0.8497 - val_loss: 0.3698 - val_accuracy: 0.8444\n",
      "Epoch 40/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3604 - accuracy: 0.8498 - val_loss: 0.3631 - val_accuracy: 0.8479\n",
      "Epoch 41/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3604 - accuracy: 0.8496 - val_loss: 0.3632 - val_accuracy: 0.8477\n",
      "Epoch 42/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3602 - accuracy: 0.8497 - val_loss: 0.3644 - val_accuracy: 0.8477\n",
      "Epoch 43/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3601 - accuracy: 0.8497 - val_loss: 0.3639 - val_accuracy: 0.8461\n",
      "Epoch 44/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3601 - accuracy: 0.8499 - val_loss: 0.3628 - val_accuracy: 0.8479\n",
      "Epoch 45/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3601 - accuracy: 0.8496 - val_loss: 0.3627 - val_accuracy: 0.8481\n",
      "Epoch 46/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3599 - accuracy: 0.8497 - val_loss: 0.3619 - val_accuracy: 0.8479\n",
      "Epoch 47/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3600 - accuracy: 0.8499 - val_loss: 0.3646 - val_accuracy: 0.8474\n",
      "Epoch 48/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3599 - accuracy: 0.8497 - val_loss: 0.3615 - val_accuracy: 0.8488\n",
      "Epoch 49/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3598 - accuracy: 0.8499 - val_loss: 0.3632 - val_accuracy: 0.8476\n",
      "Epoch 50/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3597 - accuracy: 0.8498 - val_loss: 0.3630 - val_accuracy: 0.8475\n",
      "Epoch 51/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3598 - accuracy: 0.8497 - val_loss: 0.3633 - val_accuracy: 0.8466\n",
      "Epoch 52/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3596 - accuracy: 0.8500 - val_loss: 0.3617 - val_accuracy: 0.8490\n",
      "Epoch 53/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3597 - accuracy: 0.8499 - val_loss: 0.3632 - val_accuracy: 0.8476\n",
      "Epoch 54/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3596 - accuracy: 0.8498 - val_loss: 0.3629 - val_accuracy: 0.8479\n",
      "Epoch 55/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3596 - accuracy: 0.8498 - val_loss: 0.3626 - val_accuracy: 0.8482\n",
      "Epoch 56/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3596 - accuracy: 0.8499 - val_loss: 0.3666 - val_accuracy: 0.8479\n",
      "Epoch 57/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3594 - accuracy: 0.8500 - val_loss: 0.3639 - val_accuracy: 0.8485\n",
      "Epoch 58/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3595 - accuracy: 0.8500 - val_loss: 0.3651 - val_accuracy: 0.8482\n",
      "Epoch 59/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3593 - accuracy: 0.8501 - val_loss: 0.3634 - val_accuracy: 0.8466\n",
      "Epoch 60/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3594 - accuracy: 0.8502 - val_loss: 0.3625 - val_accuracy: 0.8489\n",
      "Epoch 61/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3594 - accuracy: 0.8498 - val_loss: 0.3613 - val_accuracy: 0.8492\n",
      "Epoch 62/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3593 - accuracy: 0.8500 - val_loss: 0.3615 - val_accuracy: 0.8488\n",
      "Epoch 63/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3593 - accuracy: 0.8501 - val_loss: 0.3621 - val_accuracy: 0.8498\n",
      "Epoch 64/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3593 - accuracy: 0.8503 - val_loss: 0.3622 - val_accuracy: 0.8481\n",
      "Epoch 65/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3593 - accuracy: 0.8501 - val_loss: 0.3644 - val_accuracy: 0.8477\n",
      "Epoch 66/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3592 - accuracy: 0.8503 - val_loss: 0.3612 - val_accuracy: 0.8489\n",
      "Epoch 67/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3591 - accuracy: 0.8502 - val_loss: 0.3639 - val_accuracy: 0.8490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3590 - accuracy: 0.8501 - val_loss: 0.3612 - val_accuracy: 0.8493\n",
      "Epoch 69/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3590 - accuracy: 0.8502 - val_loss: 0.3611 - val_accuracy: 0.8485\n",
      "Epoch 70/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3590 - accuracy: 0.8502 - val_loss: 0.3629 - val_accuracy: 0.8472\n",
      "Epoch 71/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3589 - accuracy: 0.8503 - val_loss: 0.3632 - val_accuracy: 0.8487\n",
      "Epoch 72/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3589 - accuracy: 0.8503 - val_loss: 0.3626 - val_accuracy: 0.8486\n",
      "Epoch 73/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3590 - accuracy: 0.8504 - val_loss: 0.3618 - val_accuracy: 0.8491\n",
      "Epoch 74/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3589 - accuracy: 0.8503 - val_loss: 0.3616 - val_accuracy: 0.8499\n",
      "Epoch 75/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3587 - accuracy: 0.8505 - val_loss: 0.3609 - val_accuracy: 0.8501\n",
      "Epoch 76/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3588 - accuracy: 0.8503 - val_loss: 0.3608 - val_accuracy: 0.8482\n",
      "Epoch 77/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3588 - accuracy: 0.8505 - val_loss: 0.3666 - val_accuracy: 0.8458\n",
      "Epoch 78/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3588 - accuracy: 0.8507 - val_loss: 0.3616 - val_accuracy: 0.8493\n",
      "Epoch 79/100\n",
      "64092/64092 [==============================] - 181s 3ms/step - loss: 0.3587 - accuracy: 0.8504 - val_loss: 0.3607 - val_accuracy: 0.8498\n",
      "Epoch 80/100\n",
      "64092/64092 [==============================] - 179s 3ms/step - loss: 0.3586 - accuracy: 0.8506 - val_loss: 0.3647 - val_accuracy: 0.8487\n",
      "Epoch 81/100\n",
      "64092/64092 [==============================] - 181s 3ms/step - loss: 0.3586 - accuracy: 0.8507 - val_loss: 0.3651 - val_accuracy: 0.8473\n",
      "Epoch 82/100\n",
      "64092/64092 [==============================] - 181s 3ms/step - loss: 0.3586 - accuracy: 0.8505 - val_loss: 0.3624 - val_accuracy: 0.8493\n",
      "Epoch 83/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3586 - accuracy: 0.8504 - val_loss: 0.3621 - val_accuracy: 0.8502\n",
      "Epoch 84/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3586 - accuracy: 0.8508 - val_loss: 0.3613 - val_accuracy: 0.8494\n",
      "Epoch 85/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3585 - accuracy: 0.8508 - val_loss: 0.3656 - val_accuracy: 0.8479\n",
      "Epoch 86/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3585 - accuracy: 0.8506 - val_loss: 0.3642 - val_accuracy: 0.8495\n",
      "Epoch 87/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3584 - accuracy: 0.8505 - val_loss: 0.3617 - val_accuracy: 0.8494\n",
      "Epoch 88/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3584 - accuracy: 0.8508 - val_loss: 0.3638 - val_accuracy: 0.8497\n",
      "Epoch 89/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3584 - accuracy: 0.8508 - val_loss: 0.3610 - val_accuracy: 0.8491\n",
      "Epoch 90/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3585 - accuracy: 0.8503 - val_loss: 0.3605 - val_accuracy: 0.8487\n",
      "Epoch 91/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3583 - accuracy: 0.8507 - val_loss: 0.3624 - val_accuracy: 0.8486\n",
      "Epoch 92/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3584 - accuracy: 0.8506 - val_loss: 0.3596 - val_accuracy: 0.8509\n",
      "Epoch 93/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3584 - accuracy: 0.8505 - val_loss: 0.3615 - val_accuracy: 0.8497\n",
      "Epoch 94/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3584 - accuracy: 0.8507 - val_loss: 0.3609 - val_accuracy: 0.8492\n",
      "Epoch 95/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3585 - accuracy: 0.8507 - val_loss: 0.3609 - val_accuracy: 0.8504\n",
      "Epoch 96/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3583 - accuracy: 0.8508 - val_loss: 0.3603 - val_accuracy: 0.8508\n",
      "Epoch 97/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3583 - accuracy: 0.8507 - val_loss: 0.3597 - val_accuracy: 0.8500\n",
      "Epoch 98/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3584 - accuracy: 0.8506 - val_loss: 0.3598 - val_accuracy: 0.8496\n",
      "Epoch 99/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3583 - accuracy: 0.8508 - val_loss: 0.3630 - val_accuracy: 0.8494\n",
      "Epoch 100/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3582 - accuracy: 0.8507 - val_loss: 0.3610 - val_accuracy: 0.8503\n",
      "time taken for training :  18371.876517772675\n",
      "time taken for per epoch :  183.71876517772674\n",
      "\n",
      "\n",
      "\n",
      " Test file no :  4\n",
      "Graph ready\n",
      "Number of random walks for 'Train Graph': 93896\n",
      "time taken for training walks :  1186.7984781265259\n",
      "time taken for training word2vec :  21.25464415550232\n",
      "time taken for getting node embeddings :  0.0009691715240478516\n",
      "x_train and x_test are ready\n",
      "Epoch 1/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.4158 - accuracy: 0.8214 - val_loss: 0.3942 - val_accuracy: 0.8316\n",
      "Epoch 2/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3885 - accuracy: 0.8356 - val_loss: 0.3854 - val_accuracy: 0.8356\n",
      "Epoch 3/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3800 - accuracy: 0.8401 - val_loss: 0.3797 - val_accuracy: 0.8400\n",
      "Epoch 4/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3751 - accuracy: 0.8425 - val_loss: 0.3745 - val_accuracy: 0.8429\n",
      "Epoch 5/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3724 - accuracy: 0.8439 - val_loss: 0.3737 - val_accuracy: 0.8432\n",
      "Epoch 6/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3705 - accuracy: 0.8448 - val_loss: 0.3721 - val_accuracy: 0.8444\n",
      "Epoch 7/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3686 - accuracy: 0.8461 - val_loss: 0.3761 - val_accuracy: 0.8414\n",
      "Epoch 8/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3674 - accuracy: 0.8465 - val_loss: 0.3719 - val_accuracy: 0.8433\n",
      "Epoch 9/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3666 - accuracy: 0.8468 - val_loss: 0.3701 - val_accuracy: 0.8449\n",
      "Epoch 10/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3659 - accuracy: 0.8473 - val_loss: 0.3716 - val_accuracy: 0.8440\n",
      "Epoch 11/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3654 - accuracy: 0.8475 - val_loss: 0.3701 - val_accuracy: 0.8452\n",
      "Epoch 12/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3649 - accuracy: 0.8478 - val_loss: 0.3715 - val_accuracy: 0.8450\n",
      "Epoch 13/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3645 - accuracy: 0.8480 - val_loss: 0.3708 - val_accuracy: 0.8450\n",
      "Epoch 14/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3642 - accuracy: 0.8479 - val_loss: 0.3679 - val_accuracy: 0.8474\n",
      "Epoch 15/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3638 - accuracy: 0.8482 - val_loss: 0.3684 - val_accuracy: 0.8463\n",
      "Epoch 16/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3636 - accuracy: 0.8487 - val_loss: 0.3675 - val_accuracy: 0.8475\n",
      "Epoch 17/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3633 - accuracy: 0.8488 - val_loss: 0.3686 - val_accuracy: 0.8461\n",
      "Epoch 18/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3630 - accuracy: 0.8487 - val_loss: 0.3662 - val_accuracy: 0.8474\n",
      "Epoch 19/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3628 - accuracy: 0.8491 - val_loss: 0.3704 - val_accuracy: 0.8450\n",
      "Epoch 20/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3625 - accuracy: 0.8492 - val_loss: 0.3673 - val_accuracy: 0.8474\n",
      "Epoch 21/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3623 - accuracy: 0.8492 - val_loss: 0.3677 - val_accuracy: 0.8466\n",
      "Epoch 22/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3622 - accuracy: 0.8493 - val_loss: 0.3671 - val_accuracy: 0.8466\n",
      "Epoch 23/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3620 - accuracy: 0.8493 - val_loss: 0.3693 - val_accuracy: 0.8455\n",
      "Epoch 24/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3618 - accuracy: 0.8494 - val_loss: 0.3666 - val_accuracy: 0.8474\n",
      "Epoch 25/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3616 - accuracy: 0.8496 - val_loss: 0.3692 - val_accuracy: 0.8454\n",
      "Epoch 26/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3616 - accuracy: 0.8496 - val_loss: 0.3656 - val_accuracy: 0.8474\n",
      "Epoch 27/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3614 - accuracy: 0.8496 - val_loss: 0.3671 - val_accuracy: 0.8471\n",
      "Epoch 28/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3612 - accuracy: 0.8494 - val_loss: 0.3683 - val_accuracy: 0.8453\n",
      "Epoch 29/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3611 - accuracy: 0.8496 - val_loss: 0.3668 - val_accuracy: 0.8472\n",
      "Epoch 30/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3610 - accuracy: 0.8499 - val_loss: 0.3654 - val_accuracy: 0.8481\n",
      "Epoch 31/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3608 - accuracy: 0.8498 - val_loss: 0.3658 - val_accuracy: 0.8479\n",
      "Epoch 32/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3608 - accuracy: 0.8500 - val_loss: 0.3670 - val_accuracy: 0.8470\n",
      "Epoch 33/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3607 - accuracy: 0.8500 - val_loss: 0.3648 - val_accuracy: 0.8481\n",
      "Epoch 34/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3606 - accuracy: 0.8501 - val_loss: 0.3686 - val_accuracy: 0.8452\n",
      "Epoch 35/100\n",
      "64092/64092 [==============================] - 178s 3ms/step - loss: 0.3605 - accuracy: 0.8500 - val_loss: 0.3720 - val_accuracy: 0.8432\n",
      "Epoch 36/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3605 - accuracy: 0.8501 - val_loss: 0.3651 - val_accuracy: 0.8492\n",
      "Epoch 37/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3603 - accuracy: 0.8502 - val_loss: 0.3648 - val_accuracy: 0.8485\n",
      "Epoch 38/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3602 - accuracy: 0.8502 - val_loss: 0.3661 - val_accuracy: 0.8474\n",
      "Epoch 39/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3602 - accuracy: 0.8502 - val_loss: 0.3652 - val_accuracy: 0.8477\n",
      "Epoch 40/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3601 - accuracy: 0.8501 - val_loss: 0.3659 - val_accuracy: 0.8466\n",
      "Epoch 41/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3601 - accuracy: 0.8502 - val_loss: 0.3650 - val_accuracy: 0.8479\n",
      "Epoch 42/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3600 - accuracy: 0.8502 - val_loss: 0.3645 - val_accuracy: 0.8477\n",
      "Epoch 43/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3598 - accuracy: 0.8503 - val_loss: 0.3647 - val_accuracy: 0.8479\n",
      "Epoch 44/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3597 - accuracy: 0.8504 - val_loss: 0.3646 - val_accuracy: 0.8479\n",
      "Epoch 45/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3596 - accuracy: 0.8505 - val_loss: 0.3636 - val_accuracy: 0.8480\n",
      "Epoch 46/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3596 - accuracy: 0.8504 - val_loss: 0.3636 - val_accuracy: 0.8477\n",
      "Epoch 47/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3595 - accuracy: 0.8505 - val_loss: 0.3713 - val_accuracy: 0.8448\n",
      "Epoch 48/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3594 - accuracy: 0.8503 - val_loss: 0.3665 - val_accuracy: 0.8484\n",
      "Epoch 49/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3594 - accuracy: 0.8506 - val_loss: 0.3640 - val_accuracy: 0.8483\n",
      "Epoch 50/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3593 - accuracy: 0.8507 - val_loss: 0.3637 - val_accuracy: 0.8483\n",
      "Epoch 51/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3592 - accuracy: 0.8504 - val_loss: 0.3655 - val_accuracy: 0.8464\n",
      "Epoch 52/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3591 - accuracy: 0.8507 - val_loss: 0.3651 - val_accuracy: 0.8475\n",
      "Epoch 53/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3590 - accuracy: 0.8506 - val_loss: 0.3647 - val_accuracy: 0.8482\n",
      "Epoch 54/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3590 - accuracy: 0.8506 - val_loss: 0.3638 - val_accuracy: 0.8480\n",
      "Epoch 55/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3589 - accuracy: 0.8503 - val_loss: 0.3656 - val_accuracy: 0.8466\n",
      "Epoch 56/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3588 - accuracy: 0.8504 - val_loss: 0.3642 - val_accuracy: 0.8480\n",
      "Epoch 57/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3588 - accuracy: 0.8507 - val_loss: 0.3631 - val_accuracy: 0.8484\n",
      "Epoch 58/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3587 - accuracy: 0.8507 - val_loss: 0.3652 - val_accuracy: 0.8474\n",
      "Epoch 59/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3588 - accuracy: 0.8507 - val_loss: 0.3638 - val_accuracy: 0.8480\n",
      "Epoch 60/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3586 - accuracy: 0.8507 - val_loss: 0.3661 - val_accuracy: 0.8465\n",
      "Epoch 61/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3586 - accuracy: 0.8506 - val_loss: 0.3661 - val_accuracy: 0.8478\n",
      "Epoch 62/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3585 - accuracy: 0.8506 - val_loss: 0.3643 - val_accuracy: 0.8473\n",
      "Epoch 63/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3585 - accuracy: 0.8509 - val_loss: 0.3635 - val_accuracy: 0.8479\n",
      "Epoch 64/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3584 - accuracy: 0.8508 - val_loss: 0.3625 - val_accuracy: 0.8488\n",
      "Epoch 65/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3584 - accuracy: 0.8506 - val_loss: 0.3638 - val_accuracy: 0.8472\n",
      "Epoch 66/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3584 - accuracy: 0.8505 - val_loss: 0.3634 - val_accuracy: 0.8479\n",
      "Epoch 67/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3583 - accuracy: 0.8509 - val_loss: 0.3657 - val_accuracy: 0.8478\n",
      "Epoch 68/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3584 - accuracy: 0.8509 - val_loss: 0.3650 - val_accuracy: 0.8467\n",
      "Epoch 69/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3583 - accuracy: 0.8508 - val_loss: 0.3629 - val_accuracy: 0.8486\n",
      "Epoch 70/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3583 - accuracy: 0.8508 - val_loss: 0.3647 - val_accuracy: 0.8476\n",
      "Epoch 71/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3582 - accuracy: 0.8509 - val_loss: 0.3658 - val_accuracy: 0.8471\n",
      "Epoch 72/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3582 - accuracy: 0.8508 - val_loss: 0.3651 - val_accuracy: 0.8466\n",
      "Epoch 73/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3581 - accuracy: 0.8509 - val_loss: 0.3634 - val_accuracy: 0.8484\n",
      "Epoch 74/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3580 - accuracy: 0.8507 - val_loss: 0.3635 - val_accuracy: 0.8481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3581 - accuracy: 0.8508 - val_loss: 0.3625 - val_accuracy: 0.8486\n",
      "Epoch 76/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3580 - accuracy: 0.8510 - val_loss: 0.3637 - val_accuracy: 0.8469\n",
      "Epoch 77/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3580 - accuracy: 0.8510 - val_loss: 0.3654 - val_accuracy: 0.8482\n",
      "Epoch 78/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3580 - accuracy: 0.8508 - val_loss: 0.3646 - val_accuracy: 0.8479\n",
      "Epoch 79/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3579 - accuracy: 0.8510 - val_loss: 0.3672 - val_accuracy: 0.8462\n",
      "Epoch 80/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3579 - accuracy: 0.8510 - val_loss: 0.3727 - val_accuracy: 0.8441\n",
      "Epoch 81/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3580 - accuracy: 0.8510 - val_loss: 0.3658 - val_accuracy: 0.8462\n",
      "Epoch 82/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3579 - accuracy: 0.8510 - val_loss: 0.3632 - val_accuracy: 0.8474\n",
      "Epoch 83/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3579 - accuracy: 0.8510 - val_loss: 0.3631 - val_accuracy: 0.8484\n",
      "Epoch 84/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3579 - accuracy: 0.8509 - val_loss: 0.3633 - val_accuracy: 0.8484\n",
      "Epoch 85/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3579 - accuracy: 0.8511 - val_loss: 0.3631 - val_accuracy: 0.8487\n",
      "Epoch 86/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3578 - accuracy: 0.8511 - val_loss: 0.3644 - val_accuracy: 0.8480\n",
      "Epoch 87/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3578 - accuracy: 0.8510 - val_loss: 0.3623 - val_accuracy: 0.8491\n",
      "Epoch 88/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3578 - accuracy: 0.8510 - val_loss: 0.3654 - val_accuracy: 0.8484\n",
      "Epoch 89/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3577 - accuracy: 0.8511 - val_loss: 0.3659 - val_accuracy: 0.8469\n",
      "Epoch 90/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3579 - accuracy: 0.8510 - val_loss: 0.3630 - val_accuracy: 0.8485\n",
      "Epoch 91/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3578 - accuracy: 0.8511 - val_loss: 0.3625 - val_accuracy: 0.8493\n",
      "Epoch 92/100\n",
      "64092/64092 [==============================] - 181s 3ms/step - loss: 0.3576 - accuracy: 0.8512 - val_loss: 0.3630 - val_accuracy: 0.8478\n",
      "Epoch 93/100\n",
      "64092/64092 [==============================] - 179s 3ms/step - loss: 0.3577 - accuracy: 0.8511 - val_loss: 0.3624 - val_accuracy: 0.8487\n",
      "Epoch 94/100\n",
      "64092/64092 [==============================] - 180s 3ms/step - loss: 0.3577 - accuracy: 0.8510 - val_loss: 0.3626 - val_accuracy: 0.8489\n",
      "Epoch 95/100\n",
      "64092/64092 [==============================] - 181s 3ms/step - loss: 0.3577 - accuracy: 0.8513 - val_loss: 0.3638 - val_accuracy: 0.8474\n",
      "Epoch 96/100\n",
      "64092/64092 [==============================] - 181s 3ms/step - loss: 0.3578 - accuracy: 0.8509 - val_loss: 0.3692 - val_accuracy: 0.8443\n",
      "Epoch 97/100\n",
      "64092/64092 [==============================] - 181s 3ms/step - loss: 0.3577 - accuracy: 0.8512 - val_loss: 0.3646 - val_accuracy: 0.8468\n",
      "Epoch 98/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3577 - accuracy: 0.8510 - val_loss: 0.3647 - val_accuracy: 0.8476\n",
      "Epoch 99/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3576 - accuracy: 0.8511 - val_loss: 0.3632 - val_accuracy: 0.8489\n",
      "Epoch 100/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3576 - accuracy: 0.8509 - val_loss: 0.3624 - val_accuracy: 0.8480\n",
      "time taken for training :  18341.840461730957\n",
      "time taken for per epoch :  183.41840461730956\n",
      "\n",
      "\n",
      "\n",
      " Test file no :  5\n",
      "Graph ready\n",
      "Number of random walks for 'Train Graph': 93896\n",
      "time taken for training walks :  1178.103057384491\n",
      "time taken for training word2vec :  20.991380214691162\n",
      "time taken for getting node embeddings :  0.0009639263153076172\n",
      "x_train and x_test are ready\n",
      "Epoch 1/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.4064 - accuracy: 0.8267 - val_loss: 0.3808 - val_accuracy: 0.8415\n",
      "Epoch 2/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3749 - accuracy: 0.8433 - val_loss: 0.3711 - val_accuracy: 0.8456\n",
      "Epoch 3/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3696 - accuracy: 0.8457 - val_loss: 0.3670 - val_accuracy: 0.8469\n",
      "Epoch 4/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3670 - accuracy: 0.8467 - val_loss: 0.3668 - val_accuracy: 0.8449\n",
      "Epoch 5/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3651 - accuracy: 0.8476 - val_loss: 0.3645 - val_accuracy: 0.8491\n",
      "Epoch 6/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3635 - accuracy: 0.8485 - val_loss: 0.3620 - val_accuracy: 0.8495\n",
      "Epoch 7/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3618 - accuracy: 0.8493 - val_loss: 0.3614 - val_accuracy: 0.8496\n",
      "Epoch 8/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3606 - accuracy: 0.8499 - val_loss: 0.3641 - val_accuracy: 0.8492\n",
      "Epoch 9/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3599 - accuracy: 0.8502 - val_loss: 0.3605 - val_accuracy: 0.8507\n",
      "Epoch 10/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3591 - accuracy: 0.8506 - val_loss: 0.3593 - val_accuracy: 0.8510\n",
      "Epoch 11/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3586 - accuracy: 0.8508 - val_loss: 0.3590 - val_accuracy: 0.8508\n",
      "Epoch 12/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3580 - accuracy: 0.8510 - val_loss: 0.3574 - val_accuracy: 0.8522\n",
      "Epoch 13/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3577 - accuracy: 0.8513 - val_loss: 0.3581 - val_accuracy: 0.8528\n",
      "Epoch 14/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3572 - accuracy: 0.8514 - val_loss: 0.3578 - val_accuracy: 0.8521\n",
      "Epoch 15/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3569 - accuracy: 0.8514 - val_loss: 0.3566 - val_accuracy: 0.8526\n",
      "Epoch 16/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3566 - accuracy: 0.8516 - val_loss: 0.3657 - val_accuracy: 0.8488\n",
      "Epoch 17/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3564 - accuracy: 0.8521 - val_loss: 0.3567 - val_accuracy: 0.8525\n",
      "Epoch 18/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3561 - accuracy: 0.8521 - val_loss: 0.3584 - val_accuracy: 0.8519\n",
      "Epoch 19/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3560 - accuracy: 0.8519 - val_loss: 0.3571 - val_accuracy: 0.8519\n",
      "Epoch 20/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3558 - accuracy: 0.8524 - val_loss: 0.3561 - val_accuracy: 0.8524\n",
      "Epoch 21/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3556 - accuracy: 0.8523 - val_loss: 0.3559 - val_accuracy: 0.8529\n",
      "Epoch 22/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3554 - accuracy: 0.8522 - val_loss: 0.3568 - val_accuracy: 0.8527\n",
      "Epoch 23/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3553 - accuracy: 0.8524 - val_loss: 0.3568 - val_accuracy: 0.8533\n",
      "Epoch 24/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3551 - accuracy: 0.8525 - val_loss: 0.3549 - val_accuracy: 0.8529\n",
      "Epoch 25/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3549 - accuracy: 0.8528 - val_loss: 0.3597 - val_accuracy: 0.8500\n",
      "Epoch 26/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3548 - accuracy: 0.8527 - val_loss: 0.3565 - val_accuracy: 0.8525\n",
      "Epoch 27/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3546 - accuracy: 0.8528 - val_loss: 0.3551 - val_accuracy: 0.8528\n",
      "Epoch 28/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3547 - accuracy: 0.8527 - val_loss: 0.3584 - val_accuracy: 0.8525\n",
      "Epoch 29/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3544 - accuracy: 0.8529 - val_loss: 0.3570 - val_accuracy: 0.8521\n",
      "Epoch 30/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3543 - accuracy: 0.8530 - val_loss: 0.3566 - val_accuracy: 0.8519\n",
      "Epoch 31/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3542 - accuracy: 0.8531 - val_loss: 0.3547 - val_accuracy: 0.8531\n",
      "Epoch 32/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3542 - accuracy: 0.8529 - val_loss: 0.3538 - val_accuracy: 0.8538\n",
      "Epoch 33/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3540 - accuracy: 0.8533 - val_loss: 0.3547 - val_accuracy: 0.8522\n",
      "Epoch 34/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3539 - accuracy: 0.8531 - val_loss: 0.3556 - val_accuracy: 0.8522\n",
      "Epoch 35/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3539 - accuracy: 0.8531 - val_loss: 0.3540 - val_accuracy: 0.8538\n",
      "Epoch 36/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3538 - accuracy: 0.8532 - val_loss: 0.3565 - val_accuracy: 0.8520\n",
      "Epoch 37/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3537 - accuracy: 0.8532 - val_loss: 0.3544 - val_accuracy: 0.8530\n",
      "Epoch 38/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3536 - accuracy: 0.8535 - val_loss: 0.3608 - val_accuracy: 0.8497\n",
      "Epoch 39/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3535 - accuracy: 0.8535 - val_loss: 0.3540 - val_accuracy: 0.8529\n",
      "Epoch 40/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3535 - accuracy: 0.8536 - val_loss: 0.3578 - val_accuracy: 0.8511\n",
      "Epoch 41/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3533 - accuracy: 0.8534 - val_loss: 0.3558 - val_accuracy: 0.8525\n",
      "Epoch 42/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3534 - accuracy: 0.8534 - val_loss: 0.3547 - val_accuracy: 0.8532\n",
      "Epoch 43/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3533 - accuracy: 0.8534 - val_loss: 0.3569 - val_accuracy: 0.8517\n",
      "Epoch 44/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3533 - accuracy: 0.8533 - val_loss: 0.3536 - val_accuracy: 0.8532\n",
      "Epoch 45/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3533 - accuracy: 0.8535 - val_loss: 0.3550 - val_accuracy: 0.8527\n",
      "Epoch 46/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3533 - accuracy: 0.8534 - val_loss: 0.3548 - val_accuracy: 0.8528\n",
      "Epoch 47/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3532 - accuracy: 0.8535 - val_loss: 0.3543 - val_accuracy: 0.8528\n",
      "Epoch 48/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3529 - accuracy: 0.8537 - val_loss: 0.3562 - val_accuracy: 0.8535\n",
      "Epoch 49/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3530 - accuracy: 0.8534 - val_loss: 0.3540 - val_accuracy: 0.8530\n",
      "Epoch 50/100\n",
      "64092/64092 [==============================] - 178s 3ms/step - loss: 0.3530 - accuracy: 0.8537 - val_loss: 0.3554 - val_accuracy: 0.8529\n",
      "Epoch 51/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3530 - accuracy: 0.8536 - val_loss: 0.3544 - val_accuracy: 0.8532\n",
      "Epoch 52/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3529 - accuracy: 0.8538 - val_loss: 0.3546 - val_accuracy: 0.8522\n",
      "Epoch 53/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3528 - accuracy: 0.8537 - val_loss: 0.3550 - val_accuracy: 0.8532\n",
      "Epoch 54/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3528 - accuracy: 0.8536 - val_loss: 0.3546 - val_accuracy: 0.8531\n",
      "Epoch 55/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3529 - accuracy: 0.8534 - val_loss: 0.3550 - val_accuracy: 0.8528\n",
      "Epoch 56/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3528 - accuracy: 0.8537 - val_loss: 0.3538 - val_accuracy: 0.8531\n",
      "Epoch 57/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3528 - accuracy: 0.8538 - val_loss: 0.3537 - val_accuracy: 0.8545\n",
      "Epoch 58/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3527 - accuracy: 0.8538 - val_loss: 0.3557 - val_accuracy: 0.8517\n",
      "Epoch 59/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3527 - accuracy: 0.8536 - val_loss: 0.3579 - val_accuracy: 0.8506\n",
      "Epoch 60/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3527 - accuracy: 0.8536 - val_loss: 0.3571 - val_accuracy: 0.8516\n",
      "Epoch 61/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3527 - accuracy: 0.8537 - val_loss: 0.3566 - val_accuracy: 0.8529\n",
      "Epoch 62/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3526 - accuracy: 0.8540 - val_loss: 0.3536 - val_accuracy: 0.8527\n",
      "Epoch 63/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3526 - accuracy: 0.8539 - val_loss: 0.3530 - val_accuracy: 0.8534\n",
      "Epoch 64/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3525 - accuracy: 0.8540 - val_loss: 0.3539 - val_accuracy: 0.8526\n",
      "Epoch 65/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3525 - accuracy: 0.8536 - val_loss: 0.3557 - val_accuracy: 0.8513\n",
      "Epoch 66/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3526 - accuracy: 0.8537 - val_loss: 0.3541 - val_accuracy: 0.8539\n",
      "Epoch 67/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3525 - accuracy: 0.8538 - val_loss: 0.3546 - val_accuracy: 0.8530\n",
      "Epoch 68/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3524 - accuracy: 0.8539 - val_loss: 0.3542 - val_accuracy: 0.8531\n",
      "Epoch 69/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3524 - accuracy: 0.8539 - val_loss: 0.3547 - val_accuracy: 0.8527\n",
      "Epoch 70/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3525 - accuracy: 0.8540 - val_loss: 0.3548 - val_accuracy: 0.8531\n",
      "Epoch 71/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3524 - accuracy: 0.8538 - val_loss: 0.3542 - val_accuracy: 0.8537\n",
      "Epoch 72/100\n",
      "64092/64092 [==============================] - 180s 3ms/step - loss: 0.3523 - accuracy: 0.8539 - val_loss: 0.3539 - val_accuracy: 0.8528\n",
      "Epoch 73/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3523 - accuracy: 0.8539 - val_loss: 0.3544 - val_accuracy: 0.8526\n",
      "Epoch 74/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3523 - accuracy: 0.8538 - val_loss: 0.3555 - val_accuracy: 0.8533\n",
      "Epoch 75/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3523 - accuracy: 0.8540 - val_loss: 0.3550 - val_accuracy: 0.8527\n",
      "Epoch 76/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3522 - accuracy: 0.8539 - val_loss: 0.3550 - val_accuracy: 0.8535\n",
      "Epoch 77/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3521 - accuracy: 0.8540 - val_loss: 0.3556 - val_accuracy: 0.8538\n",
      "Epoch 78/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3522 - accuracy: 0.8541 - val_loss: 0.3530 - val_accuracy: 0.8535\n",
      "Epoch 79/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3521 - accuracy: 0.8540 - val_loss: 0.3541 - val_accuracy: 0.8538\n",
      "Epoch 80/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3521 - accuracy: 0.8542 - val_loss: 0.3542 - val_accuracy: 0.8537\n",
      "Epoch 81/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3520 - accuracy: 0.8540 - val_loss: 0.3535 - val_accuracy: 0.8536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3521 - accuracy: 0.8540 - val_loss: 0.3540 - val_accuracy: 0.8537\n",
      "Epoch 83/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3521 - accuracy: 0.8540 - val_loss: 0.3554 - val_accuracy: 0.8519\n",
      "Epoch 84/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3520 - accuracy: 0.8540 - val_loss: 0.3549 - val_accuracy: 0.8524\n",
      "Epoch 85/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3520 - accuracy: 0.8540 - val_loss: 0.3538 - val_accuracy: 0.8536\n",
      "Epoch 86/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3520 - accuracy: 0.8541 - val_loss: 0.3566 - val_accuracy: 0.8533\n",
      "Epoch 87/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3521 - accuracy: 0.8541 - val_loss: 0.3546 - val_accuracy: 0.8542\n",
      "Epoch 88/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3520 - accuracy: 0.8538 - val_loss: 0.3557 - val_accuracy: 0.8517\n",
      "Epoch 89/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3520 - accuracy: 0.8543 - val_loss: 0.3576 - val_accuracy: 0.8508\n",
      "Epoch 90/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3519 - accuracy: 0.8540 - val_loss: 0.3554 - val_accuracy: 0.8537\n",
      "Epoch 91/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3519 - accuracy: 0.8539 - val_loss: 0.3552 - val_accuracy: 0.8522\n",
      "Epoch 92/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3519 - accuracy: 0.8541 - val_loss: 0.3535 - val_accuracy: 0.8544\n",
      "Epoch 93/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3519 - accuracy: 0.8540 - val_loss: 0.3535 - val_accuracy: 0.8534\n",
      "Epoch 94/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3519 - accuracy: 0.8541 - val_loss: 0.3530 - val_accuracy: 0.8541\n",
      "Epoch 95/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3519 - accuracy: 0.8541 - val_loss: 0.3532 - val_accuracy: 0.8541\n",
      "Epoch 96/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3518 - accuracy: 0.8542 - val_loss: 0.3576 - val_accuracy: 0.8518\n",
      "Epoch 97/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3518 - accuracy: 0.8542 - val_loss: 0.3528 - val_accuracy: 0.8534\n",
      "Epoch 98/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3518 - accuracy: 0.8541 - val_loss: 0.3541 - val_accuracy: 0.8528\n",
      "Epoch 99/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3519 - accuracy: 0.8541 - val_loss: 0.3540 - val_accuracy: 0.8530\n",
      "Epoch 100/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3518 - accuracy: 0.8542 - val_loss: 0.3546 - val_accuracy: 0.8530\n",
      "time taken for training :  18308.102021217346\n",
      "time taken for per epoch :  183.08102021217346\n",
      "\n",
      "\n",
      "\n",
      " Test file no :  6\n",
      "Graph ready\n",
      "Number of random walks for 'Train Graph': 93896\n",
      "time taken for training walks :  1201.1595225334167\n",
      "time taken for training word2vec :  23.83899736404419\n",
      "time taken for getting node embeddings :  0.0010099411010742188\n",
      "x_train and x_test are ready\n",
      "Epoch 1/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.4071 - accuracy: 0.8267 - val_loss: 0.3818 - val_accuracy: 0.8401\n",
      "Epoch 2/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3786 - accuracy: 0.8411 - val_loss: 0.3723 - val_accuracy: 0.8457\n",
      "Epoch 3/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3715 - accuracy: 0.8447 - val_loss: 0.3658 - val_accuracy: 0.8484\n",
      "Epoch 4/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3672 - accuracy: 0.8469 - val_loss: 0.3629 - val_accuracy: 0.8502\n",
      "Epoch 5/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3652 - accuracy: 0.8478 - val_loss: 0.3625 - val_accuracy: 0.8497\n",
      "Epoch 6/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3635 - accuracy: 0.8486 - val_loss: 0.3611 - val_accuracy: 0.8508\n",
      "Epoch 7/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3616 - accuracy: 0.8498 - val_loss: 0.3611 - val_accuracy: 0.8500\n",
      "Epoch 8/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3604 - accuracy: 0.8502 - val_loss: 0.3580 - val_accuracy: 0.8523\n",
      "Epoch 9/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3595 - accuracy: 0.8506 - val_loss: 0.3574 - val_accuracy: 0.8514\n",
      "Epoch 10/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3587 - accuracy: 0.8510 - val_loss: 0.3583 - val_accuracy: 0.8513\n",
      "Epoch 11/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3582 - accuracy: 0.8513 - val_loss: 0.3571 - val_accuracy: 0.8522\n",
      "Epoch 12/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3576 - accuracy: 0.8517 - val_loss: 0.3564 - val_accuracy: 0.8535\n",
      "Epoch 13/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3572 - accuracy: 0.8518 - val_loss: 0.3578 - val_accuracy: 0.8508\n",
      "Epoch 14/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3568 - accuracy: 0.8520 - val_loss: 0.3573 - val_accuracy: 0.8532\n",
      "Epoch 15/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3565 - accuracy: 0.8521 - val_loss: 0.3560 - val_accuracy: 0.8523\n",
      "Epoch 16/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3562 - accuracy: 0.8524 - val_loss: 0.3557 - val_accuracy: 0.8527\n",
      "Epoch 17/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3561 - accuracy: 0.8525 - val_loss: 0.3585 - val_accuracy: 0.8501\n",
      "Epoch 18/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3557 - accuracy: 0.8526 - val_loss: 0.3547 - val_accuracy: 0.8525\n",
      "Epoch 19/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3554 - accuracy: 0.8526 - val_loss: 0.3571 - val_accuracy: 0.8543\n",
      "Epoch 20/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3548 - accuracy: 0.8530 - val_loss: 0.3541 - val_accuracy: 0.8540\n",
      "Epoch 21/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3544 - accuracy: 0.8533 - val_loss: 0.3536 - val_accuracy: 0.8534\n",
      "Epoch 22/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3541 - accuracy: 0.8532 - val_loss: 0.3550 - val_accuracy: 0.8532\n",
      "Epoch 23/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3537 - accuracy: 0.8536 - val_loss: 0.3528 - val_accuracy: 0.8541\n",
      "Epoch 24/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3534 - accuracy: 0.8537 - val_loss: 0.3562 - val_accuracy: 0.8531\n",
      "Epoch 25/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3531 - accuracy: 0.8539 - val_loss: 0.3529 - val_accuracy: 0.8545\n",
      "Epoch 26/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3530 - accuracy: 0.8537 - val_loss: 0.3545 - val_accuracy: 0.8535\n",
      "Epoch 27/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3528 - accuracy: 0.8540 - val_loss: 0.3517 - val_accuracy: 0.8544\n",
      "Epoch 28/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3526 - accuracy: 0.8540 - val_loss: 0.3595 - val_accuracy: 0.8526\n",
      "Epoch 29/100\n",
      "64092/64092 [==============================] - 181s 3ms/step - loss: 0.3524 - accuracy: 0.8543 - val_loss: 0.3532 - val_accuracy: 0.8534\n",
      "Epoch 30/100\n",
      "64092/64092 [==============================] - 181s 3ms/step - loss: 0.3521 - accuracy: 0.8543 - val_loss: 0.3529 - val_accuracy: 0.8534\n",
      "Epoch 31/100\n",
      "64092/64092 [==============================] - 180s 3ms/step - loss: 0.3520 - accuracy: 0.8544 - val_loss: 0.3513 - val_accuracy: 0.8559\n",
      "Epoch 32/100\n",
      "64092/64092 [==============================] - 179s 3ms/step - loss: 0.3517 - accuracy: 0.8545 - val_loss: 0.3520 - val_accuracy: 0.8547\n",
      "Epoch 33/100\n",
      "64092/64092 [==============================] - 180s 3ms/step - loss: 0.3516 - accuracy: 0.8546 - val_loss: 0.3534 - val_accuracy: 0.8549\n",
      "Epoch 34/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3514 - accuracy: 0.8548 - val_loss: 0.3531 - val_accuracy: 0.8543\n",
      "Epoch 35/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3514 - accuracy: 0.8546 - val_loss: 0.3521 - val_accuracy: 0.8546\n",
      "Epoch 36/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3512 - accuracy: 0.8547 - val_loss: 0.3519 - val_accuracy: 0.8546\n",
      "Epoch 37/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3511 - accuracy: 0.8547 - val_loss: 0.3512 - val_accuracy: 0.8565\n",
      "Epoch 38/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3509 - accuracy: 0.8548 - val_loss: 0.3546 - val_accuracy: 0.8550\n",
      "Epoch 39/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3509 - accuracy: 0.8550 - val_loss: 0.3524 - val_accuracy: 0.8551\n",
      "Epoch 40/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3508 - accuracy: 0.8549 - val_loss: 0.3504 - val_accuracy: 0.8560\n",
      "Epoch 41/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3508 - accuracy: 0.8550 - val_loss: 0.3512 - val_accuracy: 0.8544\n",
      "Epoch 42/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3506 - accuracy: 0.8549 - val_loss: 0.3505 - val_accuracy: 0.8559\n",
      "Epoch 43/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3505 - accuracy: 0.8552 - val_loss: 0.3513 - val_accuracy: 0.8548\n",
      "Epoch 44/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3504 - accuracy: 0.8553 - val_loss: 0.3499 - val_accuracy: 0.8562\n",
      "Epoch 45/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3504 - accuracy: 0.8551 - val_loss: 0.3530 - val_accuracy: 0.8544\n",
      "Epoch 46/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3502 - accuracy: 0.8552 - val_loss: 0.3512 - val_accuracy: 0.8562\n",
      "Epoch 47/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3504 - accuracy: 0.8552 - val_loss: 0.3510 - val_accuracy: 0.8547\n",
      "Epoch 48/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3502 - accuracy: 0.8553 - val_loss: 0.3514 - val_accuracy: 0.8560\n",
      "Epoch 49/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3502 - accuracy: 0.8553 - val_loss: 0.3512 - val_accuracy: 0.8545\n",
      "Epoch 50/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3501 - accuracy: 0.8556 - val_loss: 0.3500 - val_accuracy: 0.8562\n",
      "Epoch 51/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3500 - accuracy: 0.8553 - val_loss: 0.3503 - val_accuracy: 0.8558\n",
      "Epoch 52/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3500 - accuracy: 0.8555 - val_loss: 0.3509 - val_accuracy: 0.8567\n",
      "Epoch 53/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3499 - accuracy: 0.8555 - val_loss: 0.3496 - val_accuracy: 0.8562\n",
      "Epoch 54/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3500 - accuracy: 0.8553 - val_loss: 0.3513 - val_accuracy: 0.8559\n",
      "Epoch 55/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3498 - accuracy: 0.8557 - val_loss: 0.3505 - val_accuracy: 0.8553\n",
      "Epoch 56/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3498 - accuracy: 0.8554 - val_loss: 0.3505 - val_accuracy: 0.8552\n",
      "Epoch 57/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3498 - accuracy: 0.8554 - val_loss: 0.3514 - val_accuracy: 0.8543\n",
      "Epoch 58/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3497 - accuracy: 0.8557 - val_loss: 0.3518 - val_accuracy: 0.8558\n",
      "Epoch 59/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3497 - accuracy: 0.8556 - val_loss: 0.3499 - val_accuracy: 0.8565\n",
      "Epoch 60/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3497 - accuracy: 0.8555 - val_loss: 0.3504 - val_accuracy: 0.8565\n",
      "Epoch 61/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3496 - accuracy: 0.8557 - val_loss: 0.3508 - val_accuracy: 0.8570\n",
      "Epoch 62/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3496 - accuracy: 0.8557 - val_loss: 0.3542 - val_accuracy: 0.8542\n",
      "Epoch 63/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3496 - accuracy: 0.8557 - val_loss: 0.3524 - val_accuracy: 0.8562\n",
      "Epoch 64/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3496 - accuracy: 0.8557 - val_loss: 0.3527 - val_accuracy: 0.8549\n",
      "Epoch 65/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3494 - accuracy: 0.8557 - val_loss: 0.3509 - val_accuracy: 0.8560\n",
      "Epoch 66/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3496 - accuracy: 0.8557 - val_loss: 0.3532 - val_accuracy: 0.8543\n",
      "Epoch 67/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3494 - accuracy: 0.8558 - val_loss: 0.3504 - val_accuracy: 0.8562\n",
      "Epoch 68/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3494 - accuracy: 0.8555 - val_loss: 0.3499 - val_accuracy: 0.8553\n",
      "Epoch 69/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3494 - accuracy: 0.8558 - val_loss: 0.3526 - val_accuracy: 0.8552\n",
      "Epoch 70/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3493 - accuracy: 0.8558 - val_loss: 0.3511 - val_accuracy: 0.8562\n",
      "Epoch 71/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3494 - accuracy: 0.8558 - val_loss: 0.3494 - val_accuracy: 0.8558\n",
      "Epoch 72/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3494 - accuracy: 0.8559 - val_loss: 0.3499 - val_accuracy: 0.8563\n",
      "Epoch 73/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3493 - accuracy: 0.8558 - val_loss: 0.3503 - val_accuracy: 0.8564\n",
      "Epoch 74/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3492 - accuracy: 0.8560 - val_loss: 0.3500 - val_accuracy: 0.8563\n",
      "Epoch 75/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3491 - accuracy: 0.8559 - val_loss: 0.3494 - val_accuracy: 0.8564\n",
      "Epoch 76/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3491 - accuracy: 0.8559 - val_loss: 0.3492 - val_accuracy: 0.8556\n",
      "Epoch 77/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3492 - accuracy: 0.8559 - val_loss: 0.3516 - val_accuracy: 0.8550\n",
      "Epoch 78/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3491 - accuracy: 0.8559 - val_loss: 0.3495 - val_accuracy: 0.8560\n",
      "Epoch 79/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3491 - accuracy: 0.8559 - val_loss: 0.3497 - val_accuracy: 0.8554\n",
      "Epoch 80/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3491 - accuracy: 0.8560 - val_loss: 0.3530 - val_accuracy: 0.8537\n",
      "Epoch 81/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3491 - accuracy: 0.8559 - val_loss: 0.3541 - val_accuracy: 0.8545\n",
      "Epoch 82/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3489 - accuracy: 0.8562 - val_loss: 0.3501 - val_accuracy: 0.8554\n",
      "Epoch 83/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3489 - accuracy: 0.8559 - val_loss: 0.3500 - val_accuracy: 0.8547\n",
      "Epoch 84/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3489 - accuracy: 0.8559 - val_loss: 0.3495 - val_accuracy: 0.8557\n",
      "Epoch 85/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3489 - accuracy: 0.8559 - val_loss: 0.3496 - val_accuracy: 0.8563\n",
      "Epoch 86/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3488 - accuracy: 0.8563 - val_loss: 0.3505 - val_accuracy: 0.8554\n",
      "Epoch 87/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3488 - accuracy: 0.8561 - val_loss: 0.3483 - val_accuracy: 0.8566\n",
      "Epoch 88/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3486 - accuracy: 0.8562 - val_loss: 0.3516 - val_accuracy: 0.8560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3487 - accuracy: 0.8561 - val_loss: 0.3501 - val_accuracy: 0.8554\n",
      "Epoch 90/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3487 - accuracy: 0.8563 - val_loss: 0.3525 - val_accuracy: 0.8554\n",
      "Epoch 91/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3486 - accuracy: 0.8561 - val_loss: 0.3497 - val_accuracy: 0.8565\n",
      "Epoch 92/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3486 - accuracy: 0.8562 - val_loss: 0.3489 - val_accuracy: 0.8557\n",
      "Epoch 93/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3485 - accuracy: 0.8564 - val_loss: 0.3497 - val_accuracy: 0.8555\n",
      "Epoch 94/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3486 - accuracy: 0.8561 - val_loss: 0.3487 - val_accuracy: 0.8558\n",
      "Epoch 95/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3485 - accuracy: 0.8562 - val_loss: 0.3488 - val_accuracy: 0.8557\n",
      "Epoch 96/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3484 - accuracy: 0.8563 - val_loss: 0.3501 - val_accuracy: 0.8561\n",
      "Epoch 97/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3485 - accuracy: 0.8561 - val_loss: 0.3484 - val_accuracy: 0.8569\n",
      "Epoch 98/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3485 - accuracy: 0.8565 - val_loss: 0.3495 - val_accuracy: 0.8567\n",
      "Epoch 99/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3484 - accuracy: 0.8563 - val_loss: 0.3477 - val_accuracy: 0.8569\n",
      "Epoch 100/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3483 - accuracy: 0.8563 - val_loss: 0.3521 - val_accuracy: 0.8556\n",
      "time taken for training :  18339.465112686157\n",
      "time taken for per epoch :  183.39465112686156\n",
      "\n",
      "\n",
      "\n",
      " Test file no :  7\n",
      "Graph ready\n",
      "Number of random walks for 'Train Graph': 93896\n",
      "time taken for training walks :  1129.0490102767944\n",
      "time taken for training word2vec :  20.592084407806396\n",
      "time taken for getting node embeddings :  0.0005931854248046875\n",
      "x_train and x_test are ready\n",
      "Epoch 1/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.4078 - accuracy: 0.8265 - val_loss: 0.3953 - val_accuracy: 0.8306\n",
      "Epoch 2/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3823 - accuracy: 0.8395 - val_loss: 0.3875 - val_accuracy: 0.8362\n",
      "Epoch 3/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3741 - accuracy: 0.8441 - val_loss: 0.3735 - val_accuracy: 0.8440\n",
      "Epoch 4/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3708 - accuracy: 0.8457 - val_loss: 0.3711 - val_accuracy: 0.8456\n",
      "Epoch 5/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3683 - accuracy: 0.8468 - val_loss: 0.3704 - val_accuracy: 0.8462\n",
      "Epoch 6/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3666 - accuracy: 0.8473 - val_loss: 0.3732 - val_accuracy: 0.8450\n",
      "Epoch 7/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3647 - accuracy: 0.8486 - val_loss: 0.3657 - val_accuracy: 0.8477\n",
      "Epoch 8/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3635 - accuracy: 0.8489 - val_loss: 0.3691 - val_accuracy: 0.8463\n",
      "Epoch 9/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3628 - accuracy: 0.8499 - val_loss: 0.3668 - val_accuracy: 0.8471\n",
      "Epoch 10/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3621 - accuracy: 0.8500 - val_loss: 0.3662 - val_accuracy: 0.8479\n",
      "Epoch 11/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3616 - accuracy: 0.8503 - val_loss: 0.3646 - val_accuracy: 0.8479\n",
      "Epoch 12/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3610 - accuracy: 0.8506 - val_loss: 0.3639 - val_accuracy: 0.8488\n",
      "Epoch 13/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3605 - accuracy: 0.8506 - val_loss: 0.3668 - val_accuracy: 0.8469\n",
      "Epoch 14/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3604 - accuracy: 0.8509 - val_loss: 0.3660 - val_accuracy: 0.8503\n",
      "Epoch 15/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3600 - accuracy: 0.8513 - val_loss: 0.3622 - val_accuracy: 0.8504\n",
      "Epoch 16/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3597 - accuracy: 0.8514 - val_loss: 0.3608 - val_accuracy: 0.8507\n",
      "Epoch 17/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3593 - accuracy: 0.8515 - val_loss: 0.3623 - val_accuracy: 0.8493\n",
      "Epoch 18/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3591 - accuracy: 0.8514 - val_loss: 0.3620 - val_accuracy: 0.8496\n",
      "Epoch 19/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3588 - accuracy: 0.8515 - val_loss: 0.3651 - val_accuracy: 0.8489\n",
      "Epoch 20/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3586 - accuracy: 0.8518 - val_loss: 0.3607 - val_accuracy: 0.8505\n",
      "Epoch 21/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3584 - accuracy: 0.8516 - val_loss: 0.3634 - val_accuracy: 0.8488\n",
      "Epoch 22/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3583 - accuracy: 0.8518 - val_loss: 0.3658 - val_accuracy: 0.8476\n",
      "Epoch 23/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3580 - accuracy: 0.8520 - val_loss: 0.3609 - val_accuracy: 0.8505\n",
      "Epoch 24/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3578 - accuracy: 0.8520 - val_loss: 0.3613 - val_accuracy: 0.8497\n",
      "Epoch 25/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3577 - accuracy: 0.8521 - val_loss: 0.3606 - val_accuracy: 0.8502\n",
      "Epoch 26/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3577 - accuracy: 0.8520 - val_loss: 0.3610 - val_accuracy: 0.8510\n",
      "Epoch 27/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3574 - accuracy: 0.8523 - val_loss: 0.3598 - val_accuracy: 0.8517\n",
      "Epoch 28/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3573 - accuracy: 0.8524 - val_loss: 0.3596 - val_accuracy: 0.8515\n",
      "Epoch 29/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3571 - accuracy: 0.8525 - val_loss: 0.3598 - val_accuracy: 0.8509\n",
      "Epoch 30/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3570 - accuracy: 0.8526 - val_loss: 0.3600 - val_accuracy: 0.8518\n",
      "Epoch 31/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3570 - accuracy: 0.8526 - val_loss: 0.3593 - val_accuracy: 0.8516\n",
      "Epoch 32/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3567 - accuracy: 0.8527 - val_loss: 0.3629 - val_accuracy: 0.8473\n",
      "Epoch 33/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3566 - accuracy: 0.8526 - val_loss: 0.3604 - val_accuracy: 0.8516\n",
      "Epoch 34/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3565 - accuracy: 0.8529 - val_loss: 0.3609 - val_accuracy: 0.8504\n",
      "Epoch 35/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3565 - accuracy: 0.8527 - val_loss: 0.3594 - val_accuracy: 0.8515\n",
      "Epoch 36/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3564 - accuracy: 0.8527 - val_loss: 0.3608 - val_accuracy: 0.8497\n",
      "Epoch 37/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3563 - accuracy: 0.8533 - val_loss: 0.3618 - val_accuracy: 0.8495\n",
      "Epoch 38/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3562 - accuracy: 0.8532 - val_loss: 0.3606 - val_accuracy: 0.8501\n",
      "Epoch 39/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3561 - accuracy: 0.8532 - val_loss: 0.3597 - val_accuracy: 0.8513\n",
      "Epoch 40/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3561 - accuracy: 0.8533 - val_loss: 0.3607 - val_accuracy: 0.8504\n",
      "Epoch 41/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3560 - accuracy: 0.8531 - val_loss: 0.3593 - val_accuracy: 0.8500\n",
      "Epoch 42/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3559 - accuracy: 0.8533 - val_loss: 0.3598 - val_accuracy: 0.8496\n",
      "Epoch 43/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3558 - accuracy: 0.8532 - val_loss: 0.3596 - val_accuracy: 0.8510\n",
      "Epoch 44/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3558 - accuracy: 0.8534 - val_loss: 0.3600 - val_accuracy: 0.8500\n",
      "Epoch 45/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3557 - accuracy: 0.8534 - val_loss: 0.3589 - val_accuracy: 0.8508\n",
      "Epoch 46/100\n",
      "64092/64092 [==============================] - 200s 3ms/step - loss: 0.3556 - accuracy: 0.8537 - val_loss: 0.3587 - val_accuracy: 0.8514\n",
      "Epoch 47/100\n",
      "64092/64092 [==============================] - 198s 3ms/step - loss: 0.3556 - accuracy: 0.8534 - val_loss: 0.3592 - val_accuracy: 0.8510\n",
      "Epoch 48/100\n",
      "64092/64092 [==============================] - 199s 3ms/step - loss: 0.3555 - accuracy: 0.8536 - val_loss: 0.3601 - val_accuracy: 0.8518\n",
      "Epoch 49/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3555 - accuracy: 0.8536 - val_loss: 0.3614 - val_accuracy: 0.8481\n",
      "Epoch 50/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3554 - accuracy: 0.8534 - val_loss: 0.3620 - val_accuracy: 0.8499\n",
      "Epoch 51/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3553 - accuracy: 0.8537 - val_loss: 0.3580 - val_accuracy: 0.8511\n",
      "Epoch 52/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3553 - accuracy: 0.8538 - val_loss: 0.3592 - val_accuracy: 0.8517\n",
      "Epoch 53/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3553 - accuracy: 0.8537 - val_loss: 0.3585 - val_accuracy: 0.8510\n",
      "Epoch 54/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3552 - accuracy: 0.8538 - val_loss: 0.3589 - val_accuracy: 0.8507\n",
      "Epoch 55/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3550 - accuracy: 0.8537 - val_loss: 0.3594 - val_accuracy: 0.8504\n",
      "Epoch 56/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3550 - accuracy: 0.8536 - val_loss: 0.3579 - val_accuracy: 0.8515\n",
      "Epoch 57/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3550 - accuracy: 0.8538 - val_loss: 0.3588 - val_accuracy: 0.8518\n",
      "Epoch 58/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3550 - accuracy: 0.8538 - val_loss: 0.3584 - val_accuracy: 0.8529\n",
      "Epoch 59/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3549 - accuracy: 0.8541 - val_loss: 0.3618 - val_accuracy: 0.8491\n",
      "Epoch 60/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3549 - accuracy: 0.8539 - val_loss: 0.3584 - val_accuracy: 0.8516\n",
      "Epoch 61/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3548 - accuracy: 0.8540 - val_loss: 0.3633 - val_accuracy: 0.8499\n",
      "Epoch 62/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3547 - accuracy: 0.8539 - val_loss: 0.3578 - val_accuracy: 0.8507\n",
      "Epoch 63/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3547 - accuracy: 0.8538 - val_loss: 0.3592 - val_accuracy: 0.8521\n",
      "Epoch 64/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3547 - accuracy: 0.8539 - val_loss: 0.3597 - val_accuracy: 0.8504\n",
      "Epoch 65/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3547 - accuracy: 0.8539 - val_loss: 0.3573 - val_accuracy: 0.8525\n",
      "Epoch 66/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3546 - accuracy: 0.8541 - val_loss: 0.3581 - val_accuracy: 0.8518\n",
      "Epoch 67/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3546 - accuracy: 0.8539 - val_loss: 0.3568 - val_accuracy: 0.8522\n",
      "Epoch 68/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3545 - accuracy: 0.8541 - val_loss: 0.3632 - val_accuracy: 0.8480\n",
      "Epoch 69/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3545 - accuracy: 0.8542 - val_loss: 0.3588 - val_accuracy: 0.8503\n",
      "Epoch 70/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3545 - accuracy: 0.8541 - val_loss: 0.3644 - val_accuracy: 0.8494\n",
      "Epoch 71/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3545 - accuracy: 0.8540 - val_loss: 0.3598 - val_accuracy: 0.8515\n",
      "Epoch 72/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3544 - accuracy: 0.8540 - val_loss: 0.3585 - val_accuracy: 0.8509\n",
      "Epoch 73/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3545 - accuracy: 0.8541 - val_loss: 0.3571 - val_accuracy: 0.8520\n",
      "Epoch 74/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3545 - accuracy: 0.8542 - val_loss: 0.3581 - val_accuracy: 0.8521\n",
      "Epoch 75/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3543 - accuracy: 0.8541 - val_loss: 0.3594 - val_accuracy: 0.8498\n",
      "Epoch 76/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3543 - accuracy: 0.8542 - val_loss: 0.3663 - val_accuracy: 0.8462\n",
      "Epoch 77/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3543 - accuracy: 0.8541 - val_loss: 0.3586 - val_accuracy: 0.8519\n",
      "Epoch 78/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3542 - accuracy: 0.8541 - val_loss: 0.3597 - val_accuracy: 0.8510\n",
      "Epoch 79/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3541 - accuracy: 0.8542 - val_loss: 0.3572 - val_accuracy: 0.8525\n",
      "Epoch 80/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3541 - accuracy: 0.8544 - val_loss: 0.3597 - val_accuracy: 0.8500\n",
      "Epoch 81/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3541 - accuracy: 0.8542 - val_loss: 0.3620 - val_accuracy: 0.8492\n",
      "Epoch 82/100\n",
      "64092/64092 [==============================] - 190s 3ms/step - loss: 0.3540 - accuracy: 0.8542 - val_loss: 0.3604 - val_accuracy: 0.8519\n",
      "Epoch 83/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3540 - accuracy: 0.8544 - val_loss: 0.3598 - val_accuracy: 0.8515\n",
      "Epoch 84/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3540 - accuracy: 0.8544 - val_loss: 0.3577 - val_accuracy: 0.8519\n",
      "Epoch 85/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3540 - accuracy: 0.8542 - val_loss: 0.3569 - val_accuracy: 0.8519\n",
      "Epoch 86/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3539 - accuracy: 0.8542 - val_loss: 0.3616 - val_accuracy: 0.8504\n",
      "Epoch 87/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3539 - accuracy: 0.8543 - val_loss: 0.3593 - val_accuracy: 0.8516\n",
      "Epoch 88/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3538 - accuracy: 0.8544 - val_loss: 0.3600 - val_accuracy: 0.8520\n",
      "Epoch 89/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3537 - accuracy: 0.8544 - val_loss: 0.3628 - val_accuracy: 0.8500\n",
      "Epoch 90/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3538 - accuracy: 0.8540 - val_loss: 0.3590 - val_accuracy: 0.8521\n",
      "Epoch 91/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3538 - accuracy: 0.8544 - val_loss: 0.3589 - val_accuracy: 0.8525\n",
      "Epoch 92/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3538 - accuracy: 0.8544 - val_loss: 0.3572 - val_accuracy: 0.8521\n",
      "Epoch 93/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3537 - accuracy: 0.8544 - val_loss: 0.3570 - val_accuracy: 0.8530\n",
      "Epoch 94/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3537 - accuracy: 0.8544 - val_loss: 0.3572 - val_accuracy: 0.8529\n",
      "Epoch 95/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3537 - accuracy: 0.8543 - val_loss: 0.3648 - val_accuracy: 0.8489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3537 - accuracy: 0.8544 - val_loss: 0.3579 - val_accuracy: 0.8532\n",
      "Epoch 97/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3536 - accuracy: 0.8544 - val_loss: 0.3569 - val_accuracy: 0.8522\n",
      "Epoch 98/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3536 - accuracy: 0.8543 - val_loss: 0.3567 - val_accuracy: 0.8523\n",
      "Epoch 99/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3537 - accuracy: 0.8544 - val_loss: 0.3572 - val_accuracy: 0.8518\n",
      "Epoch 100/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3537 - accuracy: 0.8543 - val_loss: 0.3602 - val_accuracy: 0.8494\n",
      "time taken for training :  19217.01907634735\n",
      "time taken for per epoch :  192.1701907634735\n",
      "\n",
      "\n",
      "\n",
      " Test file no :  8\n",
      "Graph ready\n",
      "Number of random walks for 'Train Graph': 93896\n",
      "time taken for training walks :  983.4895722866058\n",
      "time taken for training word2vec :  20.133061408996582\n",
      "time taken for getting node embeddings :  0.0004181861877441406\n",
      "x_train and x_test are ready\n",
      "Epoch 1/100\n",
      "64092/64092 [==============================] - 200s 3ms/step - loss: 0.4035 - accuracy: 0.8272 - val_loss: 0.3802 - val_accuracy: 0.8410\n",
      "Epoch 2/100\n",
      "64092/64092 [==============================] - 200s 3ms/step - loss: 0.3763 - accuracy: 0.8410 - val_loss: 0.3727 - val_accuracy: 0.8444\n",
      "Epoch 3/100\n",
      "64092/64092 [==============================] - 197s 3ms/step - loss: 0.3704 - accuracy: 0.8441 - val_loss: 0.3644 - val_accuracy: 0.8487\n",
      "Epoch 4/100\n",
      "64092/64092 [==============================] - 197s 3ms/step - loss: 0.3671 - accuracy: 0.8457 - val_loss: 0.3677 - val_accuracy: 0.8444\n",
      "Epoch 5/100\n",
      "64092/64092 [==============================] - 197s 3ms/step - loss: 0.3641 - accuracy: 0.8477 - val_loss: 0.3579 - val_accuracy: 0.8508\n",
      "Epoch 6/100\n",
      "64092/64092 [==============================] - 196s 3ms/step - loss: 0.3615 - accuracy: 0.8489 - val_loss: 0.3594 - val_accuracy: 0.8491\n",
      "Epoch 7/100\n",
      "64092/64092 [==============================] - 196s 3ms/step - loss: 0.3601 - accuracy: 0.8496 - val_loss: 0.3576 - val_accuracy: 0.8509\n",
      "Epoch 8/100\n",
      "64092/64092 [==============================] - 197s 3ms/step - loss: 0.3587 - accuracy: 0.8501 - val_loss: 0.3566 - val_accuracy: 0.8516\n",
      "Epoch 9/100\n",
      "64092/64092 [==============================] - 197s 3ms/step - loss: 0.3575 - accuracy: 0.8509 - val_loss: 0.3547 - val_accuracy: 0.8507\n",
      "Epoch 10/100\n",
      "64092/64092 [==============================] - 197s 3ms/step - loss: 0.3567 - accuracy: 0.8512 - val_loss: 0.3530 - val_accuracy: 0.8526\n",
      "Epoch 11/100\n",
      "64092/64092 [==============================] - 198s 3ms/step - loss: 0.3558 - accuracy: 0.8515 - val_loss: 0.3543 - val_accuracy: 0.8509\n",
      "Epoch 12/100\n",
      "64092/64092 [==============================] - 198s 3ms/step - loss: 0.3551 - accuracy: 0.8520 - val_loss: 0.3529 - val_accuracy: 0.8517\n",
      "Epoch 13/100\n",
      "64092/64092 [==============================] - 199s 3ms/step - loss: 0.3543 - accuracy: 0.8523 - val_loss: 0.3528 - val_accuracy: 0.8514\n",
      "Epoch 14/100\n",
      "64092/64092 [==============================] - 200s 3ms/step - loss: 0.3531 - accuracy: 0.8530 - val_loss: 0.3512 - val_accuracy: 0.8550\n",
      "Epoch 15/100\n",
      "64092/64092 [==============================] - 200s 3ms/step - loss: 0.3520 - accuracy: 0.8536 - val_loss: 0.3497 - val_accuracy: 0.8554\n",
      "Epoch 16/100\n",
      "64092/64092 [==============================] - 200s 3ms/step - loss: 0.3513 - accuracy: 0.8539 - val_loss: 0.3480 - val_accuracy: 0.8549\n",
      "Epoch 17/100\n",
      "64092/64092 [==============================] - 200s 3ms/step - loss: 0.3508 - accuracy: 0.8542 - val_loss: 0.3493 - val_accuracy: 0.8556\n",
      "Epoch 18/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3503 - accuracy: 0.8543 - val_loss: 0.3486 - val_accuracy: 0.8549\n",
      "Epoch 19/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3499 - accuracy: 0.8546 - val_loss: 0.3473 - val_accuracy: 0.8557\n",
      "Epoch 20/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3495 - accuracy: 0.8549 - val_loss: 0.3475 - val_accuracy: 0.8549\n",
      "Epoch 21/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3493 - accuracy: 0.8549 - val_loss: 0.3475 - val_accuracy: 0.8562\n",
      "Epoch 22/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3490 - accuracy: 0.8551 - val_loss: 0.3477 - val_accuracy: 0.8559\n",
      "Epoch 23/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3489 - accuracy: 0.8553 - val_loss: 0.3466 - val_accuracy: 0.8558\n",
      "Epoch 24/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3486 - accuracy: 0.8552 - val_loss: 0.3503 - val_accuracy: 0.8547\n",
      "Epoch 25/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3485 - accuracy: 0.8552 - val_loss: 0.3469 - val_accuracy: 0.8562\n",
      "Epoch 26/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3484 - accuracy: 0.8555 - val_loss: 0.3465 - val_accuracy: 0.8569\n",
      "Epoch 27/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3482 - accuracy: 0.8556 - val_loss: 0.3472 - val_accuracy: 0.8553\n",
      "Epoch 28/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3482 - accuracy: 0.8557 - val_loss: 0.3471 - val_accuracy: 0.8561\n",
      "Epoch 29/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3479 - accuracy: 0.8556 - val_loss: 0.3455 - val_accuracy: 0.8575\n",
      "Epoch 30/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3479 - accuracy: 0.8560 - val_loss: 0.3463 - val_accuracy: 0.8563\n",
      "Epoch 31/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3478 - accuracy: 0.8558 - val_loss: 0.3461 - val_accuracy: 0.8568\n",
      "Epoch 32/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3477 - accuracy: 0.8558 - val_loss: 0.3467 - val_accuracy: 0.8569\n",
      "Epoch 33/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3476 - accuracy: 0.8559 - val_loss: 0.3454 - val_accuracy: 0.8570\n",
      "Epoch 34/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3475 - accuracy: 0.8558 - val_loss: 0.3474 - val_accuracy: 0.8554\n",
      "Epoch 35/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3473 - accuracy: 0.8559 - val_loss: 0.3460 - val_accuracy: 0.8565\n",
      "Epoch 36/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3473 - accuracy: 0.8560 - val_loss: 0.3448 - val_accuracy: 0.8570\n",
      "Epoch 37/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3471 - accuracy: 0.8561 - val_loss: 0.3452 - val_accuracy: 0.8566\n",
      "Epoch 38/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3470 - accuracy: 0.8562 - val_loss: 0.3457 - val_accuracy: 0.8563\n",
      "Epoch 39/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3470 - accuracy: 0.8562 - val_loss: 0.3452 - val_accuracy: 0.8566\n",
      "Epoch 40/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3468 - accuracy: 0.8564 - val_loss: 0.3458 - val_accuracy: 0.8572\n",
      "Epoch 41/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3468 - accuracy: 0.8563 - val_loss: 0.3514 - val_accuracy: 0.8546\n",
      "Epoch 42/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3468 - accuracy: 0.8561 - val_loss: 0.3446 - val_accuracy: 0.8580\n",
      "Epoch 43/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3466 - accuracy: 0.8564 - val_loss: 0.3445 - val_accuracy: 0.8571\n",
      "Epoch 44/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3466 - accuracy: 0.8565 - val_loss: 0.3445 - val_accuracy: 0.8571\n",
      "Epoch 45/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3464 - accuracy: 0.8567 - val_loss: 0.3439 - val_accuracy: 0.8580\n",
      "Epoch 46/100\n",
      "64092/64092 [==============================] - 200s 3ms/step - loss: 0.3463 - accuracy: 0.8565 - val_loss: 0.3466 - val_accuracy: 0.8545\n",
      "Epoch 47/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3463 - accuracy: 0.8566 - val_loss: 0.3458 - val_accuracy: 0.8577\n",
      "Epoch 48/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3463 - accuracy: 0.8567 - val_loss: 0.3443 - val_accuracy: 0.8579\n",
      "Epoch 49/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3462 - accuracy: 0.8567 - val_loss: 0.3458 - val_accuracy: 0.8566\n",
      "Epoch 50/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3460 - accuracy: 0.8566 - val_loss: 0.3441 - val_accuracy: 0.8577\n",
      "Epoch 51/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3460 - accuracy: 0.8567 - val_loss: 0.3455 - val_accuracy: 0.8573\n",
      "Epoch 52/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3460 - accuracy: 0.8568 - val_loss: 0.3455 - val_accuracy: 0.8560\n",
      "Epoch 53/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3458 - accuracy: 0.8568 - val_loss: 0.3456 - val_accuracy: 0.8575\n",
      "Epoch 54/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3458 - accuracy: 0.8568 - val_loss: 0.3480 - val_accuracy: 0.8567\n",
      "Epoch 55/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3457 - accuracy: 0.8569 - val_loss: 0.3446 - val_accuracy: 0.8576\n",
      "Epoch 56/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3457 - accuracy: 0.8570 - val_loss: 0.3495 - val_accuracy: 0.8551\n",
      "Epoch 57/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3456 - accuracy: 0.8571 - val_loss: 0.3453 - val_accuracy: 0.8565\n",
      "Epoch 58/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3455 - accuracy: 0.8572 - val_loss: 0.3462 - val_accuracy: 0.8566\n",
      "Epoch 59/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3455 - accuracy: 0.8571 - val_loss: 0.3440 - val_accuracy: 0.8585\n",
      "Epoch 60/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3455 - accuracy: 0.8570 - val_loss: 0.3453 - val_accuracy: 0.8578\n",
      "Epoch 61/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3454 - accuracy: 0.8573 - val_loss: 0.3446 - val_accuracy: 0.8576\n",
      "Epoch 62/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3454 - accuracy: 0.8571 - val_loss: 0.3436 - val_accuracy: 0.8578\n",
      "Epoch 63/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3454 - accuracy: 0.8570 - val_loss: 0.3454 - val_accuracy: 0.8573\n",
      "Epoch 64/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3453 - accuracy: 0.8574 - val_loss: 0.3489 - val_accuracy: 0.8539\n",
      "Epoch 65/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3453 - accuracy: 0.8572 - val_loss: 0.3449 - val_accuracy: 0.8580\n",
      "Epoch 66/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3453 - accuracy: 0.8572 - val_loss: 0.3452 - val_accuracy: 0.8571\n",
      "Epoch 67/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3451 - accuracy: 0.8572 - val_loss: 0.3455 - val_accuracy: 0.8572\n",
      "Epoch 68/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3451 - accuracy: 0.8574 - val_loss: 0.3447 - val_accuracy: 0.8582\n",
      "Epoch 69/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3451 - accuracy: 0.8574 - val_loss: 0.3443 - val_accuracy: 0.8581\n",
      "Epoch 70/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3450 - accuracy: 0.8573 - val_loss: 0.3443 - val_accuracy: 0.8579\n",
      "Epoch 71/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3449 - accuracy: 0.8574 - val_loss: 0.3433 - val_accuracy: 0.8588\n",
      "Epoch 72/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3448 - accuracy: 0.8573 - val_loss: 0.3487 - val_accuracy: 0.8565\n",
      "Epoch 73/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3449 - accuracy: 0.8574 - val_loss: 0.3446 - val_accuracy: 0.8564\n",
      "Epoch 74/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3448 - accuracy: 0.8574 - val_loss: 0.3454 - val_accuracy: 0.8582\n",
      "Epoch 75/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3446 - accuracy: 0.8573 - val_loss: 0.3458 - val_accuracy: 0.8578\n",
      "Epoch 76/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3447 - accuracy: 0.8575 - val_loss: 0.3452 - val_accuracy: 0.8578\n",
      "Epoch 77/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3447 - accuracy: 0.8573 - val_loss: 0.3435 - val_accuracy: 0.8589\n",
      "Epoch 78/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3445 - accuracy: 0.8577 - val_loss: 0.3476 - val_accuracy: 0.8572\n",
      "Epoch 79/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3446 - accuracy: 0.8576 - val_loss: 0.3460 - val_accuracy: 0.8574\n",
      "Epoch 80/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3445 - accuracy: 0.8576 - val_loss: 0.3462 - val_accuracy: 0.8572\n",
      "Epoch 81/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3444 - accuracy: 0.8575 - val_loss: 0.3440 - val_accuracy: 0.8580\n",
      "Epoch 82/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3443 - accuracy: 0.8578 - val_loss: 0.3436 - val_accuracy: 0.8583\n",
      "Epoch 83/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3444 - accuracy: 0.8576 - val_loss: 0.3441 - val_accuracy: 0.8574\n",
      "Epoch 84/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3443 - accuracy: 0.8575 - val_loss: 0.3436 - val_accuracy: 0.8580\n",
      "Epoch 85/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3442 - accuracy: 0.8576 - val_loss: 0.3457 - val_accuracy: 0.8565\n",
      "Epoch 86/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3441 - accuracy: 0.8575 - val_loss: 0.3446 - val_accuracy: 0.8570\n",
      "Epoch 87/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3441 - accuracy: 0.8578 - val_loss: 0.3453 - val_accuracy: 0.8562\n",
      "Epoch 88/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3440 - accuracy: 0.8578 - val_loss: 0.3435 - val_accuracy: 0.8591\n",
      "Epoch 89/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3439 - accuracy: 0.8579 - val_loss: 0.3434 - val_accuracy: 0.8584\n",
      "Epoch 90/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3439 - accuracy: 0.8578 - val_loss: 0.3459 - val_accuracy: 0.8573\n",
      "Epoch 91/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3440 - accuracy: 0.8578 - val_loss: 0.3445 - val_accuracy: 0.8572\n",
      "Epoch 92/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3438 - accuracy: 0.8576 - val_loss: 0.3457 - val_accuracy: 0.8565\n",
      "Epoch 93/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3437 - accuracy: 0.8579 - val_loss: 0.3443 - val_accuracy: 0.8589\n",
      "Epoch 94/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3437 - accuracy: 0.8580 - val_loss: 0.3427 - val_accuracy: 0.8591\n",
      "Epoch 95/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3436 - accuracy: 0.8579 - val_loss: 0.3435 - val_accuracy: 0.8573\n",
      "Epoch 96/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3435 - accuracy: 0.8579 - val_loss: 0.3445 - val_accuracy: 0.8581\n",
      "Epoch 97/100\n",
      "64092/64092 [==============================] - 193s 3ms/step - loss: 0.3435 - accuracy: 0.8581 - val_loss: 0.3437 - val_accuracy: 0.8588\n",
      "Epoch 98/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3434 - accuracy: 0.8582 - val_loss: 0.3434 - val_accuracy: 0.8584\n",
      "Epoch 99/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3433 - accuracy: 0.8581 - val_loss: 0.3447 - val_accuracy: 0.8568\n",
      "Epoch 100/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3432 - accuracy: 0.8581 - val_loss: 0.3469 - val_accuracy: 0.8555\n",
      "time taken for training :  20037.80631494522\n",
      "time taken for per epoch :  200.3780631494522\n",
      "\n",
      "\n",
      "\n",
      " Test file no :  9\n",
      "Graph ready\n",
      "Number of random walks for 'Train Graph': 93896\n",
      "time taken for training walks :  811.6791958808899\n",
      "time taken for training word2vec :  21.190908670425415\n",
      "time taken for getting node embeddings :  0.00038433074951171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train and x_test are ready\n",
      "Epoch 1/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.4180 - accuracy: 0.8202 - val_loss: 0.4014 - val_accuracy: 0.8297\n",
      "Epoch 2/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3944 - accuracy: 0.8319 - val_loss: 0.3931 - val_accuracy: 0.8314\n",
      "Epoch 3/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3890 - accuracy: 0.8349 - val_loss: 0.3899 - val_accuracy: 0.8354\n",
      "Epoch 4/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3860 - accuracy: 0.8364 - val_loss: 0.3867 - val_accuracy: 0.8352\n",
      "Epoch 5/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3828 - accuracy: 0.8378 - val_loss: 0.3834 - val_accuracy: 0.8378\n",
      "Epoch 6/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3799 - accuracy: 0.8395 - val_loss: 0.3798 - val_accuracy: 0.8394\n",
      "Epoch 7/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3782 - accuracy: 0.8405 - val_loss: 0.3795 - val_accuracy: 0.8414\n",
      "Epoch 8/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3771 - accuracy: 0.8409 - val_loss: 0.3781 - val_accuracy: 0.8413\n",
      "Epoch 9/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3761 - accuracy: 0.8414 - val_loss: 0.3789 - val_accuracy: 0.8418\n",
      "Epoch 10/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3746 - accuracy: 0.8422 - val_loss: 0.3751 - val_accuracy: 0.8419\n",
      "Epoch 11/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3736 - accuracy: 0.8428 - val_loss: 0.3756 - val_accuracy: 0.8429\n",
      "Epoch 12/100\n",
      "64092/64092 [==============================] - 196s 3ms/step - loss: 0.3725 - accuracy: 0.8435 - val_loss: 0.3740 - val_accuracy: 0.8428\n",
      "Epoch 13/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3721 - accuracy: 0.8435 - val_loss: 0.3731 - val_accuracy: 0.8446\n",
      "Epoch 14/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3716 - accuracy: 0.8438 - val_loss: 0.3742 - val_accuracy: 0.8406\n",
      "Epoch 15/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3711 - accuracy: 0.8439 - val_loss: 0.3734 - val_accuracy: 0.8419\n",
      "Epoch 16/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3707 - accuracy: 0.8441 - val_loss: 0.3729 - val_accuracy: 0.8427\n",
      "Epoch 17/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3702 - accuracy: 0.8442 - val_loss: 0.3715 - val_accuracy: 0.8440\n",
      "Epoch 18/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3698 - accuracy: 0.8445 - val_loss: 0.3729 - val_accuracy: 0.8432\n",
      "Epoch 19/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3694 - accuracy: 0.8447 - val_loss: 0.3710 - val_accuracy: 0.8446\n",
      "Epoch 20/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3690 - accuracy: 0.8450 - val_loss: 0.3723 - val_accuracy: 0.8440\n",
      "Epoch 21/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3687 - accuracy: 0.8450 - val_loss: 0.3757 - val_accuracy: 0.8421\n",
      "Epoch 22/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3685 - accuracy: 0.8453 - val_loss: 0.3699 - val_accuracy: 0.8450\n",
      "Epoch 23/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3682 - accuracy: 0.8450 - val_loss: 0.3698 - val_accuracy: 0.8451\n",
      "Epoch 24/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3680 - accuracy: 0.8453 - val_loss: 0.3753 - val_accuracy: 0.8424\n",
      "Epoch 25/100\n",
      "64092/64092 [==============================] - 211s 3ms/step - loss: 0.3678 - accuracy: 0.8456 - val_loss: 0.3690 - val_accuracy: 0.8447\n",
      "Epoch 26/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3676 - accuracy: 0.8454 - val_loss: 0.3702 - val_accuracy: 0.8443\n",
      "Epoch 27/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3675 - accuracy: 0.8456 - val_loss: 0.3721 - val_accuracy: 0.8431\n",
      "Epoch 28/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3674 - accuracy: 0.8459 - val_loss: 0.3685 - val_accuracy: 0.8449\n",
      "Epoch 29/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3673 - accuracy: 0.8457 - val_loss: 0.3686 - val_accuracy: 0.8444\n",
      "Epoch 30/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3671 - accuracy: 0.8458 - val_loss: 0.3729 - val_accuracy: 0.8421\n",
      "Epoch 31/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3670 - accuracy: 0.8461 - val_loss: 0.3683 - val_accuracy: 0.8453\n",
      "Epoch 32/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3669 - accuracy: 0.8460 - val_loss: 0.3695 - val_accuracy: 0.8452\n",
      "Epoch 33/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3668 - accuracy: 0.8459 - val_loss: 0.3696 - val_accuracy: 0.8439\n",
      "Epoch 34/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3669 - accuracy: 0.8460 - val_loss: 0.3695 - val_accuracy: 0.8458\n",
      "Epoch 35/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3666 - accuracy: 0.8462 - val_loss: 0.3703 - val_accuracy: 0.8428\n",
      "Epoch 36/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3666 - accuracy: 0.8460 - val_loss: 0.3800 - val_accuracy: 0.8371\n",
      "Epoch 37/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3665 - accuracy: 0.8463 - val_loss: 0.3711 - val_accuracy: 0.8441\n",
      "Epoch 38/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3665 - accuracy: 0.8463 - val_loss: 0.3700 - val_accuracy: 0.8438\n",
      "Epoch 39/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3663 - accuracy: 0.8465 - val_loss: 0.3680 - val_accuracy: 0.8459\n",
      "Epoch 40/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3663 - accuracy: 0.8464 - val_loss: 0.3686 - val_accuracy: 0.8456\n",
      "Epoch 41/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3663 - accuracy: 0.8464 - val_loss: 0.3689 - val_accuracy: 0.8450\n",
      "Epoch 42/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3662 - accuracy: 0.8466 - val_loss: 0.3699 - val_accuracy: 0.8443\n",
      "Epoch 43/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3661 - accuracy: 0.8465 - val_loss: 0.3681 - val_accuracy: 0.8462\n",
      "Epoch 44/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3661 - accuracy: 0.8467 - val_loss: 0.3683 - val_accuracy: 0.8456\n",
      "Epoch 45/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3661 - accuracy: 0.8464 - val_loss: 0.3682 - val_accuracy: 0.8461\n",
      "Epoch 46/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3660 - accuracy: 0.8465 - val_loss: 0.3714 - val_accuracy: 0.8424\n",
      "Epoch 47/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3660 - accuracy: 0.8466 - val_loss: 0.3689 - val_accuracy: 0.8440\n",
      "Epoch 48/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3659 - accuracy: 0.8467 - val_loss: 0.3713 - val_accuracy: 0.8453\n",
      "Epoch 49/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3658 - accuracy: 0.8466 - val_loss: 0.3693 - val_accuracy: 0.8436\n",
      "Epoch 50/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3658 - accuracy: 0.8467 - val_loss: 0.3707 - val_accuracy: 0.8449\n",
      "Epoch 51/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3658 - accuracy: 0.8466 - val_loss: 0.3691 - val_accuracy: 0.8443\n",
      "Epoch 52/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3657 - accuracy: 0.8466 - val_loss: 0.3679 - val_accuracy: 0.8451\n",
      "Epoch 53/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3657 - accuracy: 0.8467 - val_loss: 0.3688 - val_accuracy: 0.8457\n",
      "Epoch 54/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3657 - accuracy: 0.8466 - val_loss: 0.3696 - val_accuracy: 0.8459\n",
      "Epoch 55/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3656 - accuracy: 0.8466 - val_loss: 0.3706 - val_accuracy: 0.8443\n",
      "Epoch 56/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3656 - accuracy: 0.8469 - val_loss: 0.3680 - val_accuracy: 0.8463\n",
      "Epoch 57/100\n",
      "64092/64092 [==============================] - 200s 3ms/step - loss: 0.3656 - accuracy: 0.8467 - val_loss: 0.3696 - val_accuracy: 0.8468\n",
      "Epoch 58/100\n",
      "64092/64092 [==============================] - 199s 3ms/step - loss: 0.3655 - accuracy: 0.8467 - val_loss: 0.3699 - val_accuracy: 0.8440\n",
      "Epoch 59/100\n",
      "64092/64092 [==============================] - 200s 3ms/step - loss: 0.3656 - accuracy: 0.8471 - val_loss: 0.3723 - val_accuracy: 0.8442\n",
      "Epoch 60/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3654 - accuracy: 0.8467 - val_loss: 0.3694 - val_accuracy: 0.8442\n",
      "Epoch 61/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3655 - accuracy: 0.8468 - val_loss: 0.3678 - val_accuracy: 0.8457\n",
      "Epoch 62/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3655 - accuracy: 0.8470 - val_loss: 0.3734 - val_accuracy: 0.8407\n",
      "Epoch 63/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3655 - accuracy: 0.8466 - val_loss: 0.3703 - val_accuracy: 0.8450\n",
      "Epoch 64/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3654 - accuracy: 0.8468 - val_loss: 0.3681 - val_accuracy: 0.8461\n",
      "Epoch 65/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3654 - accuracy: 0.8468 - val_loss: 0.3678 - val_accuracy: 0.8471\n",
      "Epoch 66/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3653 - accuracy: 0.8468 - val_loss: 0.3726 - val_accuracy: 0.8438\n",
      "Epoch 67/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3653 - accuracy: 0.8470 - val_loss: 0.3684 - val_accuracy: 0.8453\n",
      "Epoch 68/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3652 - accuracy: 0.8467 - val_loss: 0.3733 - val_accuracy: 0.8426\n",
      "Epoch 69/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3653 - accuracy: 0.8470 - val_loss: 0.3688 - val_accuracy: 0.8453\n",
      "Epoch 70/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3652 - accuracy: 0.8468 - val_loss: 0.3688 - val_accuracy: 0.8456\n",
      "Epoch 71/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3652 - accuracy: 0.8470 - val_loss: 0.3681 - val_accuracy: 0.8447\n",
      "Epoch 72/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3652 - accuracy: 0.8468 - val_loss: 0.3692 - val_accuracy: 0.8446\n",
      "Epoch 73/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3652 - accuracy: 0.8470 - val_loss: 0.3686 - val_accuracy: 0.8457\n",
      "Epoch 74/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3652 - accuracy: 0.8467 - val_loss: 0.3693 - val_accuracy: 0.8453\n",
      "Epoch 75/100\n",
      "64092/64092 [==============================] - 191s 3ms/step - loss: 0.3651 - accuracy: 0.8469 - val_loss: 0.3685 - val_accuracy: 0.8453\n",
      "Epoch 76/100\n",
      "64092/64092 [==============================] - 192s 3ms/step - loss: 0.3651 - accuracy: 0.8468 - val_loss: 0.3694 - val_accuracy: 0.8435\n",
      "Epoch 77/100\n",
      "64092/64092 [==============================] - 195s 3ms/step - loss: 0.3651 - accuracy: 0.8468 - val_loss: 0.3684 - val_accuracy: 0.8456\n",
      "Epoch 78/100\n",
      "64092/64092 [==============================] - 197s 3ms/step - loss: 0.3651 - accuracy: 0.8469 - val_loss: 0.3703 - val_accuracy: 0.8431\n",
      "Epoch 79/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3651 - accuracy: 0.8469 - val_loss: 0.3685 - val_accuracy: 0.8454\n",
      "Epoch 80/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3651 - accuracy: 0.8469 - val_loss: 0.3687 - val_accuracy: 0.8448\n",
      "Epoch 81/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3651 - accuracy: 0.8469 - val_loss: 0.3684 - val_accuracy: 0.8467\n",
      "Epoch 82/100\n",
      "64092/64092 [==============================] - 216s 3ms/step - loss: 0.3651 - accuracy: 0.8471 - val_loss: 0.3698 - val_accuracy: 0.8446\n",
      "Epoch 83/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3650 - accuracy: 0.8471 - val_loss: 0.3680 - val_accuracy: 0.8466\n",
      "Epoch 84/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3650 - accuracy: 0.8468 - val_loss: 0.3694 - val_accuracy: 0.8452\n",
      "Epoch 85/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3650 - accuracy: 0.8470 - val_loss: 0.3692 - val_accuracy: 0.8452\n",
      "Epoch 86/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3650 - accuracy: 0.8469 - val_loss: 0.3733 - val_accuracy: 0.8413\n",
      "Epoch 87/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3650 - accuracy: 0.8470 - val_loss: 0.3677 - val_accuracy: 0.8462\n",
      "Epoch 88/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3650 - accuracy: 0.8470 - val_loss: 0.3699 - val_accuracy: 0.8435\n",
      "Epoch 89/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3649 - accuracy: 0.8470 - val_loss: 0.3685 - val_accuracy: 0.8454\n",
      "Epoch 90/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3649 - accuracy: 0.8470 - val_loss: 0.3687 - val_accuracy: 0.8451\n",
      "Epoch 91/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3648 - accuracy: 0.8469 - val_loss: 0.3702 - val_accuracy: 0.8444\n",
      "Epoch 92/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3650 - accuracy: 0.8470 - val_loss: 0.3695 - val_accuracy: 0.8461\n",
      "Epoch 93/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3649 - accuracy: 0.8469 - val_loss: 0.3694 - val_accuracy: 0.8464\n",
      "Epoch 94/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3649 - accuracy: 0.8471 - val_loss: 0.3714 - val_accuracy: 0.8448\n",
      "Epoch 95/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3648 - accuracy: 0.8471 - val_loss: 0.3709 - val_accuracy: 0.8430\n",
      "Epoch 96/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3648 - accuracy: 0.8473 - val_loss: 0.3677 - val_accuracy: 0.8462\n",
      "Epoch 97/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3649 - accuracy: 0.8469 - val_loss: 0.3702 - val_accuracy: 0.8435\n",
      "Epoch 98/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3649 - accuracy: 0.8471 - val_loss: 0.3718 - val_accuracy: 0.8450\n",
      "Epoch 99/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3649 - accuracy: 0.8469 - val_loss: 0.3676 - val_accuracy: 0.8466\n",
      "Epoch 100/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3647 - accuracy: 0.8473 - val_loss: 0.3673 - val_accuracy: 0.8468\n",
      "time taken for training :  20385.99146080017\n",
      "time taken for per epoch :  203.8599146080017\n",
      "\n",
      "\n",
      "\n",
      " Test file no :  10\n",
      "Graph ready\n",
      "Number of random walks for 'Train Graph': 93896\n",
      "time taken for training walks :  1189.6568775177002\n",
      "time taken for training word2vec :  22.403404712677002\n",
      "time taken for getting node embeddings :  0.0004112720489501953\n",
      "x_train and x_test are ready\n",
      "Epoch 1/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.4063 - accuracy: 0.8272 - val_loss: 0.3849 - val_accuracy: 0.8384\n",
      "Epoch 2/100\n",
      "64092/64092 [==============================] - 213s 3ms/step - loss: 0.3780 - accuracy: 0.8429 - val_loss: 0.3763 - val_accuracy: 0.8443\n",
      "Epoch 3/100\n",
      "64092/64092 [==============================] - 212s 3ms/step - loss: 0.3716 - accuracy: 0.8460 - val_loss: 0.3706 - val_accuracy: 0.8457\n",
      "Epoch 4/100\n",
      "64092/64092 [==============================] - 210s 3ms/step - loss: 0.3676 - accuracy: 0.8480 - val_loss: 0.3672 - val_accuracy: 0.8469\n",
      "Epoch 5/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3655 - accuracy: 0.8491 - val_loss: 0.3672 - val_accuracy: 0.8473\n",
      "Epoch 6/100\n",
      "64092/64092 [==============================] - 189s 3ms/step - loss: 0.3639 - accuracy: 0.8497 - val_loss: 0.3653 - val_accuracy: 0.8487\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64092/64092 [==============================] - 189s 3ms/step - loss: 0.3627 - accuracy: 0.8507 - val_loss: 0.3637 - val_accuracy: 0.8494\n",
      "Epoch 8/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3617 - accuracy: 0.8509 - val_loss: 0.3611 - val_accuracy: 0.8504\n",
      "Epoch 9/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3609 - accuracy: 0.8510 - val_loss: 0.3655 - val_accuracy: 0.8484\n",
      "Epoch 10/100\n",
      "64092/64092 [==============================] - 189s 3ms/step - loss: 0.3603 - accuracy: 0.8515 - val_loss: 0.3616 - val_accuracy: 0.8493\n",
      "Epoch 11/100\n",
      "64092/64092 [==============================] - 189s 3ms/step - loss: 0.3597 - accuracy: 0.8515 - val_loss: 0.3601 - val_accuracy: 0.8510\n",
      "Epoch 12/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3591 - accuracy: 0.8517 - val_loss: 0.3596 - val_accuracy: 0.8499\n",
      "Epoch 13/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3587 - accuracy: 0.8521 - val_loss: 0.3600 - val_accuracy: 0.8501\n",
      "Epoch 14/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3583 - accuracy: 0.8524 - val_loss: 0.3603 - val_accuracy: 0.8509\n",
      "Epoch 15/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3580 - accuracy: 0.8524 - val_loss: 0.3604 - val_accuracy: 0.8497\n",
      "Epoch 16/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3578 - accuracy: 0.8525 - val_loss: 0.3615 - val_accuracy: 0.8479\n",
      "Epoch 17/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3576 - accuracy: 0.8526 - val_loss: 0.3601 - val_accuracy: 0.8498\n",
      "Epoch 18/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3573 - accuracy: 0.8525 - val_loss: 0.3591 - val_accuracy: 0.8501\n",
      "Epoch 19/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3571 - accuracy: 0.8529 - val_loss: 0.3582 - val_accuracy: 0.8504\n",
      "Epoch 20/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3569 - accuracy: 0.8529 - val_loss: 0.3596 - val_accuracy: 0.8497\n",
      "Epoch 21/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3567 - accuracy: 0.8531 - val_loss: 0.3602 - val_accuracy: 0.8497\n",
      "Epoch 22/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3565 - accuracy: 0.8531 - val_loss: 0.3597 - val_accuracy: 0.8494\n",
      "Epoch 23/100\n",
      "64092/64092 [==============================] - 189s 3ms/step - loss: 0.3564 - accuracy: 0.8534 - val_loss: 0.3573 - val_accuracy: 0.8511\n",
      "Epoch 24/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3563 - accuracy: 0.8535 - val_loss: 0.3608 - val_accuracy: 0.8486\n",
      "Epoch 25/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3560 - accuracy: 0.8533 - val_loss: 0.3574 - val_accuracy: 0.8520\n",
      "Epoch 26/100\n",
      "64092/64092 [==============================] - 194s 3ms/step - loss: 0.3559 - accuracy: 0.8533 - val_loss: 0.3595 - val_accuracy: 0.8498\n",
      "Epoch 27/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3557 - accuracy: 0.8534 - val_loss: 0.3592 - val_accuracy: 0.8496\n",
      "Epoch 28/100\n",
      "64092/64092 [==============================] - 218s 3ms/step - loss: 0.3557 - accuracy: 0.8534 - val_loss: 0.3569 - val_accuracy: 0.8519\n",
      "Epoch 29/100\n",
      "64092/64092 [==============================] - 219s 3ms/step - loss: 0.3555 - accuracy: 0.8536 - val_loss: 0.3581 - val_accuracy: 0.8522\n",
      "Epoch 30/100\n",
      "64092/64092 [==============================] - 220s 3ms/step - loss: 0.3554 - accuracy: 0.8537 - val_loss: 0.3595 - val_accuracy: 0.8501\n",
      "Epoch 31/100\n",
      "64092/64092 [==============================] - 223s 3ms/step - loss: 0.3553 - accuracy: 0.8539 - val_loss: 0.3598 - val_accuracy: 0.8486\n",
      "Epoch 32/100\n",
      "64092/64092 [==============================] - 220s 3ms/step - loss: 0.3552 - accuracy: 0.8539 - val_loss: 0.3589 - val_accuracy: 0.8515\n",
      "Epoch 33/100\n",
      "64092/64092 [==============================] - 220s 3ms/step - loss: 0.3551 - accuracy: 0.8538 - val_loss: 0.3590 - val_accuracy: 0.8524\n",
      "Epoch 34/100\n",
      "64092/64092 [==============================] - 220s 3ms/step - loss: 0.3549 - accuracy: 0.8539 - val_loss: 0.3580 - val_accuracy: 0.8508\n",
      "Epoch 35/100\n",
      "64092/64092 [==============================] - 219s 3ms/step - loss: 0.3548 - accuracy: 0.8539 - val_loss: 0.3571 - val_accuracy: 0.8526\n",
      "Epoch 36/100\n",
      "64092/64092 [==============================] - 218s 3ms/step - loss: 0.3547 - accuracy: 0.8539 - val_loss: 0.3586 - val_accuracy: 0.8512\n",
      "Epoch 37/100\n",
      "64092/64092 [==============================] - 219s 3ms/step - loss: 0.3546 - accuracy: 0.8540 - val_loss: 0.3572 - val_accuracy: 0.8516\n",
      "Epoch 38/100\n",
      "64092/64092 [==============================] - 218s 3ms/step - loss: 0.3546 - accuracy: 0.8541 - val_loss: 0.3570 - val_accuracy: 0.8530\n",
      "Epoch 39/100\n",
      "64092/64092 [==============================] - 217s 3ms/step - loss: 0.3546 - accuracy: 0.8541 - val_loss: 0.3580 - val_accuracy: 0.8522\n",
      "Epoch 40/100\n",
      "64092/64092 [==============================] - 216s 3ms/step - loss: 0.3545 - accuracy: 0.8540 - val_loss: 0.3597 - val_accuracy: 0.8489\n",
      "Epoch 41/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3544 - accuracy: 0.8541 - val_loss: 0.3574 - val_accuracy: 0.8527\n",
      "Epoch 42/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3543 - accuracy: 0.8542 - val_loss: 0.3577 - val_accuracy: 0.8519\n",
      "Epoch 43/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3543 - accuracy: 0.8543 - val_loss: 0.3563 - val_accuracy: 0.8523\n",
      "Epoch 44/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3543 - accuracy: 0.8542 - val_loss: 0.3583 - val_accuracy: 0.8516\n",
      "Epoch 45/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3542 - accuracy: 0.8543 - val_loss: 0.3579 - val_accuracy: 0.8519\n",
      "Epoch 46/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3541 - accuracy: 0.8542 - val_loss: 0.3561 - val_accuracy: 0.8528\n",
      "Epoch 47/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3540 - accuracy: 0.8543 - val_loss: 0.3609 - val_accuracy: 0.8499\n",
      "Epoch 48/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3539 - accuracy: 0.8544 - val_loss: 0.3600 - val_accuracy: 0.8491\n",
      "Epoch 49/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3539 - accuracy: 0.8543 - val_loss: 0.3564 - val_accuracy: 0.8519\n",
      "Epoch 50/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3539 - accuracy: 0.8543 - val_loss: 0.3562 - val_accuracy: 0.8520\n",
      "Epoch 51/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3538 - accuracy: 0.8542 - val_loss: 0.3602 - val_accuracy: 0.8500\n",
      "Epoch 52/100\n",
      "64092/64092 [==============================] - 216s 3ms/step - loss: 0.3538 - accuracy: 0.8543 - val_loss: 0.3573 - val_accuracy: 0.8518\n",
      "Epoch 53/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3538 - accuracy: 0.8545 - val_loss: 0.3573 - val_accuracy: 0.8526\n",
      "Epoch 54/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3536 - accuracy: 0.8543 - val_loss: 0.3582 - val_accuracy: 0.8517\n",
      "Epoch 55/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3537 - accuracy: 0.8544 - val_loss: 0.3570 - val_accuracy: 0.8522\n",
      "Epoch 56/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3537 - accuracy: 0.8543 - val_loss: 0.3575 - val_accuracy: 0.8524\n",
      "Epoch 57/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3536 - accuracy: 0.8544 - val_loss: 0.3574 - val_accuracy: 0.8511\n",
      "Epoch 58/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3536 - accuracy: 0.8544 - val_loss: 0.3561 - val_accuracy: 0.8533\n",
      "Epoch 59/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3535 - accuracy: 0.8544 - val_loss: 0.3570 - val_accuracy: 0.8529\n",
      "Epoch 60/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3535 - accuracy: 0.8545 - val_loss: 0.3555 - val_accuracy: 0.8535\n",
      "Epoch 61/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3534 - accuracy: 0.8546 - val_loss: 0.3585 - val_accuracy: 0.8506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3535 - accuracy: 0.8545 - val_loss: 0.3557 - val_accuracy: 0.8529\n",
      "Epoch 63/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3534 - accuracy: 0.8543 - val_loss: 0.3567 - val_accuracy: 0.8527\n",
      "Epoch 64/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3534 - accuracy: 0.8543 - val_loss: 0.3592 - val_accuracy: 0.8519\n",
      "Epoch 65/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3534 - accuracy: 0.8544 - val_loss: 0.3563 - val_accuracy: 0.8519\n",
      "Epoch 66/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3534 - accuracy: 0.8545 - val_loss: 0.3558 - val_accuracy: 0.8527\n",
      "Epoch 67/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3533 - accuracy: 0.8546 - val_loss: 0.3569 - val_accuracy: 0.8521\n",
      "Epoch 68/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3533 - accuracy: 0.8543 - val_loss: 0.3573 - val_accuracy: 0.8527\n",
      "Epoch 69/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3533 - accuracy: 0.8544 - val_loss: 0.3563 - val_accuracy: 0.8526\n",
      "Epoch 70/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3532 - accuracy: 0.8547 - val_loss: 0.3566 - val_accuracy: 0.8530\n",
      "Epoch 71/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3532 - accuracy: 0.8544 - val_loss: 0.3585 - val_accuracy: 0.8506\n",
      "Epoch 72/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3532 - accuracy: 0.8546 - val_loss: 0.3568 - val_accuracy: 0.8525\n",
      "Epoch 73/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3532 - accuracy: 0.8543 - val_loss: 0.3584 - val_accuracy: 0.8505\n",
      "Epoch 74/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3531 - accuracy: 0.8545 - val_loss: 0.3570 - val_accuracy: 0.8525\n",
      "Epoch 75/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3531 - accuracy: 0.8546 - val_loss: 0.3578 - val_accuracy: 0.8520\n",
      "Epoch 76/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3530 - accuracy: 0.8546 - val_loss: 0.3560 - val_accuracy: 0.8523\n",
      "Epoch 77/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3531 - accuracy: 0.8544 - val_loss: 0.3562 - val_accuracy: 0.8521\n",
      "Epoch 78/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3530 - accuracy: 0.8545 - val_loss: 0.3646 - val_accuracy: 0.8489\n",
      "Epoch 79/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3530 - accuracy: 0.8546 - val_loss: 0.3562 - val_accuracy: 0.8519\n",
      "Epoch 80/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3530 - accuracy: 0.8547 - val_loss: 0.3547 - val_accuracy: 0.8534\n",
      "Epoch 81/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3530 - accuracy: 0.8548 - val_loss: 0.3574 - val_accuracy: 0.8508\n",
      "Epoch 82/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3529 - accuracy: 0.8547 - val_loss: 0.3561 - val_accuracy: 0.8517\n",
      "Epoch 83/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3529 - accuracy: 0.8547 - val_loss: 0.3577 - val_accuracy: 0.8518\n",
      "Epoch 84/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3529 - accuracy: 0.8548 - val_loss: 0.3598 - val_accuracy: 0.8518\n",
      "Epoch 85/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3529 - accuracy: 0.8548 - val_loss: 0.3595 - val_accuracy: 0.8514\n",
      "Epoch 86/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3529 - accuracy: 0.8546 - val_loss: 0.3566 - val_accuracy: 0.8531\n",
      "Epoch 87/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3529 - accuracy: 0.8546 - val_loss: 0.3561 - val_accuracy: 0.8520\n",
      "Epoch 88/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3529 - accuracy: 0.8545 - val_loss: 0.3556 - val_accuracy: 0.8526\n",
      "Epoch 89/100\n",
      "64092/64092 [==============================] - 212s 3ms/step - loss: 0.3529 - accuracy: 0.8546 - val_loss: 0.3576 - val_accuracy: 0.8529\n",
      "Epoch 90/100\n",
      "64092/64092 [==============================] - 211s 3ms/step - loss: 0.3528 - accuracy: 0.8545 - val_loss: 0.3569 - val_accuracy: 0.8519\n",
      "Epoch 91/100\n",
      "64092/64092 [==============================] - 209s 3ms/step - loss: 0.3528 - accuracy: 0.8547 - val_loss: 0.3570 - val_accuracy: 0.8513\n",
      "Epoch 92/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3528 - accuracy: 0.8546 - val_loss: 0.3576 - val_accuracy: 0.8537\n",
      "Epoch 93/100\n",
      "64092/64092 [==============================] - 208s 3ms/step - loss: 0.3528 - accuracy: 0.8547 - val_loss: 0.3556 - val_accuracy: 0.8532\n",
      "Epoch 94/100\n",
      "64092/64092 [==============================] - 210s 3ms/step - loss: 0.3528 - accuracy: 0.8545 - val_loss: 0.3552 - val_accuracy: 0.8534\n",
      "Epoch 95/100\n",
      "64092/64092 [==============================] - 211s 3ms/step - loss: 0.3528 - accuracy: 0.8546 - val_loss: 0.3557 - val_accuracy: 0.8532\n",
      "Epoch 96/100\n",
      "64092/64092 [==============================] - 213s 3ms/step - loss: 0.3528 - accuracy: 0.8547 - val_loss: 0.3550 - val_accuracy: 0.8529\n",
      "Epoch 97/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3526 - accuracy: 0.8548 - val_loss: 0.3566 - val_accuracy: 0.8532\n",
      "Epoch 98/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3526 - accuracy: 0.8546 - val_loss: 0.3574 - val_accuracy: 0.8507\n",
      "Epoch 99/100\n",
      "64092/64092 [==============================] - 211s 3ms/step - loss: 0.3527 - accuracy: 0.8548 - val_loss: 0.3574 - val_accuracy: 0.8518\n",
      "Epoch 100/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3526 - accuracy: 0.8547 - val_loss: 0.3567 - val_accuracy: 0.8522\n",
      "time taken for training :  20892.270640850067\n",
      "time taken for per epoch :  208.92270640850066\n"
     ]
    }
   ],
   "source": [
    "for split_no in range(1,11,1):\n",
    "    test_file_no = split_no\n",
    "    print(\"\\n\\n\\n Test file no : \",test_file_no)\n",
    "    \n",
    "    #creating training and testing dataset\n",
    "    train_df = pd.DataFrame()\n",
    "    for i in range(1,11,1):\n",
    "        if i != test_file_no:\n",
    "            df = pd.read_csv(dir_path+\"/WSJ_positive_edges_split_\"+str(i)+\".csv\") \n",
    "            train_df = train_df.append(df, ignore_index=True)\n",
    "            del df\n",
    "        else:\n",
    "            test_df = pd.read_csv(dir_path+\"/WSJ_positive_edges_split_\"+str(i)+\".csv\")\n",
    "            neg_df = pd.read_csv(dir_path+\"/WSJ_negative_edges_split_\"+str(i)+\".csv\")\n",
    "            test_df = test_df.append(neg_df, ignore_index=True)\n",
    "            del neg_df\n",
    "    #converting to StellarGraph\n",
    "    train_df.rename(columns = {'src':'source','dest':'target'}, inplace = True)\n",
    "    G = StellarGraph({\"entity\": nodes_entity, \"user\": nodes_users, \"events\": nodes_events},edges=train_df)\n",
    "    print(\"Graph ready\")\n",
    "    \n",
    "    #training walks\n",
    "    curr = time.time()\n",
    "    rw = UniformRandomMetaPathWalk(G)\n",
    "    walks = rw.run(\n",
    "        G.nodes(), n=num_walks, length=walk_length, metapaths=user_metapaths\n",
    "    )\n",
    "    print(f\"Number of random walks for 'Train Graph': {len(walks)}\")\n",
    "\n",
    "    timetaken = time.time()-curr\n",
    "    print(\"time taken for training walks : \",timetaken)\n",
    "    \n",
    "    #training word2vec\n",
    "    curr = time.time()\n",
    "    mdl = Word2Vec(\n",
    "            walks,\n",
    "            vector_size=dimensions,\n",
    "            window=context_window_size,\n",
    "            min_count=0,\n",
    "            sg=1,\n",
    "            workers=workers\n",
    "        )\n",
    "    timetaken = time.time()-curr\n",
    "    print(\"time taken for training word2vec : \",timetaken)\n",
    "    mdl.save(\"my_\"+str(dbname)+\"_metapath2V_node_embedding_model_\"+str(test_file_no)+\".model\")\n",
    "    \n",
    "    #calculating node features\n",
    "    curr = time.time()\n",
    "    node_ids = mdl.wv.index_to_key  # list of node IDs\n",
    "    node_embeddings = (\n",
    "        mdl.wv.vectors\n",
    "    )\n",
    "    timetaken = time.time()-curr\n",
    "    print(\"time taken for getting node embeddings : \",timetaken)\n",
    "    \n",
    "    #creating training data\n",
    "    train_df = pd.DataFrame()\n",
    "    for i in range(1,11,1):\n",
    "        if i != test_file_no:\n",
    "            df = pd.read_csv(dir_path+\"/WSJ_positive_edges_split_\"+str(i)+\".csv\") \n",
    "            train_df = train_df.append(df, ignore_index=True)\n",
    "            df = pd.read_csv(dir_path+\"/WSJ_negative_edges_split_\"+str(i)+\".csv\")\n",
    "            train_df = train_df.append(df, ignore_index=True)\n",
    "            del df\n",
    "    train_df = train_df.drop(['layer', 'weight',\"sign\"], axis=1)\n",
    "    train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "    train_df.loc[train_df['label'] == -1, \"label\"] = 0\n",
    "    # creating x_train\n",
    "    X_train = [(mdl.wv.get_vector(node_ids.index(train_df['src'][i])) + mdl.wv.get_vector(node_ids.index(train_df['dest'][i]))) for i in train_df.index]\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(train_df['label'])\n",
    "    del train_df\n",
    "    \n",
    "    #preparing x_test data\n",
    "    # creating x_test\n",
    "    #test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "    #test_df.loc[test_df['label'] == -1, \"label\"] = 0\n",
    "    #X_test = [(mdl.wv.get_vector(node_ids.index(test_df['src'][i])) + mdl.wv.get_vector(node_ids.index(test_df['dest'][i]))) for i in test_df.index]\n",
    "    #pickle.dump(X_test,open(\"metapath2v_\"+str(dbname)+\"_X_test_whole_\"+str(test_file_no)+\".csv\",\"wb\"))\n",
    "    #X_test = np.array(X_test)\n",
    "    #y_test = list(test_df['label'])\n",
    "    del test_df\n",
    "    \n",
    "    print(\"x_train and x_test are ready\")\n",
    "    # creating keras model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu')) # Add an input shape! (features,)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    curr = time.time()\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, validation_split=0.10, epochs=epochs, batch_size=16,verbose=1)\n",
    "\n",
    "    timetaken = time.time()-curr\n",
    "    print(\"time taken for training : \",timetaken)\n",
    "    print(\"time taken for per epoch : \",timetaken/epochs)\n",
    "    \n",
    "    model.save(\"my_\"+str(dbname)+\"_METAPATH2V_model_\"+str(test_file_no)+\".keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84da011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0849dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4464a26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f007428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f39cf0e0",
   "metadata": {},
   "source": [
    "# rough code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f81faa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"WSJ split data files\"\n",
    "test_file_no = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce292eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-562bfdb627f2>:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-4-562bfdb627f2>:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-4-562bfdb627f2>:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-4-562bfdb627f2>:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-4-562bfdb627f2>:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-4-562bfdb627f2>:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-4-562bfdb627f2>:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-4-562bfdb627f2>:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-4-562bfdb627f2>:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame()\n",
    "for i in range(1,11,1):\n",
    "    if i != test_file_no:\n",
    "        df = pd.read_csv(dir_path+\"/WSJ_positive_edges_split_\"+str(i)+\".csv\") \n",
    "        train_df = train_df.append(df, ignore_index=True)\n",
    "        del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09f2059b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dest</th>\n",
       "      <th>layer</th>\n",
       "      <th>weight</th>\n",
       "      <th>sign</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5046</td>\n",
       "      <td>8395</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100036</td>\n",
       "      <td>103501</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100670</td>\n",
       "      <td>102593</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>870</td>\n",
       "      <td>5764</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5036</td>\n",
       "      <td>6048</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569695</th>\n",
       "      <td>100442</td>\n",
       "      <td>100451</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569696</th>\n",
       "      <td>5338</td>\n",
       "      <td>8134</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569697</th>\n",
       "      <td>100075</td>\n",
       "      <td>100086</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569698</th>\n",
       "      <td>5082</td>\n",
       "      <td>5400</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569699</th>\n",
       "      <td>101385</td>\n",
       "      <td>103235</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569700 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           src    dest  layer  weight  sign  label\n",
       "0         5046    8395     12       2  -2.0      1\n",
       "1       100036  103501      3      27  -2.0      1\n",
       "2       100670  102593      3       2  -2.0      1\n",
       "3          870    5764      2      33  -1.0      1\n",
       "4         5036    6048     12       7  -2.0      1\n",
       "...        ...     ...    ...     ...   ...    ...\n",
       "569695  100442  100451      3       4  -2.0      1\n",
       "569696    5338    8134     12       3  -2.0      1\n",
       "569697  100075  100086      3       5  -2.0      1\n",
       "569698    5082    5400     12       2  -2.0      1\n",
       "569699  101385  103235      3       3  -2.0      1\n",
       "\n",
       "[569700 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55171c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-2f4674388914>:3: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  s1.append(s2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "0    4\n",
       "1    5\n",
       "2    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = pd.Series([1, 2, 3])\n",
    "s2 = pd.Series([4, 5, 6])\n",
    "s1.append(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd881dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-4952a3502677>:1: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_nodes = train_df[\"src\"].append(train_df[\"dest\"]).unique()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8536"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_nodes = train_df[\"src\"].append(train_df[\"dest\"]).unique()\n",
    "len(all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "133afbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5046, 5036, 5143, ..., 8168, 7908, 7930])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_nodes = pd.Series(list(all_nodes))\n",
    "#all_nodes[all_nodes.between(5000, 100000)].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0322c06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_entity = all_nodes[all_nodes.between(5000, 99999)].unique()\n",
    "nodes_users = all_nodes[all_nodes>=100000].unique()\n",
    "nodes_events = all_nodes[all_nodes<5000].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "707b09ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_entity = pd.DataFrame(index=list(nodes_entity))\n",
    "nodes_users = pd.DataFrame(index=list(nodes_users))\n",
    "nodes_events = pd.DataFrame(index=list(nodes_events))\n",
    "#train_df.rename(columns = {'src':'source','dest':'target'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa8d8202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 8536, Edges: 569700\n",
      "\n",
      " Node types:\n",
      "  entity: [4857]\n",
      "    Features: none\n",
      "    Edge types: entity-default->entity, entity-default->events, entity-default->user\n",
      "  user: [3651]\n",
      "    Features: none\n",
      "    Edge types: user-default->entity, user-default->events, user-default->user\n",
      "  events: [28]\n",
      "    Features: none\n",
      "    Edge types: events-default->entity, events-default->events, events-default->user\n",
      "\n",
      " Edge types:\n",
      "    user-default->user: [422780]\n",
      "        Weights: range=[1, 2226], mean=12.8169, std=29.887\n",
      "        Features: float32 vector, length 3\n",
      "    entity-default->entity: [119500]\n",
      "        Weights: range=[2, 2973], mean=8.03984, std=36.8979\n",
      "        Features: float32 vector, length 3\n",
      "    entity-default->user: [16955]\n",
      "        Weights: range=[1, 92], mean=2.71525, std=3.50289\n",
      "        Features: float32 vector, length 3\n",
      "    entity-default->events: [5570]\n",
      "        Weights: range=[1, 325], mean=3.8088, std=12.8579\n",
      "        Features: float32 vector, length 3\n",
      "    events-default->user: [4852]\n",
      "        Weights: range=[1, 328], mean=9.48248, std=16.5644\n",
      "        Features: float32 vector, length 3\n",
      "    events-default->events: [43]\n",
      "        Weights: range=[6, 87093], mean=4638.02, std=14798\n",
      "        Features: float32 vector, length 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "G = StellarGraph({\"entity\": nodes_entity, \"user\": nodes_users, \"events\": nodes_events},edges=train_df)\n",
    "print(G.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afda75c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dimensions = 128\n",
    "num_walks = 1\n",
    "walk_length = 100\n",
    "context_window_size = 10\n",
    "num_iter = 1\n",
    "workers = multiprocessing.cpu_count()\n",
    "user_metapaths = [\n",
    "    #entity metapaths\n",
    "    [\"entity\",\"entity\"],\n",
    "    [\"entity\", \"events\", \"entity\"],\n",
    "    [\"entity\", \"events\", \"entity\", \"entity\"],\n",
    "    [\"entity\", \"events\", \"events\", \"entity\"],\n",
    "    [\"entity\", \"user\", \"entity\"],\n",
    "    [\"entity\", \"user\", \"entity\", \"entity\"],\n",
    "    [\"entity\", \"user\", \"user\", \"entity\"],\n",
    "    [\"entity\", \"user\", \"events\", \"entity\"],\n",
    "    [\"entity\", \"events\", \"user\", \"entity\"],\n",
    "    [\"entity\", \"user\", \"events\", \"entity\", \"entity\"],\n",
    "    [\"entity\", \"events\", \"user\", \"entity\", \"entity\"],\n",
    "    #events metapath\n",
    "    [\"events\", \"events\"],\n",
    "    [\"events\", \"entity\", \"events\"],\n",
    "    [\"events\", \"entity\", \"events\", \"events\"],\n",
    "    [\"events\", \"entity\", \"entity\", \"events\"],\n",
    "    [\"events\", \"user\", \"events\"],\n",
    "    [\"events\", \"user\", \"events\", \"events\"],\n",
    "    [\"events\", \"user\", \"user\", \"events\"],\n",
    "    [\"events\", \"entity\", \"user\", \"events\"],\n",
    "    [\"events\", \"user\", \"entity\", \"events\"],\n",
    "    [\"events\", \"entity\", \"user\", \"events\", \"events\"],\n",
    "    [\"events\", \"user\", \"entity\", \"events\", \"events\"],\n",
    "    #user metapath\n",
    "    [\"user\", \"user\"],\n",
    "    [\"user\", \"events\", \"user\"],\n",
    "    [\"user\", \"events\", \"user\", \"user\"],\n",
    "    [\"user\", \"events\", \"events\", \"user\"],\n",
    "    [\"user\", \"entity\", \"user\"],\n",
    "    [\"user\", \"entity\", \"user\", \"user\"],\n",
    "    [\"user\", \"entity\", \"entity\", \"user\"],\n",
    "    [\"user\", \"entity\", \"events\", \"user\"],\n",
    "    [\"user\", \"events\", \"entity\", \"user\"],\n",
    "    [\"user\", \"entity\", \"events\", \"user\", \"user\"],\n",
    "    [\"user\", \"events\", \"entity\", \"user\", \"user\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb35924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph.data import UniformRandomMetaPathWalk\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "def metapath2vec_embedding(graph, name):\n",
    "    rw = UniformRandomMetaPathWalk(graph)\n",
    "    walks = rw.run(\n",
    "        graph.nodes(), n=num_walks, length=walk_length, metapaths=user_metapaths\n",
    "    )\n",
    "    print(f\"Number of random walks for '{name}': {len(walks)}\")\n",
    "\n",
    "    model = Word2Vec(\n",
    "        walks,\n",
    "        size=dimensions,\n",
    "        window=context_window_size,\n",
    "        min_count=0,\n",
    "        sg=1,\n",
    "        workers=workers,\n",
    "        iter=num_iter,\n",
    "    )\n",
    "\n",
    "    def get_embedding(u):\n",
    "        return model.wv[u]\n",
    "\n",
    "    return get_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b3aaa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of random walks for 'Train Graph': 93896\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-58e8367f516d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetapath2vec_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Train Graph\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-33744dbca91d>\u001b[0m in \u001b[0;36mmetapath2vec_embedding\u001b[0;34m(graph, name)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Number of random walks for '{name}': {len(walks)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     model = Word2Vec(\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mwalks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'size'"
     ]
    }
   ],
   "source": [
    "embedding_train = metapath2vec_embedding(G, \"Train Graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9af8c7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of random walks for 'Train Graph': 93896\n",
      "time taken for training walks :  1362.9943737983704\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "curr = time.time()\n",
    "rw = UniformRandomMetaPathWalk(G)\n",
    "walks = rw.run(\n",
    "    G.nodes(), n=num_walks, length=walk_length, metapaths=user_metapaths\n",
    ")\n",
    "print(f\"Number of random walks for 'Train Graph': {len(walks)}\")\n",
    "\n",
    "timetaken = time.time()-curr\n",
    "print(\"time taken for training walks : \",timetaken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2facacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( walks, open( \"walks_m2v_1.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0bb563a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for training word2vec :  51.37902116775513\n"
     ]
    }
   ],
   "source": [
    "curr = time.time()\n",
    "model = Word2Vec(\n",
    "        walks,\n",
    "        vector_size=dimensions,\n",
    "        window=context_window_size,\n",
    "        min_count=0,\n",
    "        sg=1,\n",
    "        workers=workers\n",
    "    )\n",
    "timetaken = time.time()-curr\n",
    "print(\"time taken for training word2vec : \",timetaken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08bfdefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(u):\n",
    "    return model.wv[u]\n",
    "\n",
    "embedding_train = get_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "93a2f189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_embedding(u)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3503d39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for getting node embeddings :  0.0001201629638671875\n"
     ]
    }
   ],
   "source": [
    "curr = time.time()\n",
    "node_ids = model.wv.index_to_key  # list of node IDs\n",
    "node_embeddings = (\n",
    "    model.wv.vectors\n",
    ")\n",
    "timetaken = time.time()-curr\n",
    "print(\"time taken for getting node embeddings : \",timetaken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc7a1b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04454675, -0.15098633, -0.14263374, ..., -0.02475462,\n",
       "         0.02735988, -0.04422437],\n",
       "       [ 0.00534413, -0.00093344, -0.07663991, ..., -0.1003122 ,\n",
       "         0.05472428, -0.02785431],\n",
       "       [-0.03314362,  0.05169779, -0.16807988, ..., -0.06688873,\n",
       "         0.11019027, -0.0072902 ],\n",
       "       ...,\n",
       "       [-0.04662629, -0.36680228,  0.25478554, ..., -0.05306149,\n",
       "         0.08224034,  0.16038658],\n",
       "       [-0.04669413, -0.05721235,  0.15926437, ...,  0.01061422,\n",
       "        -0.16594188,  0.14179882],\n",
       "       [-0.00074436, -0.03708893,  0.19749694, ..., -0.00540493,\n",
       "        -0.05588885,  0.07483114]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7725bb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1114,\n",
       " 870,\n",
       " 1100,\n",
       " 1146,\n",
       " 5008,\n",
       " 5009,\n",
       " 1118,\n",
       " 5005,\n",
       " 5011,\n",
       " 5034,\n",
       " 5070,\n",
       " 931,\n",
       " 5002,\n",
       " 5042,\n",
       " 505,\n",
       " 38,\n",
       " 1087,\n",
       " 70,\n",
       " 5036,\n",
       " 5012,\n",
       " 103,\n",
       " 5014,\n",
       " 1164,\n",
       " 1007,\n",
       " 5255,\n",
       " 848,\n",
       " 5057,\n",
       " 5028,\n",
       " 5032,\n",
       " 5145,\n",
       " 5024,\n",
       " 5225,\n",
       " 964,\n",
       " 5064,\n",
       " 1163,\n",
       " 5037,\n",
       " 5018,\n",
       " 5000,\n",
       " 853,\n",
       " 5053,\n",
       " 5081,\n",
       " 5624,\n",
       " 5095,\n",
       " 5838,\n",
       " 5019,\n",
       " 6,\n",
       " 5046,\n",
       " 989,\n",
       " 5182,\n",
       " 5264,\n",
       " 5158,\n",
       " 5475,\n",
       " 847,\n",
       " 120,\n",
       " 100007,\n",
       " 5076,\n",
       " 5045,\n",
       " 100031,\n",
       " 100103,\n",
       " 5494,\n",
       " 100051,\n",
       " 900,\n",
       " 34,\n",
       " 5223,\n",
       " 5049,\n",
       " 100294,\n",
       " 100170,\n",
       " 5030,\n",
       " 5639,\n",
       " 5385,\n",
       " 5173,\n",
       " 5058,\n",
       " 100519,\n",
       " 5137,\n",
       " 5003,\n",
       " 50,\n",
       " 5139,\n",
       " 5688,\n",
       " 5035,\n",
       " 5073,\n",
       " 102786,\n",
       " 100044,\n",
       " 921,\n",
       " 1148,\n",
       " 100428,\n",
       " 5051,\n",
       " 5159,\n",
       " 100288,\n",
       " 5366,\n",
       " 100014,\n",
       " 5082,\n",
       " 100747,\n",
       " 5837,\n",
       " 100060,\n",
       " 101524,\n",
       " 100057,\n",
       " 101870,\n",
       " 1180,\n",
       " 100319,\n",
       " 5689,\n",
       " 102231,\n",
       " 100215,\n",
       " 100341,\n",
       " 100216,\n",
       " 7495,\n",
       " 5117,\n",
       " 102391,\n",
       " 100790,\n",
       " 5330,\n",
       " 5060,\n",
       " 100316,\n",
       " 100008,\n",
       " 5525,\n",
       " 5021,\n",
       " 5601,\n",
       " 5536,\n",
       " 5478,\n",
       " 5572,\n",
       " 514,\n",
       " 5109,\n",
       " 100036,\n",
       " 100829,\n",
       " 100292,\n",
       " 100252,\n",
       " 5784,\n",
       " 5069,\n",
       " 103045,\n",
       " 100055,\n",
       " 5157,\n",
       " 100405,\n",
       " 100082,\n",
       " 100310,\n",
       " 100070,\n",
       " 101773,\n",
       " 5096,\n",
       " 101429,\n",
       " 100395,\n",
       " 100324,\n",
       " 5097,\n",
       " 5675,\n",
       " 100654,\n",
       " 100213,\n",
       " 100067,\n",
       " 5451,\n",
       " 5613,\n",
       " 100109,\n",
       " 100192,\n",
       " 5056,\n",
       " 100662,\n",
       " 100210,\n",
       " 5071,\n",
       " 100787,\n",
       " 5063,\n",
       " 100211,\n",
       " 5162,\n",
       " 5026,\n",
       " 5149,\n",
       " 100858,\n",
       " 100325,\n",
       " 100327,\n",
       " 5020,\n",
       " 100162,\n",
       " 5258,\n",
       " 5180,\n",
       " 5764,\n",
       " 100232,\n",
       " 100021,\n",
       " 101736,\n",
       " 100804,\n",
       " 100360,\n",
       " 100983,\n",
       " 5061,\n",
       " 5586,\n",
       " 100796,\n",
       " 100638,\n",
       " 100322,\n",
       " 103401,\n",
       " 5089,\n",
       " 100446,\n",
       " 101403,\n",
       " 5301,\n",
       " 100767,\n",
       " 101775,\n",
       " 100255,\n",
       " 100714,\n",
       " 100488,\n",
       " 100890,\n",
       " 100110,\n",
       " 100138,\n",
       " 100595,\n",
       " 5561,\n",
       " 100282,\n",
       " 5470,\n",
       " 101041,\n",
       " 100465,\n",
       " 5138,\n",
       " 100336,\n",
       " 100677,\n",
       " 100234,\n",
       " 5107,\n",
       " 100925,\n",
       " 100268,\n",
       " 100921,\n",
       " 100798,\n",
       " 100537,\n",
       " 5087,\n",
       " 100883,\n",
       " 100253,\n",
       " 5015,\n",
       " 100523,\n",
       " 5121,\n",
       " 101063,\n",
       " 100517,\n",
       " 101067,\n",
       " 100168,\n",
       " 100441,\n",
       " 101269,\n",
       " 100035,\n",
       " 101807,\n",
       " 100556,\n",
       " 100830,\n",
       " 100179,\n",
       " 100144,\n",
       " 5244,\n",
       " 100033,\n",
       " 100577,\n",
       " 101462,\n",
       " 101102,\n",
       " 5305,\n",
       " 101068,\n",
       " 102673,\n",
       " 101479,\n",
       " 100263,\n",
       " 101437,\n",
       " 100238,\n",
       " 100274,\n",
       " 100797,\n",
       " 100177,\n",
       " 101476,\n",
       " 100926,\n",
       " 101315,\n",
       " 100173,\n",
       " 100045,\n",
       " 100741,\n",
       " 100079,\n",
       " 100053,\n",
       " 5050,\n",
       " 6031,\n",
       " 5220,\n",
       " 6720,\n",
       " 100246,\n",
       " 6327,\n",
       " 5199,\n",
       " 101770,\n",
       " 101430,\n",
       " 100825,\n",
       " 5001,\n",
       " 100188,\n",
       " 100392,\n",
       " 5723,\n",
       " 100464,\n",
       " 100002,\n",
       " 100413,\n",
       " 100569,\n",
       " 101300,\n",
       " 101348,\n",
       " 100064,\n",
       " 5690,\n",
       " 101058,\n",
       " 5113,\n",
       " 100503,\n",
       " 101659,\n",
       " 102140,\n",
       " 100094,\n",
       " 100041,\n",
       " 100313,\n",
       " 101638,\n",
       " 5435,\n",
       " 5231,\n",
       " 5873,\n",
       " 100770,\n",
       " 5127,\n",
       " 100499,\n",
       " 100422,\n",
       " 5778,\n",
       " 101647,\n",
       " 102376,\n",
       " 5077,\n",
       " 100693,\n",
       " 101406,\n",
       " 100164,\n",
       " 6064,\n",
       " 5188,\n",
       " 5092,\n",
       " 100199,\n",
       " 100643,\n",
       " 100071,\n",
       " 100119,\n",
       " 100182,\n",
       " 101115,\n",
       " 6314,\n",
       " 100667,\n",
       " 5033,\n",
       " 5730,\n",
       " 100349,\n",
       " 101938,\n",
       " 5105,\n",
       " 100270,\n",
       " 100853,\n",
       " 5490,\n",
       " 100198,\n",
       " 100214,\n",
       " 100329,\n",
       " 100777,\n",
       " 5384,\n",
       " 9162,\n",
       " 100117,\n",
       " 102880,\n",
       " 5546,\n",
       " 100297,\n",
       " 100475,\n",
       " 100587,\n",
       " 100340,\n",
       " 6271,\n",
       " 100396,\n",
       " 100708,\n",
       " 100675,\n",
       " 101183,\n",
       " 100457,\n",
       " 101413,\n",
       " 100502,\n",
       " 5102,\n",
       " 101020,\n",
       " 5124,\n",
       " 5196,\n",
       " 5116,\n",
       " 102523,\n",
       " 5136,\n",
       " 101692,\n",
       " 101081,\n",
       " 5130,\n",
       " 5114,\n",
       " 100025,\n",
       " 5129,\n",
       " 5093,\n",
       " 5590,\n",
       " 100772,\n",
       " 101059,\n",
       " 101302,\n",
       " 100009,\n",
       " 100449,\n",
       " 6035,\n",
       " 5125,\n",
       " 5143,\n",
       " 100841,\n",
       " 5197,\n",
       " 101843,\n",
       " 100368,\n",
       " 100345,\n",
       " 102615,\n",
       " 100124,\n",
       " 5860,\n",
       " 101248,\n",
       " 100902,\n",
       " 100242,\n",
       " 5155,\n",
       " 5123,\n",
       " 100486,\n",
       " 5161,\n",
       " 100137,\n",
       " 101153,\n",
       " 100433,\n",
       " 101383,\n",
       " 102000,\n",
       " 100376,\n",
       " 103353,\n",
       " 5128,\n",
       " 5581,\n",
       " 101189,\n",
       " 102322,\n",
       " 5767,\n",
       " 100372,\n",
       " 5115,\n",
       " 103222,\n",
       " 100746,\n",
       " 101356,\n",
       " 100208,\n",
       " 102110,\n",
       " 5250,\n",
       " 103042,\n",
       " 100178,\n",
       " 102418,\n",
       " 101759,\n",
       " 100184,\n",
       " 5765,\n",
       " 101509,\n",
       " 101557,\n",
       " 100126,\n",
       " 100309,\n",
       " 100344,\n",
       " 100615,\n",
       " 100844,\n",
       " 100354,\n",
       " 100737,\n",
       " 100453,\n",
       " 100548,\n",
       " 100752,\n",
       " 100374,\n",
       " 100583,\n",
       " 5387,\n",
       " 100669,\n",
       " 100379,\n",
       " 101566,\n",
       " 100038,\n",
       " 100096,\n",
       " 9181,\n",
       " 5872,\n",
       " 100717,\n",
       " 102057,\n",
       " 100568,\n",
       " 101370,\n",
       " 5375,\n",
       " 101266,\n",
       " 100072,\n",
       " 100024,\n",
       " 5461,\n",
       " 100032,\n",
       " 102287,\n",
       " 100193,\n",
       " 101641,\n",
       " 100755,\n",
       " 101740,\n",
       " 101023,\n",
       " 100731,\n",
       " 100994,\n",
       " 100846,\n",
       " 100603,\n",
       " 5059,\n",
       " 102344,\n",
       " 100130,\n",
       " 103602,\n",
       " 101897,\n",
       " 102542,\n",
       " 101086,\n",
       " 100525,\n",
       " 100373,\n",
       " 100205,\n",
       " 5935,\n",
       " 100644,\n",
       " 100331,\n",
       " 100012,\n",
       " 100749,\n",
       " 100705,\n",
       " 100681,\n",
       " 5481,\n",
       " 101334,\n",
       " 100202,\n",
       " 102496,\n",
       " 101265,\n",
       " 5150,\n",
       " 100099,\n",
       " 103478,\n",
       " 101392,\n",
       " 100622,\n",
       " 100813,\n",
       " 100233,\n",
       " 100450,\n",
       " 100131,\n",
       " 102032,\n",
       " 101127,\n",
       " 100923,\n",
       " 101635,\n",
       " 5841,\n",
       " 100219,\n",
       " 100209,\n",
       " 102565,\n",
       " 100046,\n",
       " 101196,\n",
       " 102230,\n",
       " 100484,\n",
       " 6719,\n",
       " 100719,\n",
       " 100580,\n",
       " 5575,\n",
       " 100588,\n",
       " 100295,\n",
       " 101436,\n",
       " 103201,\n",
       " 100175,\n",
       " 5254,\n",
       " 101358,\n",
       " 100470,\n",
       " 100438,\n",
       " 101048,\n",
       " 5684,\n",
       " 5218,\n",
       " 100880,\n",
       " 100771,\n",
       " 101642,\n",
       " 100876,\n",
       " 100370,\n",
       " 101049,\n",
       " 101031,\n",
       " 100867,\n",
       " 5144,\n",
       " 100506,\n",
       " 100419,\n",
       " 6189,\n",
       " 100084,\n",
       " 100779,\n",
       " 5485,\n",
       " 100352,\n",
       " 101502,\n",
       " 102034,\n",
       " 100459,\n",
       " 100334,\n",
       " 101559,\n",
       " 100963,\n",
       " 9492,\n",
       " 102661,\n",
       " 100988,\n",
       " 5402,\n",
       " 100824,\n",
       " 101375,\n",
       " 101152,\n",
       " 100226,\n",
       " 101250,\n",
       " 6821,\n",
       " 5471,\n",
       " 102158,\n",
       " 100469,\n",
       " 101386,\n",
       " 5164,\n",
       " 100015,\n",
       " 100062,\n",
       " 101012,\n",
       " 102183,\n",
       " 103365,\n",
       " 102873,\n",
       " 101228,\n",
       " 5374,\n",
       " 100448,\n",
       " 5054,\n",
       " 100639,\n",
       " 102583,\n",
       " 101835,\n",
       " 102663,\n",
       " 101351,\n",
       " 5574,\n",
       " 7666,\n",
       " 5318,\n",
       " 101274,\n",
       " 100878,\n",
       " 100810,\n",
       " 101432,\n",
       " 100217,\n",
       " 100176,\n",
       " 101573,\n",
       " 101286,\n",
       " 101790,\n",
       " 5214,\n",
       " 5599,\n",
       " 5527,\n",
       " 100280,\n",
       " 102200,\n",
       " 102356,\n",
       " 6744,\n",
       " 5237,\n",
       " 100802,\n",
       " 101471,\n",
       " 5582,\n",
       " 5006,\n",
       " 100894,\n",
       " 100380,\n",
       " 101204,\n",
       " 102142,\n",
       " 102116,\n",
       " 102044,\n",
       " 102667,\n",
       " 101485,\n",
       " 5729,\n",
       " 6078,\n",
       " 101246,\n",
       " 5652,\n",
       " 100302,\n",
       " 100684,\n",
       " 5367,\n",
       " 100147,\n",
       " 100172,\n",
       " 101706,\n",
       " 102614,\n",
       " 100052,\n",
       " 100869,\n",
       " 100758,\n",
       " 101298,\n",
       " 100997,\n",
       " 100375,\n",
       " 5521,\n",
       " 100001,\n",
       " 100833,\n",
       " 5146,\n",
       " 100832,\n",
       " 100018,\n",
       " 5433,\n",
       " 100005,\n",
       " 101729,\n",
       " 100229,\n",
       " 101534,\n",
       " 100011,\n",
       " 100842,\n",
       " 5883,\n",
       " 100027,\n",
       " 102101,\n",
       " 5269,\n",
       " 102412,\n",
       " 101515,\n",
       " 100886,\n",
       " 102599,\n",
       " 100287,\n",
       " 5498,\n",
       " 101537,\n",
       " 101590,\n",
       " 102547,\n",
       " 100505,\n",
       " 100050,\n",
       " 100847,\n",
       " 102747,\n",
       " 100734,\n",
       " 5038,\n",
       " 101318,\n",
       " 101092,\n",
       " 100753,\n",
       " 102797,\n",
       " 5183,\n",
       " 100160,\n",
       " 100116,\n",
       " 100683,\n",
       " 101044,\n",
       " 100091,\n",
       " 100356,\n",
       " 102901,\n",
       " 100296,\n",
       " 100774,\n",
       " 5449,\n",
       " 5079,\n",
       " 100161,\n",
       " 7867,\n",
       " 100673,\n",
       " 101188,\n",
       " 102345,\n",
       " 6322,\n",
       " 5298,\n",
       " 5424,\n",
       " 100884,\n",
       " 101643,\n",
       " 101094,\n",
       " 101180,\n",
       " 102337,\n",
       " 101505,\n",
       " 100404,\n",
       " 5438,\n",
       " 100659,\n",
       " 100231,\n",
       " 100862,\n",
       " 5080,\n",
       " 100495,\n",
       " 101129,\n",
       " 6812,\n",
       " 100547,\n",
       " 100729,\n",
       " 102574,\n",
       " 102613,\n",
       " 102798,\n",
       " 100152,\n",
       " 100132,\n",
       " 6481,\n",
       " 102685,\n",
       " 5090,\n",
       " 101355,\n",
       " 100573,\n",
       " 101496,\n",
       " 102535,\n",
       " 6049,\n",
       " 102919,\n",
       " 5331,\n",
       " 5427,\n",
       " 100222,\n",
       " 100250,\n",
       " 100042,\n",
       " 100794,\n",
       " 5912,\n",
       " 100414,\n",
       " 100351,\n",
       " 101551,\n",
       " 5444,\n",
       " 100112,\n",
       " 100388,\n",
       " 7247,\n",
       " 100976,\n",
       " 5320,\n",
       " 100808,\n",
       " 100520,\n",
       " 101616,\n",
       " 101072,\n",
       " 6285,\n",
       " 101749,\n",
       " 101492,\n",
       " 100128,\n",
       " 5152,\n",
       " 5029,\n",
       " 5101,\n",
       " 5291,\n",
       " 100308,\n",
       " 100931,\n",
       " 102813,\n",
       " 5335,\n",
       " 101217,\n",
       " 100100,\n",
       " 5187,\n",
       " 100332,\n",
       " 100757,\n",
       " 100742,\n",
       " 100550,\n",
       " 5156,\n",
       " 101328,\n",
       " 100652,\n",
       " 5557,\n",
       " 100527,\n",
       " 103199,\n",
       " 100565,\n",
       " 101529,\n",
       " 5425,\n",
       " 6012,\n",
       " 102261,\n",
       " 101239,\n",
       " 100089,\n",
       " 101814,\n",
       " 101191,\n",
       " 101772,\n",
       " 100249,\n",
       " 100458,\n",
       " 5302,\n",
       " 103202,\n",
       " 102405,\n",
       " 101106,\n",
       " 101308,\n",
       " 102623,\n",
       " 101745,\n",
       " 5333,\n",
       " 100679,\n",
       " 101801,\n",
       " 5995,\n",
       " 5393,\n",
       " 100023,\n",
       " 103149,\n",
       " 100908,\n",
       " 100343,\n",
       " 8005,\n",
       " 102511,\n",
       " 102365,\n",
       " 6855,\n",
       " 102349,\n",
       " 102028,\n",
       " 101267,\n",
       " 100781,\n",
       " 102177,\n",
       " 101703,\n",
       " 100312,\n",
       " 6253,\n",
       " 5413,\n",
       " 100427,\n",
       " 103031,\n",
       " 5996,\n",
       " 100466,\n",
       " 102320,\n",
       " 101199,\n",
       " 101382,\n",
       " 100682,\n",
       " 100452,\n",
       " 5372,\n",
       " 102307,\n",
       " 101587,\n",
       " 5227,\n",
       " 9078,\n",
       " 100093,\n",
       " 5662,\n",
       " 100765,\n",
       " 6632,\n",
       " 100281,\n",
       " 5663,\n",
       " 101016,\n",
       " 100891,\n",
       " 103613,\n",
       " 100125,\n",
       " 102187,\n",
       " 101139,\n",
       " 6337,\n",
       " 100780,\n",
       " 101252,\n",
       " 100967,\n",
       " 5184,\n",
       " 7087,\n",
       " 5249,\n",
       " 100123,\n",
       " 7855,\n",
       " 5295,\n",
       " 101758,\n",
       " 102222,\n",
       " 102099,\n",
       " 100899,\n",
       " 5351,\n",
       " 101671,\n",
       " 100788,\n",
       " 101921,\n",
       " 101162,\n",
       " 100978,\n",
       " 101818,\n",
       " 100230,\n",
       " 103614,\n",
       " 102435,\n",
       " 102064,\n",
       " 100586,\n",
       " 101077,\n",
       " 5160,\n",
       " 101593,\n",
       " 100649,\n",
       " 100115,\n",
       " 100185,\n",
       " 101468,\n",
       " 6740,\n",
       " 100740,\n",
       " 100849,\n",
       " 100371,\n",
       " 100223,\n",
       " 100544,\n",
       " 101934,\n",
       " 6386,\n",
       " 100786,\n",
       " 7635,\n",
       " 101541,\n",
       " 102642,\n",
       " 5567,\n",
       " 100445,\n",
       " 101256,\n",
       " 101808,\n",
       " 5482,\n",
       " 5350,\n",
       " 102025,\n",
       " 5556,\n",
       " 100444,\n",
       " 100837,\n",
       " 100289,\n",
       " 102845,\n",
       " 102856,\n",
       " 5700,\n",
       " 100421,\n",
       " 101276,\n",
       " 100641,\n",
       " 100497,\n",
       " 100111,\n",
       " 101576,\n",
       " 102277,\n",
       " 100707,\n",
       " 5583,\n",
       " 5380,\n",
       " 100489,\n",
       " 100017,\n",
       " 101632,\n",
       " 101969,\n",
       " 100301,\n",
       " 100959,\n",
       " 102595,\n",
       " 100442,\n",
       " 101667,\n",
       " 5783,\n",
       " 101543,\n",
       " 5052,\n",
       " 6824,\n",
       " 101742,\n",
       " 101523,\n",
       " 5135,\n",
       " 101896,\n",
       " 5891,\n",
       " 100892,\n",
       " 100291,\n",
       " 101792,\n",
       " 100367,\n",
       " 5222,\n",
       " 5300,\n",
       " 100524,\n",
       " 5192,\n",
       " 100203,\n",
       " 101570,\n",
       " 5207,\n",
       " 5296,\n",
       " 102668,\n",
       " 101697,\n",
       " 5208,\n",
       " 100938,\n",
       " 5203,\n",
       " 100086,\n",
       " 100364,\n",
       " 102734,\n",
       " 100721,\n",
       " 100618,\n",
       " 5381,\n",
       " 101911,\n",
       " 102168,\n",
       " 101344,\n",
       " 5629,\n",
       " 102608,\n",
       " 5185,\n",
       " 100267,\n",
       " 100857,\n",
       " 102129,\n",
       " 102699,\n",
       " 100690,\n",
       " 100799,\n",
       " 5349,\n",
       " 100905,\n",
       " 100480,\n",
       " 102122,\n",
       " 100751,\n",
       " 100515,\n",
       " 101929,\n",
       " 6490,\n",
       " 102017,\n",
       " 102546,\n",
       " 102206,\n",
       " 102169,\n",
       " 100069,\n",
       " 5271,\n",
       " 101110,\n",
       " 102073,\n",
       " 102103,\n",
       " 100879,\n",
       " 103146,\n",
       " 101311,\n",
       " 100440,\n",
       " 100393,\n",
       " 7783,\n",
       " 101440,\n",
       " 102059,\n",
       " 100058,\n",
       " 102858,\n",
       " 5676,\n",
       " 101782,\n",
       " 5039,\n",
       " 100337,\n",
       " 101010,\n",
       " 100756,\n",
       " 5010,\n",
       " 103450,\n",
       " 6363,\n",
       " 100398,\n",
       " 100630,\n",
       " 6958,\n",
       " 103319,\n",
       " 102704,\n",
       " 100358,\n",
       " 5118,\n",
       " 5329,\n",
       " 100455,\n",
       " 101601,\n",
       " 102597,\n",
       " 100968,\n",
       " 5151,\n",
       " 100377,\n",
       " 100283,\n",
       " 100987,\n",
       " 5270,\n",
       " 102635,\n",
       " 5456,\n",
       " 103151,\n",
       " 101663,\n",
       " 100828,\n",
       " 5809,\n",
       " 101793,\n",
       " 100635,\n",
       " 102938,\n",
       " 5787,\n",
       " 5272,\n",
       " 100823,\n",
       " 5932,\n",
       " 5405,\n",
       " 6660,\n",
       " 7687,\n",
       " 5319,\n",
       " 100362,\n",
       " 100485,\n",
       " 5558,\n",
       " 102121,\n",
       " 100782,\n",
       " 6358,\n",
       " 101229,\n",
       " 100821,\n",
       " 101053,\n",
       " 5966,\n",
       " 101438,\n",
       " 100567,\n",
       " ...]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7454a876",
   "metadata": {},
   "source": [
    "# finally creating training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99303635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_ids.index(5005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7eba9b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-55-fdc3888e92fb>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-55-fdc3888e92fb>:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-55-fdc3888e92fb>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-55-fdc3888e92fb>:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-55-fdc3888e92fb>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-55-fdc3888e92fb>:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-55-fdc3888e92fb>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-55-fdc3888e92fb>:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-55-fdc3888e92fb>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-55-fdc3888e92fb>:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-55-fdc3888e92fb>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-55-fdc3888e92fb>:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-55-fdc3888e92fb>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-55-fdc3888e92fb>:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-55-fdc3888e92fb>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-55-fdc3888e92fb>:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-55-fdc3888e92fb>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-55-fdc3888e92fb>:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-fdc3888e92fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# creating x_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'src'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dest'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame()\n",
    "test_file_no = 1\n",
    "dir_path = \"WSJ split data files\"\n",
    "for i in range(1,11,1):\n",
    "    if i != test_file_no:\n",
    "        df = pd.read_csv(dir_path+\"/WSJ_positive_edges_split_\"+str(i)+\".csv\") \n",
    "        train_df = train_df.append(df, ignore_index=True)\n",
    "        df = pd.read_csv(dir_path+\"/WSJ_negative_edges_split_\"+str(i)+\".csv\")\n",
    "        train_df = train_df.append(df, ignore_index=True)\n",
    "        del df\n",
    "train_df = train_df.drop(['layer', 'weight',\"sign\"], axis=1)\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# creating x_train\n",
    "X_train = [(model.wv.get_vector(node_ids.index(train_df['src'][i])) + model.wv.get_vector(node_ids.index(train_df['dest'][i]))) for i in train_df.index]\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(train_df['label'])\n",
    "\n",
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7514ef27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = model.wv.get_vector(node_ids.index(870))\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d82b54a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1139400, 128)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(train_df['label'])\n",
    "\n",
    "del train_df\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "90c2a69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16023/16023 - 18s - loss: -2.2777e+06 - accuracy: 0.1480 - val_loss: -8.0011e+06 - val_accuracy: 0.1491 - 18s/epoch - 1ms/step\n",
      "Epoch 2/100\n",
      "16023/16023 - 19s - loss: -2.4414e+07 - accuracy: 0.1487 - val_loss: -4.8366e+07 - val_accuracy: 0.1506 - 19s/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "16023/16023 - 16s - loss: -9.0262e+07 - accuracy: 0.1489 - val_loss: -1.4406e+08 - val_accuracy: 0.1484 - 16s/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "16023/16023 - 17s - loss: -2.2220e+08 - accuracy: 0.1485 - val_loss: -3.1724e+08 - val_accuracy: 0.1501 - 17s/epoch - 1ms/step\n",
      "Epoch 5/100\n",
      "16023/16023 - 18s - loss: -4.4242e+08 - accuracy: 0.1487 - val_loss: -5.9013e+08 - val_accuracy: 0.1493 - 18s/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "16023/16023 - 17s - loss: -7.7264e+08 - accuracy: 0.1485 - val_loss: -9.8488e+08 - val_accuracy: 0.1493 - 17s/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "16023/16023 - 17s - loss: -1.2344e+09 - accuracy: 0.1485 - val_loss: -1.5227e+09 - val_accuracy: 0.1495 - 17s/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "16023/16023 - 18s - loss: -1.8505e+09 - accuracy: 0.1486 - val_loss: -2.2260e+09 - val_accuracy: 0.1488 - 18s/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "16023/16023 - 17s - loss: -2.6428e+09 - accuracy: 0.1485 - val_loss: -3.1173e+09 - val_accuracy: 0.1491 - 17s/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "16023/16023 - 18s - loss: -3.6302e+09 - accuracy: 0.1486 - val_loss: -4.2159e+09 - val_accuracy: 0.1491 - 18s/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "16023/16023 - 17s - loss: -4.8371e+09 - accuracy: 0.1484 - val_loss: -5.5460e+09 - val_accuracy: 0.1495 - 17s/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "16023/16023 - 17s - loss: -6.2860e+09 - accuracy: 0.1487 - val_loss: -7.1292e+09 - val_accuracy: 0.1491 - 17s/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "16023/16023 - 18s - loss: -7.9914e+09 - accuracy: 0.1484 - val_loss: -8.9811e+09 - val_accuracy: 0.1500 - 18s/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "16023/16023 - 16s - loss: -9.9815e+09 - accuracy: 0.1487 - val_loss: -1.1129e+10 - val_accuracy: 0.1495 - 16s/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "16023/16023 - 17s - loss: -1.2279e+10 - accuracy: 0.1488 - val_loss: -1.3601e+10 - val_accuracy: 0.1490 - 17s/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "16023/16023 - 17s - loss: -1.4903e+10 - accuracy: 0.1487 - val_loss: -1.6405e+10 - val_accuracy: 0.1485 - 17s/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "16023/16023 - 16s - loss: -1.7871e+10 - accuracy: 0.1482 - val_loss: -1.9571e+10 - val_accuracy: 0.1499 - 16s/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "16023/16023 - 19s - loss: -2.1200e+10 - accuracy: 0.1486 - val_loss: -2.3114e+10 - val_accuracy: 0.1498 - 19s/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "16023/16023 - 21s - loss: -2.4937e+10 - accuracy: 0.1487 - val_loss: -2.7067e+10 - val_accuracy: 0.1494 - 21s/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "16023/16023 - 17s - loss: -2.9078e+10 - accuracy: 0.1487 - val_loss: -3.1442e+10 - val_accuracy: 0.1491 - 17s/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "16023/16023 - 18s - loss: -3.3651e+10 - accuracy: 0.1484 - val_loss: -3.6262e+10 - val_accuracy: 0.1498 - 18s/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "16023/16023 - 17s - loss: -3.8680e+10 - accuracy: 0.1487 - val_loss: -4.1556e+10 - val_accuracy: 0.1496 - 17s/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "16023/16023 - 18s - loss: -4.4194e+10 - accuracy: 0.1485 - val_loss: -4.7340e+10 - val_accuracy: 0.1496 - 18s/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "16023/16023 - 18s - loss: -5.0197e+10 - accuracy: 0.1488 - val_loss: -5.3635e+10 - val_accuracy: 0.1489 - 18s/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "16023/16023 - 16s - loss: -5.6715e+10 - accuracy: 0.1484 - val_loss: -6.0450e+10 - val_accuracy: 0.1493 - 16s/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "16023/16023 - 19s - loss: -6.3781e+10 - accuracy: 0.1486 - val_loss: -6.7828e+10 - val_accuracy: 0.1494 - 19s/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "16023/16023 - 16s - loss: -7.1411e+10 - accuracy: 0.1486 - val_loss: -7.5784e+10 - val_accuracy: 0.1494 - 16s/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "16023/16023 - 17s - loss: -7.9623e+10 - accuracy: 0.1486 - val_loss: -8.4343e+10 - val_accuracy: 0.1493 - 17s/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "16023/16023 - 17s - loss: -8.8450e+10 - accuracy: 0.1484 - val_loss: -9.3520e+10 - val_accuracy: 0.1496 - 17s/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "16023/16023 - 17s - loss: -9.7889e+10 - accuracy: 0.1487 - val_loss: -1.0332e+11 - val_accuracy: 0.1494 - 17s/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "16023/16023 - 19s - loss: -1.0799e+11 - accuracy: 0.1487 - val_loss: -1.1381e+11 - val_accuracy: 0.1488 - 19s/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "16023/16023 - 17s - loss: -1.1874e+11 - accuracy: 0.1481 - val_loss: -1.2495e+11 - val_accuracy: 0.1495 - 17s/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "16023/16023 - 17s - loss: -1.3018e+11 - accuracy: 0.1484 - val_loss: -1.3681e+11 - val_accuracy: 0.1494 - 17s/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "16023/16023 - 19s - loss: -1.4234e+11 - accuracy: 0.1487 - val_loss: -1.4938e+11 - val_accuracy: 0.1493 - 19s/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "16023/16023 - 17s - loss: -1.5523e+11 - accuracy: 0.1485 - val_loss: -1.6272e+11 - val_accuracy: 0.1493 - 17s/epoch - 1ms/step\n",
      "Epoch 36/100\n",
      "16023/16023 - 17s - loss: -1.6888e+11 - accuracy: 0.1484 - val_loss: -1.7683e+11 - val_accuracy: 0.1496 - 17s/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "16023/16023 - 19s - loss: -1.8332e+11 - accuracy: 0.1486 - val_loss: -1.9172e+11 - val_accuracy: 0.1495 - 19s/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "16023/16023 - 17s - loss: -1.9855e+11 - accuracy: 0.1486 - val_loss: -2.0745e+11 - val_accuracy: 0.1492 - 17s/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "16023/16023 - 18s - loss: -2.1459e+11 - accuracy: 0.1484 - val_loss: -2.2400e+11 - val_accuracy: 0.1493 - 18s/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "16023/16023 - 17s - loss: -2.3151e+11 - accuracy: 0.1486 - val_loss: -2.4139e+11 - val_accuracy: 0.1492 - 17s/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "16023/16023 - 18s - loss: -2.4923e+11 - accuracy: 0.1485 - val_loss: -2.5966e+11 - val_accuracy: 0.1494 - 18s/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "16023/16023 - 18s - loss: -2.6788e+11 - accuracy: 0.1487 - val_loss: -2.7884e+11 - val_accuracy: 0.1493 - 18s/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "16023/16023 - 18s - loss: -2.8740e+11 - accuracy: 0.1486 - val_loss: -2.9895e+11 - val_accuracy: 0.1491 - 18s/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "16023/16023 - 18s - loss: -3.0787e+11 - accuracy: 0.1484 - val_loss: -3.1997e+11 - val_accuracy: 0.1494 - 18s/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "16023/16023 - 18s - loss: -3.2927e+11 - accuracy: 0.1485 - val_loss: -3.4194e+11 - val_accuracy: 0.1493 - 18s/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "16023/16023 - 17s - loss: -3.5167e+11 - accuracy: 0.1486 - val_loss: -3.6493e+11 - val_accuracy: 0.1493 - 17s/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "16023/16023 - 19s - loss: -3.7500e+11 - accuracy: 0.1485 - val_loss: -3.8889e+11 - val_accuracy: 0.1493 - 19s/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "16023/16023 - 17s - loss: -3.9939e+11 - accuracy: 0.1485 - val_loss: -4.1393e+11 - val_accuracy: 0.1492 - 17s/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "16023/16023 - 19s - loss: -4.2480e+11 - accuracy: 0.1485 - val_loss: -4.3995e+11 - val_accuracy: 0.1493 - 19s/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "16023/16023 - 19s - loss: -4.5125e+11 - accuracy: 0.1485 - val_loss: -4.6712e+11 - val_accuracy: 0.1493 - 19s/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "16023/16023 - 18s - loss: -4.7879e+11 - accuracy: 0.1484 - val_loss: -4.9535e+11 - val_accuracy: 0.1493 - 18s/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "16023/16023 - 19s - loss: -5.0746e+11 - accuracy: 0.1485 - val_loss: -5.2466e+11 - val_accuracy: 0.1494 - 19s/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "16023/16023 - 17s - loss: -5.3719e+11 - accuracy: 0.1486 - val_loss: -5.5513e+11 - val_accuracy: 0.1493 - 17s/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "16023/16023 - 18s - loss: -5.6809e+11 - accuracy: 0.1483 - val_loss: -5.8680e+11 - val_accuracy: 0.1495 - 18s/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "16023/16023 - 18s - loss: -6.0019e+11 - accuracy: 0.1485 - val_loss: -6.1962e+11 - val_accuracy: 0.1495 - 18s/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "16023/16023 - 19s - loss: -6.3343e+11 - accuracy: 0.1486 - val_loss: -6.5360e+11 - val_accuracy: 0.1494 - 19s/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "16023/16023 - 17s - loss: -6.6786e+11 - accuracy: 0.1486 - val_loss: -6.8882e+11 - val_accuracy: 0.1494 - 17s/epoch - 1ms/step\n",
      "Epoch 58/100\n",
      "16023/16023 - 18s - loss: -7.0352e+11 - accuracy: 0.1485 - val_loss: -7.2531e+11 - val_accuracy: 0.1494 - 18s/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "16023/16023 - 19s - loss: -7.4041e+11 - accuracy: 0.1486 - val_loss: -7.6301e+11 - val_accuracy: 0.1492 - 19s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "16023/16023 - 18s - loss: -7.7861e+11 - accuracy: 0.1484 - val_loss: -8.0203e+11 - val_accuracy: 0.1494 - 18s/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "16023/16023 - 18s - loss: -8.1808e+11 - accuracy: 0.1486 - val_loss: -8.4231e+11 - val_accuracy: 0.1494 - 18s/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "16023/16023 - 19s - loss: -8.5881e+11 - accuracy: 0.1485 - val_loss: -8.8396e+11 - val_accuracy: 0.1493 - 19s/epoch - 1ms/step\n",
      "Epoch 63/100\n",
      "16023/16023 - 17s - loss: -9.0097e+11 - accuracy: 0.1484 - val_loss: -9.2694e+11 - val_accuracy: 0.1494 - 17s/epoch - 1ms/step\n",
      "Epoch 64/100\n",
      "16023/16023 - 17s - loss: -9.4438e+11 - accuracy: 0.1487 - val_loss: -9.7129e+11 - val_accuracy: 0.1493 - 17s/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "16023/16023 - 23s - loss: -9.8919e+11 - accuracy: 0.1485 - val_loss: -1.0170e+12 - val_accuracy: 0.1494 - 23s/epoch - 1ms/step\n",
      "Epoch 66/100\n",
      "16023/16023 - 16s - loss: -1.0355e+12 - accuracy: 0.1486 - val_loss: -1.0642e+12 - val_accuracy: 0.1493 - 16s/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "16023/16023 - 18s - loss: -1.0830e+12 - accuracy: 0.1484 - val_loss: -1.1128e+12 - val_accuracy: 0.1492 - 18s/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "16023/16023 - 19s - loss: -1.1322e+12 - accuracy: 0.1486 - val_loss: -1.1629e+12 - val_accuracy: 0.1491 - 19s/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "16023/16023 - 18s - loss: -1.1828e+12 - accuracy: 0.1484 - val_loss: -1.2144e+12 - val_accuracy: 0.1491 - 18s/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "16023/16023 - 17s - loss: -1.2348e+12 - accuracy: 0.1484 - val_loss: -1.2675e+12 - val_accuracy: 0.1492 - 17s/epoch - 1ms/step\n",
      "Epoch 71/100\n",
      "16023/16023 - 19s - loss: -1.2884e+12 - accuracy: 0.1484 - val_loss: -1.3221e+12 - val_accuracy: 0.1493 - 19s/epoch - 1ms/step\n",
      "Epoch 72/100\n",
      "16023/16023 - 18s - loss: -1.3435e+12 - accuracy: 0.1486 - val_loss: -1.3782e+12 - val_accuracy: 0.1492 - 18s/epoch - 1ms/step\n",
      "Epoch 73/100\n",
      "16023/16023 - 18s - loss: -1.4000e+12 - accuracy: 0.1485 - val_loss: -1.4358e+12 - val_accuracy: 0.1492 - 18s/epoch - 1ms/step\n",
      "Epoch 74/100\n",
      "16023/16023 - 18s - loss: -1.4581e+12 - accuracy: 0.1485 - val_loss: -1.4950e+12 - val_accuracy: 0.1493 - 18s/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "16023/16023 - 18s - loss: -1.5179e+12 - accuracy: 0.1484 - val_loss: -1.5558e+12 - val_accuracy: 0.1494 - 18s/epoch - 1ms/step\n",
      "Epoch 76/100\n",
      "16023/16023 - 45s - loss: -1.5793e+12 - accuracy: 0.1486 - val_loss: -1.6184e+12 - val_accuracy: 0.1493 - 45s/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "16023/16023 - 20s - loss: -1.6423e+12 - accuracy: 0.1485 - val_loss: -1.6825e+12 - val_accuracy: 0.1493 - 20s/epoch - 1ms/step\n",
      "Epoch 78/100\n",
      "16023/16023 - 20s - loss: -1.7071e+12 - accuracy: 0.1485 - val_loss: -1.7484e+12 - val_accuracy: 0.1493 - 20s/epoch - 1ms/step\n",
      "Epoch 79/100\n",
      "16023/16023 - 17s - loss: -1.7734e+12 - accuracy: 0.1485 - val_loss: -1.8160e+12 - val_accuracy: 0.1493 - 17s/epoch - 1ms/step\n",
      "Epoch 80/100\n",
      "16023/16023 - 20s - loss: -1.8414e+12 - accuracy: 0.1485 - val_loss: -1.8851e+12 - val_accuracy: 0.1493 - 20s/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "16023/16023 - 17s - loss: -1.9111e+12 - accuracy: 0.1484 - val_loss: -1.9560e+12 - val_accuracy: 0.1494 - 17s/epoch - 1ms/step\n",
      "Epoch 82/100\n",
      "16023/16023 - 17s - loss: -1.9824e+12 - accuracy: 0.1485 - val_loss: -2.0287e+12 - val_accuracy: 0.1494 - 17s/epoch - 1ms/step\n",
      "Epoch 83/100\n",
      "16023/16023 - 18s - loss: -2.0559e+12 - accuracy: 0.1486 - val_loss: -2.1033e+12 - val_accuracy: 0.1493 - 18s/epoch - 1ms/step\n",
      "Epoch 84/100\n",
      "16023/16023 - 16s - loss: -2.1309e+12 - accuracy: 0.1485 - val_loss: -2.1796e+12 - val_accuracy: 0.1492 - 16s/epoch - 1ms/step\n",
      "Epoch 85/100\n",
      "16023/16023 - 18s - loss: -2.2077e+12 - accuracy: 0.1486 - val_loss: -2.2577e+12 - val_accuracy: 0.1492 - 18s/epoch - 1ms/step\n",
      "Epoch 86/100\n",
      "16023/16023 - 21s - loss: -2.2864e+12 - accuracy: 0.1484 - val_loss: -2.3378e+12 - val_accuracy: 0.1494 - 21s/epoch - 1ms/step\n",
      "Epoch 87/100\n",
      "16023/16023 - 20s - loss: -2.3670e+12 - accuracy: 0.1486 - val_loss: -2.4195e+12 - val_accuracy: 0.1493 - 20s/epoch - 1ms/step\n",
      "Epoch 88/100\n",
      "16023/16023 - 19s - loss: -2.4494e+12 - accuracy: 0.1485 - val_loss: -2.5033e+12 - val_accuracy: 0.1492 - 19s/epoch - 1ms/step\n",
      "Epoch 89/100\n",
      "16023/16023 - 20s - loss: -2.5337e+12 - accuracy: 0.1486 - val_loss: -2.5888e+12 - val_accuracy: 0.1492 - 20s/epoch - 1ms/step\n",
      "Epoch 90/100\n",
      "16023/16023 - 19s - loss: -2.6197e+12 - accuracy: 0.1485 - val_loss: -2.6764e+12 - val_accuracy: 0.1493 - 19s/epoch - 1ms/step\n",
      "Epoch 91/100\n",
      "16023/16023 - 19s - loss: -2.7078e+12 - accuracy: 0.1485 - val_loss: -2.7658e+12 - val_accuracy: 0.1493 - 19s/epoch - 1ms/step\n",
      "Epoch 92/100\n",
      "16023/16023 - 17s - loss: -2.7978e+12 - accuracy: 0.1485 - val_loss: -2.8574e+12 - val_accuracy: 0.1493 - 17s/epoch - 1ms/step\n",
      "Epoch 93/100\n",
      "16023/16023 - 18s - loss: -2.8898e+12 - accuracy: 0.1486 - val_loss: -2.9508e+12 - val_accuracy: 0.1493 - 18s/epoch - 1ms/step\n",
      "Epoch 94/100\n",
      "16023/16023 - 17s - loss: -2.9837e+12 - accuracy: 0.1486 - val_loss: -3.0463e+12 - val_accuracy: 0.1493 - 17s/epoch - 1ms/step\n",
      "Epoch 95/100\n",
      "16023/16023 - 21s - loss: -3.0798e+12 - accuracy: 0.1485 - val_loss: -3.1438e+12 - val_accuracy: 0.1493 - 21s/epoch - 1ms/step\n",
      "Epoch 96/100\n",
      "16023/16023 - 17s - loss: -3.1777e+12 - accuracy: 0.1485 - val_loss: -3.2432e+12 - val_accuracy: 0.1493 - 17s/epoch - 1ms/step\n",
      "Epoch 97/100\n",
      "16023/16023 - 17s - loss: -3.2780e+12 - accuracy: 0.1485 - val_loss: -3.3450e+12 - val_accuracy: 0.1493 - 17s/epoch - 1ms/step\n",
      "Epoch 98/100\n",
      "16023/16023 - 19s - loss: -3.3800e+12 - accuracy: 0.1485 - val_loss: -3.4486e+12 - val_accuracy: 0.1494 - 19s/epoch - 1ms/step\n",
      "Epoch 99/100\n",
      "16023/16023 - 17s - loss: -3.4845e+12 - accuracy: 0.1485 - val_loss: -3.5546e+12 - val_accuracy: 0.1494 - 17s/epoch - 1ms/step\n",
      "Epoch 100/100\n",
      "16023/16023 - 17s - loss: -3.5909e+12 - accuracy: 0.1486 - val_loss: -3.6627e+12 - val_accuracy: 0.1493 - 17s/epoch - 1ms/step\n",
      "time taken for training :  1825.7242391109467\n",
      "time taken for per epoch :  18.257242391109468\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import time\n",
    " \n",
    "epochs = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(56, input_shape=(X_train.shape[1],), activation='relu')) # Add an input shape! (features,)\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "curr = time.time()\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_split=0.10, epochs=epochs, batch_size=64,verbose=2)\n",
    "\n",
    "timetaken = time.time()-curr\n",
    "print(\"time taken for training : \",timetaken)\n",
    "print(\"time taken for per epoch : \",timetaken/epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9a9fc2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_metapath2vec_model_1.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7b74ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( X_train, open( \"X_train_m2v_1.p\", \"wb\" ) )\n",
    "pickle.dump( y_train, open( \"y_train_m2v_1.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca453fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea0914ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# 1. link embeddings\n",
    "def link_examples_to_features(link_examples, transform_node, binary_operator):\n",
    "    return [\n",
    "        binary_operator(transform_node(src), transform_node(dst))\n",
    "        for src, dst in link_examples\n",
    "    ]\n",
    "\n",
    "\n",
    "# 2. training classifier\n",
    "def train_link_prediction_model(\n",
    "    link_examples, link_labels, get_embedding, binary_operator\n",
    "):\n",
    "    clf = link_prediction_classifier()\n",
    "    link_features = link_examples_to_features(\n",
    "        link_examples, get_embedding, binary_operator\n",
    "    )\n",
    "    clf.fit(link_features, link_labels)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def link_prediction_classifier(max_iter=2000):\n",
    "    lr_clf = LogisticRegressionCV(Cs=10, cv=10, scoring=\"roc_auc\", max_iter=max_iter)\n",
    "    return Pipeline(steps=[(\"sc\", StandardScaler()), (\"clf\", lr_clf)])\n",
    "\n",
    "\n",
    "# 3. and 4. evaluate classifier\n",
    "def evaluate_link_prediction_model(\n",
    "    clf, link_examples_test, link_labels_test, get_embedding, binary_operator\n",
    "):\n",
    "    link_features_test = link_examples_to_features(\n",
    "        link_examples_test, get_embedding, binary_operator\n",
    "    )\n",
    "    score = evaluate_roc_auc(clf, link_features_test, link_labels_test)\n",
    "    return score\n",
    "\n",
    "\n",
    "def evaluate_roc_auc(clf, link_features, link_labels):\n",
    "    predicted = clf.predict_proba(link_features)\n",
    "\n",
    "    # check which class corresponds to positive links\n",
    "    positive_column = list(clf.classes_).index(1)\n",
    "    return roc_auc_score(link_labels, predicted[:, positive_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5f23b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def operator_l1(u, v):\n",
    "    return np.abs(u - v)\n",
    "\n",
    "\n",
    "def operator_l2(u, v):\n",
    "    return (u - v) ** 2\n",
    "\n",
    "\n",
    "def run_link_prediction(binary_operator):\n",
    "    clf = train_link_prediction_model(\n",
    "        examples_train, labels_train, embedding_train, binary_operator\n",
    "    )\n",
    "    score = evaluate_link_prediction_model(\n",
    "        clf,\n",
    "        examples_model_selection,\n",
    "        labels_model_selection,\n",
    "        embedding_train,\n",
    "        binary_operator,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"classifier\": clf,\n",
    "        \"binary_operator\": binary_operator,\n",
    "        \"score\": score,\n",
    "    }\n",
    "\n",
    "\n",
    "binary_operators = [operator_l1, operator_l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d56b07cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function __main__.operator_l1(u, v)>, <function __main__.operator_l2(u, v)>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef8cb29c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'examples_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-ede661efb50c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrun_link_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbinary_operators\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Best result from '{best_result['binary_operator'].__name__}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-ede661efb50c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrun_link_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbinary_operators\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Best result from '{best_result['binary_operator'].__name__}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-6ca5820e4cb9>\u001b[0m in \u001b[0;36mrun_link_prediction\u001b[0;34m(binary_operator)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_link_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_operator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     clf = train_link_prediction_model(\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mexamples_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     13\u001b[0m     score = evaluate_link_prediction_model(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'examples_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "results = [run_link_prediction(op) for op in binary_operators]\n",
    "best_result = max(results, key=lambda result: result[\"score\"])\n",
    "\n",
    "print(f\"Best result from '{best_result['binary_operator'].__name__}'\")\n",
    "\n",
    "pd.DataFrame(\n",
    "    [(result[\"binary_operator\"].__name__, result[\"score\"]) for result in results],\n",
    "    columns=(\"name\", \"ROC AUC score\"),\n",
    ").set_index(\"name\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
