{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6e097d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, top_k_accuracy_score, precision_score, recall_score, f1_score\n",
    "import pickle\n",
    "from node2vec import Node2Vec as n2v\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3d5c5a",
   "metadata": {},
   "source": [
    "# final code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f381dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user set params\n",
    "dir_path = \"WSJ split data files\"\n",
    "node_feature_dir_path = \"WSJ node features\"\n",
    "dbname = \"WSJ\"\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3421d834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique nodes found :  8536\n"
     ]
    }
   ],
   "source": [
    "# converting nodes to continuous variable\n",
    "train_df = pd.DataFrame()\n",
    "for i in range(1,11,1):\n",
    "    df = pd.read_csv(dir_path+\"/WSJ_positive_edges_split_\"+str(i)+\".csv\") \n",
    "    train_df = train_df.append(df, ignore_index=True)\n",
    "    del df\n",
    "temp_node_no = {}\n",
    "id = 0\n",
    "for i in np.unique(train_df[['src', 'dest']].values):\n",
    "    temp_node_no[i] = id\n",
    "    id += 1\n",
    "print(\"total unique nodes found : \",id)\n",
    "pickle.dump( temp_node_no, open( \"node_id_into_continuous_node_ids.p\", \"wb\" ) )\n",
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c358087d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " Test file no :  1\n",
      "Dataset has been successfully prepared\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ecac67987c46878db0c1dff604871b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/8536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|████████████████| 10/10 [06:05<00:00, 36.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for training node embedding model :  3565.7120933532715\n",
      "<bound method NDFrame.head of           src  dest  label\n",
      "0        5176  6392      1\n",
      "1         344  4836      0\n",
      "2        5622  6594      1\n",
      "3          88  4625      1\n",
      "4        3577  7954      0\n",
      "...       ...   ...    ...\n",
      "1139395  3441  3189      0\n",
      "1139396  7865  3993      0\n",
      "1139397  2044  1424      0\n",
      "1139398  6227   403      0\n",
      "1139399  4952  6151      1\n",
      "\n",
      "[1139400 rows x 3 columns]>\n",
      "x_train and x_test are ready\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 16:56:54.977799: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-07-19 16:56:54.977840: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-07-19 16:56:54.977854: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a3d): /proc/driver/nvidia/version does not exist\n",
      "2023-07-19 16:56:54.978079: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64092/64092 [==============================] - 133s 2ms/step - loss: 0.4084 - accuracy: 0.8267 - val_loss: 0.3944 - val_accuracy: 0.8349\n",
      "Epoch 2/100\n",
      "64092/64092 [==============================] - 129s 2ms/step - loss: 0.3892 - accuracy: 0.8363 - val_loss: 0.3890 - val_accuracy: 0.8361\n",
      "Epoch 3/100\n",
      "64092/64092 [==============================] - 128s 2ms/step - loss: 0.3844 - accuracy: 0.8386 - val_loss: 0.3837 - val_accuracy: 0.8382\n",
      "Epoch 4/100\n",
      "64092/64092 [==============================] - 130s 2ms/step - loss: 0.3811 - accuracy: 0.8397 - val_loss: 0.3846 - val_accuracy: 0.8374\n",
      "Epoch 5/100\n",
      "64092/64092 [==============================] - 131s 2ms/step - loss: 0.3783 - accuracy: 0.8409 - val_loss: 0.3832 - val_accuracy: 0.8386\n",
      "Epoch 6/100\n",
      "64092/64092 [==============================] - 131s 2ms/step - loss: 0.3760 - accuracy: 0.8418 - val_loss: 0.3752 - val_accuracy: 0.8419\n",
      "Epoch 7/100\n",
      "64092/64092 [==============================] - 130s 2ms/step - loss: 0.3742 - accuracy: 0.8423 - val_loss: 0.3742 - val_accuracy: 0.8417\n",
      "Epoch 8/100\n",
      "64092/64092 [==============================] - 130s 2ms/step - loss: 0.3729 - accuracy: 0.8426 - val_loss: 0.3746 - val_accuracy: 0.8424\n",
      "Epoch 9/100\n",
      "64092/64092 [==============================] - 130s 2ms/step - loss: 0.3721 - accuracy: 0.8432 - val_loss: 0.3751 - val_accuracy: 0.8410\n",
      "Epoch 10/100\n",
      "64092/64092 [==============================] - 141s 2ms/step - loss: 0.3714 - accuracy: 0.8433 - val_loss: 0.3745 - val_accuracy: 0.8422\n",
      "Epoch 11/100\n",
      "64092/64092 [==============================] - 151s 2ms/step - loss: 0.3706 - accuracy: 0.8436 - val_loss: 0.3773 - val_accuracy: 0.8413\n",
      "Epoch 12/100\n",
      "64092/64092 [==============================] - 149s 2ms/step - loss: 0.3701 - accuracy: 0.8439 - val_loss: 0.3729 - val_accuracy: 0.8413\n",
      "Epoch 13/100\n",
      "64092/64092 [==============================] - 150s 2ms/step - loss: 0.3698 - accuracy: 0.8440 - val_loss: 0.3707 - val_accuracy: 0.8443\n",
      "Epoch 14/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3694 - accuracy: 0.8443 - val_loss: 0.3710 - val_accuracy: 0.8446\n",
      "Epoch 15/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3690 - accuracy: 0.8442 - val_loss: 0.3730 - val_accuracy: 0.8443\n",
      "Epoch 16/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3687 - accuracy: 0.8445 - val_loss: 0.3714 - val_accuracy: 0.8438\n",
      "Epoch 17/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3685 - accuracy: 0.8445 - val_loss: 0.3704 - val_accuracy: 0.8445\n",
      "Epoch 18/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3682 - accuracy: 0.8446 - val_loss: 0.3711 - val_accuracy: 0.8443\n",
      "Epoch 19/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3680 - accuracy: 0.8448 - val_loss: 0.3734 - val_accuracy: 0.8416\n",
      "Epoch 20/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3678 - accuracy: 0.8447 - val_loss: 0.3702 - val_accuracy: 0.8441\n",
      "Epoch 21/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3676 - accuracy: 0.8449 - val_loss: 0.3696 - val_accuracy: 0.8454\n",
      "Epoch 22/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3675 - accuracy: 0.8450 - val_loss: 0.3700 - val_accuracy: 0.8435\n",
      "Epoch 23/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3673 - accuracy: 0.8450 - val_loss: 0.3713 - val_accuracy: 0.8441\n",
      "Epoch 24/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3673 - accuracy: 0.8450 - val_loss: 0.3696 - val_accuracy: 0.8435\n",
      "Epoch 25/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3670 - accuracy: 0.8452 - val_loss: 0.3704 - val_accuracy: 0.8449\n",
      "Epoch 26/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3670 - accuracy: 0.8451 - val_loss: 0.3713 - val_accuracy: 0.8438\n",
      "Epoch 27/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3669 - accuracy: 0.8450 - val_loss: 0.3692 - val_accuracy: 0.8449\n",
      "Epoch 28/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3666 - accuracy: 0.8453 - val_loss: 0.3701 - val_accuracy: 0.8445\n",
      "Epoch 29/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3666 - accuracy: 0.8453 - val_loss: 0.3698 - val_accuracy: 0.8448\n",
      "Epoch 30/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3665 - accuracy: 0.8452 - val_loss: 0.3701 - val_accuracy: 0.8438\n",
      "Epoch 31/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3665 - accuracy: 0.8453 - val_loss: 0.3693 - val_accuracy: 0.8441\n",
      "Epoch 32/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3665 - accuracy: 0.8453 - val_loss: 0.3687 - val_accuracy: 0.8450\n",
      "Epoch 33/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3663 - accuracy: 0.8453 - val_loss: 0.3720 - val_accuracy: 0.8436\n",
      "Epoch 34/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3662 - accuracy: 0.8454 - val_loss: 0.3692 - val_accuracy: 0.8446\n",
      "Epoch 35/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3662 - accuracy: 0.8454 - val_loss: 0.3707 - val_accuracy: 0.8429\n",
      "Epoch 36/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3662 - accuracy: 0.8455 - val_loss: 0.3709 - val_accuracy: 0.8435\n",
      "Epoch 37/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3660 - accuracy: 0.8455 - val_loss: 0.3703 - val_accuracy: 0.8437\n",
      "Epoch 38/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3659 - accuracy: 0.8456 - val_loss: 0.3680 - val_accuracy: 0.8435\n",
      "Epoch 39/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3659 - accuracy: 0.8456 - val_loss: 0.3684 - val_accuracy: 0.8443\n",
      "Epoch 40/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3658 - accuracy: 0.8455 - val_loss: 0.3687 - val_accuracy: 0.8448\n",
      "Epoch 41/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3657 - accuracy: 0.8456 - val_loss: 0.3684 - val_accuracy: 0.8439\n",
      "Epoch 42/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3659 - accuracy: 0.8454 - val_loss: 0.3683 - val_accuracy: 0.8444\n",
      "Epoch 43/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3657 - accuracy: 0.8457 - val_loss: 0.3712 - val_accuracy: 0.8450\n",
      "Epoch 44/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3656 - accuracy: 0.8455 - val_loss: 0.3687 - val_accuracy: 0.8434\n",
      "Epoch 45/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3656 - accuracy: 0.8456 - val_loss: 0.3692 - val_accuracy: 0.8436\n",
      "Epoch 46/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3656 - accuracy: 0.8456 - val_loss: 0.3682 - val_accuracy: 0.8440\n",
      "Epoch 47/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3655 - accuracy: 0.8453 - val_loss: 0.3683 - val_accuracy: 0.8449\n",
      "Epoch 48/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3654 - accuracy: 0.8457 - val_loss: 0.3687 - val_accuracy: 0.8442\n",
      "Epoch 49/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3654 - accuracy: 0.8456 - val_loss: 0.3678 - val_accuracy: 0.8448\n",
      "Epoch 50/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3653 - accuracy: 0.8457 - val_loss: 0.3678 - val_accuracy: 0.8444\n",
      "Epoch 51/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3654 - accuracy: 0.8456 - val_loss: 0.3674 - val_accuracy: 0.8451\n",
      "Epoch 52/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3654 - accuracy: 0.8457 - val_loss: 0.3688 - val_accuracy: 0.8438\n",
      "Epoch 53/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3653 - accuracy: 0.8458 - val_loss: 0.3698 - val_accuracy: 0.8441\n",
      "Epoch 54/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3653 - accuracy: 0.8456 - val_loss: 0.3699 - val_accuracy: 0.8450\n",
      "Epoch 55/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3652 - accuracy: 0.8459 - val_loss: 0.3746 - val_accuracy: 0.8412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3651 - accuracy: 0.8457 - val_loss: 0.3721 - val_accuracy: 0.8418\n",
      "Epoch 57/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3651 - accuracy: 0.8458 - val_loss: 0.3668 - val_accuracy: 0.8451\n",
      "Epoch 58/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3650 - accuracy: 0.8458 - val_loss: 0.3678 - val_accuracy: 0.8458\n",
      "Epoch 59/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3651 - accuracy: 0.8458 - val_loss: 0.3677 - val_accuracy: 0.8447\n",
      "Epoch 60/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3650 - accuracy: 0.8457 - val_loss: 0.3664 - val_accuracy: 0.8458\n",
      "Epoch 61/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3649 - accuracy: 0.8460 - val_loss: 0.3687 - val_accuracy: 0.8449\n",
      "Epoch 62/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3650 - accuracy: 0.8459 - val_loss: 0.3668 - val_accuracy: 0.8457\n",
      "Epoch 63/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3648 - accuracy: 0.8459 - val_loss: 0.3701 - val_accuracy: 0.8438\n",
      "Epoch 64/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3649 - accuracy: 0.8459 - val_loss: 0.3682 - val_accuracy: 0.8449\n",
      "Epoch 65/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3649 - accuracy: 0.8458 - val_loss: 0.3683 - val_accuracy: 0.8442\n",
      "Epoch 66/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3649 - accuracy: 0.8458 - val_loss: 0.3678 - val_accuracy: 0.8445\n",
      "Epoch 67/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3648 - accuracy: 0.8459 - val_loss: 0.3673 - val_accuracy: 0.8446\n",
      "Epoch 68/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3648 - accuracy: 0.8459 - val_loss: 0.3667 - val_accuracy: 0.8453\n",
      "Epoch 69/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3648 - accuracy: 0.8459 - val_loss: 0.3675 - val_accuracy: 0.8446\n",
      "Epoch 70/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3647 - accuracy: 0.8461 - val_loss: 0.3681 - val_accuracy: 0.8461\n",
      "Epoch 71/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3647 - accuracy: 0.8460 - val_loss: 0.3688 - val_accuracy: 0.8451\n",
      "Epoch 72/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3646 - accuracy: 0.8459 - val_loss: 0.3670 - val_accuracy: 0.8442\n",
      "Epoch 73/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3646 - accuracy: 0.8460 - val_loss: 0.3675 - val_accuracy: 0.8445\n",
      "Epoch 74/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3645 - accuracy: 0.8459 - val_loss: 0.3675 - val_accuracy: 0.8448\n",
      "Epoch 75/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3645 - accuracy: 0.8460 - val_loss: 0.3675 - val_accuracy: 0.8447\n",
      "Epoch 76/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3645 - accuracy: 0.8460 - val_loss: 0.3670 - val_accuracy: 0.8457\n",
      "Epoch 77/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3646 - accuracy: 0.8460 - val_loss: 0.3671 - val_accuracy: 0.8452\n",
      "Epoch 78/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3645 - accuracy: 0.8460 - val_loss: 0.3675 - val_accuracy: 0.8440\n",
      "Epoch 79/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3643 - accuracy: 0.8462 - val_loss: 0.3680 - val_accuracy: 0.8447\n",
      "Epoch 80/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3645 - accuracy: 0.8460 - val_loss: 0.3714 - val_accuracy: 0.8446\n",
      "Epoch 81/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3644 - accuracy: 0.8460 - val_loss: 0.3708 - val_accuracy: 0.8443\n",
      "Epoch 82/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3643 - accuracy: 0.8461 - val_loss: 0.3690 - val_accuracy: 0.8436\n",
      "Epoch 83/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3643 - accuracy: 0.8461 - val_loss: 0.3721 - val_accuracy: 0.8408\n",
      "Epoch 84/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3643 - accuracy: 0.8462 - val_loss: 0.3672 - val_accuracy: 0.8446\n",
      "Epoch 85/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3643 - accuracy: 0.8461 - val_loss: 0.3681 - val_accuracy: 0.8441\n",
      "Epoch 86/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3642 - accuracy: 0.8461 - val_loss: 0.3663 - val_accuracy: 0.8454\n",
      "Epoch 87/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3642 - accuracy: 0.8462 - val_loss: 0.3671 - val_accuracy: 0.8452\n",
      "Epoch 88/100\n",
      "64092/64092 [==============================] - 181s 3ms/step - loss: 0.3641 - accuracy: 0.8460 - val_loss: 0.3672 - val_accuracy: 0.8461\n",
      "Epoch 89/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3641 - accuracy: 0.8463 - val_loss: 0.3677 - val_accuracy: 0.8443\n",
      "Epoch 90/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3642 - accuracy: 0.8460 - val_loss: 0.3684 - val_accuracy: 0.8434\n",
      "Epoch 91/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3641 - accuracy: 0.8462 - val_loss: 0.3704 - val_accuracy: 0.8431\n",
      "Epoch 92/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3641 - accuracy: 0.8463 - val_loss: 0.3699 - val_accuracy: 0.8450\n",
      "Epoch 93/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3639 - accuracy: 0.8461 - val_loss: 0.3684 - val_accuracy: 0.8442\n",
      "Epoch 94/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3641 - accuracy: 0.8461 - val_loss: 0.3674 - val_accuracy: 0.8460\n",
      "Epoch 95/100\n",
      "64092/64092 [==============================] - 169s 3ms/step - loss: 0.3640 - accuracy: 0.8462 - val_loss: 0.3657 - val_accuracy: 0.8453\n",
      "Epoch 96/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3640 - accuracy: 0.8463 - val_loss: 0.3668 - val_accuracy: 0.8451\n",
      "Epoch 97/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3640 - accuracy: 0.8462 - val_loss: 0.3662 - val_accuracy: 0.8455\n",
      "Epoch 98/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3639 - accuracy: 0.8462 - val_loss: 0.3670 - val_accuracy: 0.8451\n",
      "Epoch 99/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3638 - accuracy: 0.8464 - val_loss: 0.3685 - val_accuracy: 0.8433\n",
      "Epoch 100/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3639 - accuracy: 0.8462 - val_loss: 0.3683 - val_accuracy: 0.8430\n",
      "time taken for training :  17666.927307128906\n",
      "time taken for per epoch :  176.66927307128907\n",
      "\n",
      "\n",
      "\n",
      " Test file no :  2\n",
      "Dataset has been successfully prepared\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2580624b3ff4951a942d77110fc1855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/8536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|████████████████| 10/10 [06:00<00:00, 36.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for training node embedding model :  3956.2943725585938\n",
      "<bound method NDFrame.head of           src  dest  label\n",
      "0        7124  7125      1\n",
      "1        7659  2555      0\n",
      "2        7988  6125      0\n",
      "3        7544  7990      0\n",
      "4        7789  7791      0\n",
      "...       ...   ...    ...\n",
      "1139397  8468  1112      0\n",
      "1139398  5452  7565      0\n",
      "1139399   948  7889      0\n",
      "1139400  8157  2931      0\n",
      "1139401  1071  8188      0\n",
      "\n",
      "[1139402 rows x 3 columns]>\n",
      "x_train and x_test are ready\n",
      "Epoch 1/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.4093 - accuracy: 0.8260 - val_loss: 0.3906 - val_accuracy: 0.8365\n",
      "Epoch 2/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3863 - accuracy: 0.8378 - val_loss: 0.3821 - val_accuracy: 0.8410\n",
      "Epoch 3/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3805 - accuracy: 0.8404 - val_loss: 0.3806 - val_accuracy: 0.8395\n",
      "Epoch 4/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3776 - accuracy: 0.8415 - val_loss: 0.3769 - val_accuracy: 0.8431\n",
      "Epoch 5/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3756 - accuracy: 0.8422 - val_loss: 0.3748 - val_accuracy: 0.8415\n",
      "Epoch 6/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3742 - accuracy: 0.8427 - val_loss: 0.3755 - val_accuracy: 0.8412\n",
      "Epoch 7/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3732 - accuracy: 0.8428 - val_loss: 0.3742 - val_accuracy: 0.8442\n",
      "Epoch 8/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3723 - accuracy: 0.8433 - val_loss: 0.3719 - val_accuracy: 0.8425\n",
      "Epoch 9/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3715 - accuracy: 0.8434 - val_loss: 0.3744 - val_accuracy: 0.8425\n",
      "Epoch 10/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3710 - accuracy: 0.8437 - val_loss: 0.3725 - val_accuracy: 0.8423\n",
      "Epoch 11/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3706 - accuracy: 0.8439 - val_loss: 0.3712 - val_accuracy: 0.8437\n",
      "Epoch 12/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3700 - accuracy: 0.8442 - val_loss: 0.3705 - val_accuracy: 0.8445\n",
      "Epoch 13/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3697 - accuracy: 0.8442 - val_loss: 0.3763 - val_accuracy: 0.8450\n",
      "Epoch 14/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3693 - accuracy: 0.8446 - val_loss: 0.3717 - val_accuracy: 0.8429\n",
      "Epoch 15/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3691 - accuracy: 0.8447 - val_loss: 0.3712 - val_accuracy: 0.8447\n",
      "Epoch 16/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3687 - accuracy: 0.8447 - val_loss: 0.3714 - val_accuracy: 0.8444\n",
      "Epoch 17/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3684 - accuracy: 0.8449 - val_loss: 0.3707 - val_accuracy: 0.8442\n",
      "Epoch 18/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3681 - accuracy: 0.8448 - val_loss: 0.3675 - val_accuracy: 0.8455\n",
      "Epoch 19/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3679 - accuracy: 0.8450 - val_loss: 0.3672 - val_accuracy: 0.8461\n",
      "Epoch 20/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3676 - accuracy: 0.8451 - val_loss: 0.3687 - val_accuracy: 0.8455\n",
      "Epoch 21/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3675 - accuracy: 0.8453 - val_loss: 0.3698 - val_accuracy: 0.8454\n",
      "Epoch 22/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3673 - accuracy: 0.8453 - val_loss: 0.3672 - val_accuracy: 0.8463\n",
      "Epoch 23/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3672 - accuracy: 0.8454 - val_loss: 0.3673 - val_accuracy: 0.8452\n",
      "Epoch 24/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3669 - accuracy: 0.8453 - val_loss: 0.3678 - val_accuracy: 0.8441\n",
      "Epoch 25/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3669 - accuracy: 0.8453 - val_loss: 0.3673 - val_accuracy: 0.8457\n",
      "Epoch 26/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3667 - accuracy: 0.8458 - val_loss: 0.3690 - val_accuracy: 0.8426\n",
      "Epoch 27/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3665 - accuracy: 0.8457 - val_loss: 0.3686 - val_accuracy: 0.8448\n",
      "Epoch 28/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3665 - accuracy: 0.8455 - val_loss: 0.3673 - val_accuracy: 0.8450\n",
      "Epoch 29/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3664 - accuracy: 0.8457 - val_loss: 0.3686 - val_accuracy: 0.8447\n",
      "Epoch 30/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3663 - accuracy: 0.8457 - val_loss: 0.3685 - val_accuracy: 0.8433\n",
      "Epoch 31/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3662 - accuracy: 0.8457 - val_loss: 0.3711 - val_accuracy: 0.8462\n",
      "Epoch 32/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3661 - accuracy: 0.8459 - val_loss: 0.3673 - val_accuracy: 0.8463\n",
      "Epoch 33/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3660 - accuracy: 0.8459 - val_loss: 0.3668 - val_accuracy: 0.8461\n",
      "Epoch 34/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3659 - accuracy: 0.8462 - val_loss: 0.3659 - val_accuracy: 0.8467\n",
      "Epoch 35/100\n",
      "64092/64092 [==============================] - 181s 3ms/step - loss: 0.3658 - accuracy: 0.8460 - val_loss: 0.3663 - val_accuracy: 0.8447\n",
      "Epoch 36/100\n",
      "64092/64092 [==============================] - 180s 3ms/step - loss: 0.3658 - accuracy: 0.8459 - val_loss: 0.3667 - val_accuracy: 0.8465\n",
      "Epoch 37/100\n",
      "64092/64092 [==============================] - 180s 3ms/step - loss: 0.3655 - accuracy: 0.8461 - val_loss: 0.3667 - val_accuracy: 0.8456\n",
      "Epoch 38/100\n",
      "64092/64092 [==============================] - 181s 3ms/step - loss: 0.3656 - accuracy: 0.8462 - val_loss: 0.3659 - val_accuracy: 0.8459\n",
      "Epoch 39/100\n",
      "64092/64092 [==============================] - 181s 3ms/step - loss: 0.3655 - accuracy: 0.8459 - val_loss: 0.3676 - val_accuracy: 0.8447\n",
      "Epoch 40/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3654 - accuracy: 0.8464 - val_loss: 0.3686 - val_accuracy: 0.8441\n",
      "Epoch 41/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3654 - accuracy: 0.8462 - val_loss: 0.3671 - val_accuracy: 0.8467\n",
      "Epoch 42/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3653 - accuracy: 0.8464 - val_loss: 0.3671 - val_accuracy: 0.8479\n",
      "Epoch 43/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3652 - accuracy: 0.8465 - val_loss: 0.3667 - val_accuracy: 0.8474\n",
      "Epoch 44/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3652 - accuracy: 0.8465 - val_loss: 0.3653 - val_accuracy: 0.8472\n",
      "Epoch 45/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3651 - accuracy: 0.8464 - val_loss: 0.3671 - val_accuracy: 0.8477\n",
      "Epoch 46/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3650 - accuracy: 0.8466 - val_loss: 0.3672 - val_accuracy: 0.8476\n",
      "Epoch 47/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3649 - accuracy: 0.8464 - val_loss: 0.3655 - val_accuracy: 0.8462\n",
      "Epoch 48/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3649 - accuracy: 0.8466 - val_loss: 0.3661 - val_accuracy: 0.8466\n",
      "Epoch 49/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3646 - accuracy: 0.8467 - val_loss: 0.3668 - val_accuracy: 0.8449\n",
      "Epoch 50/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3647 - accuracy: 0.8465 - val_loss: 0.3661 - val_accuracy: 0.8469\n",
      "Epoch 51/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3646 - accuracy: 0.8466 - val_loss: 0.3663 - val_accuracy: 0.8454\n",
      "Epoch 52/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3645 - accuracy: 0.8468 - val_loss: 0.3705 - val_accuracy: 0.8432\n",
      "Epoch 53/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3644 - accuracy: 0.8470 - val_loss: 0.3654 - val_accuracy: 0.8460\n",
      "Epoch 54/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3644 - accuracy: 0.8467 - val_loss: 0.3673 - val_accuracy: 0.8461\n",
      "Epoch 55/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3643 - accuracy: 0.8470 - val_loss: 0.3663 - val_accuracy: 0.8459\n",
      "Epoch 56/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3643 - accuracy: 0.8470 - val_loss: 0.3659 - val_accuracy: 0.8461\n",
      "Epoch 57/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3642 - accuracy: 0.8470 - val_loss: 0.3650 - val_accuracy: 0.8466\n",
      "Epoch 58/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3641 - accuracy: 0.8470 - val_loss: 0.3652 - val_accuracy: 0.8469\n",
      "Epoch 59/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3641 - accuracy: 0.8471 - val_loss: 0.3640 - val_accuracy: 0.8480\n",
      "Epoch 60/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3641 - accuracy: 0.8469 - val_loss: 0.3643 - val_accuracy: 0.8477\n",
      "Epoch 61/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3640 - accuracy: 0.8471 - val_loss: 0.3642 - val_accuracy: 0.8465\n",
      "Epoch 62/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3640 - accuracy: 0.8471 - val_loss: 0.3664 - val_accuracy: 0.8441\n",
      "Epoch 63/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3638 - accuracy: 0.8470 - val_loss: 0.3649 - val_accuracy: 0.8477\n",
      "Epoch 64/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3640 - accuracy: 0.8469 - val_loss: 0.3682 - val_accuracy: 0.8474\n",
      "Epoch 65/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3637 - accuracy: 0.8470 - val_loss: 0.3644 - val_accuracy: 0.8477\n",
      "Epoch 66/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3638 - accuracy: 0.8469 - val_loss: 0.3646 - val_accuracy: 0.8466\n",
      "Epoch 67/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3638 - accuracy: 0.8472 - val_loss: 0.3658 - val_accuracy: 0.8449\n",
      "Epoch 68/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3637 - accuracy: 0.8471 - val_loss: 0.3647 - val_accuracy: 0.8484\n",
      "Epoch 69/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3637 - accuracy: 0.8473 - val_loss: 0.3641 - val_accuracy: 0.8476\n",
      "Epoch 70/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3637 - accuracy: 0.8471 - val_loss: 0.3646 - val_accuracy: 0.8466\n",
      "Epoch 71/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3636 - accuracy: 0.8471 - val_loss: 0.3681 - val_accuracy: 0.8476\n",
      "Epoch 72/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3636 - accuracy: 0.8473 - val_loss: 0.3637 - val_accuracy: 0.8472\n",
      "Epoch 73/100\n",
      "64092/64092 [==============================] - 181s 3ms/step - loss: 0.3635 - accuracy: 0.8473 - val_loss: 0.3655 - val_accuracy: 0.8474\n",
      "Epoch 74/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3635 - accuracy: 0.8474 - val_loss: 0.3646 - val_accuracy: 0.8475\n",
      "Epoch 75/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3636 - accuracy: 0.8472 - val_loss: 0.3645 - val_accuracy: 0.8480\n",
      "Epoch 76/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3635 - accuracy: 0.8473 - val_loss: 0.3653 - val_accuracy: 0.8451\n",
      "Epoch 77/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3635 - accuracy: 0.8474 - val_loss: 0.3634 - val_accuracy: 0.8482\n",
      "Epoch 78/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3634 - accuracy: 0.8473 - val_loss: 0.3668 - val_accuracy: 0.8477\n",
      "Epoch 79/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3634 - accuracy: 0.8474 - val_loss: 0.3644 - val_accuracy: 0.8475\n",
      "Epoch 80/100\n",
      "64092/64092 [==============================] - 170s 3ms/step - loss: 0.3634 - accuracy: 0.8472 - val_loss: 0.3680 - val_accuracy: 0.8466\n",
      "Epoch 81/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3633 - accuracy: 0.8474 - val_loss: 0.3657 - val_accuracy: 0.8476\n",
      "Epoch 82/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3634 - accuracy: 0.8472 - val_loss: 0.3650 - val_accuracy: 0.8475\n",
      "Epoch 83/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3632 - accuracy: 0.8475 - val_loss: 0.3636 - val_accuracy: 0.8471\n",
      "Epoch 84/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3632 - accuracy: 0.8473 - val_loss: 0.3661 - val_accuracy: 0.8471\n",
      "Epoch 85/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3631 - accuracy: 0.8472 - val_loss: 0.3640 - val_accuracy: 0.8471\n",
      "Epoch 86/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3633 - accuracy: 0.8473 - val_loss: 0.3650 - val_accuracy: 0.8463\n",
      "Epoch 87/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3632 - accuracy: 0.8472 - val_loss: 0.3649 - val_accuracy: 0.8481\n",
      "Epoch 88/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3631 - accuracy: 0.8474 - val_loss: 0.3706 - val_accuracy: 0.8470\n",
      "Epoch 89/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3632 - accuracy: 0.8472 - val_loss: 0.3662 - val_accuracy: 0.8476\n",
      "Epoch 90/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3631 - accuracy: 0.8474 - val_loss: 0.3650 - val_accuracy: 0.8463\n",
      "Epoch 91/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3632 - accuracy: 0.8474 - val_loss: 0.3649 - val_accuracy: 0.8464\n",
      "Epoch 92/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3631 - accuracy: 0.8473 - val_loss: 0.3641 - val_accuracy: 0.8464\n",
      "Epoch 93/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3631 - accuracy: 0.8475 - val_loss: 0.3650 - val_accuracy: 0.8479\n",
      "Epoch 94/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3631 - accuracy: 0.8473 - val_loss: 0.3665 - val_accuracy: 0.8471\n",
      "Epoch 95/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3630 - accuracy: 0.8473 - val_loss: 0.3644 - val_accuracy: 0.8462\n",
      "Epoch 96/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3630 - accuracy: 0.8472 - val_loss: 0.3657 - val_accuracy: 0.8446\n",
      "Epoch 97/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3629 - accuracy: 0.8474 - val_loss: 0.3652 - val_accuracy: 0.8482\n",
      "Epoch 98/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3629 - accuracy: 0.8475 - val_loss: 0.3645 - val_accuracy: 0.8462\n",
      "Epoch 99/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3630 - accuracy: 0.8473 - val_loss: 0.3642 - val_accuracy: 0.8478\n",
      "Epoch 100/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3629 - accuracy: 0.8473 - val_loss: 0.3649 - val_accuracy: 0.8471\n",
      "time taken for training :  18416.337570905685\n",
      "time taken for per epoch :  184.16337570905685\n",
      "\n",
      "\n",
      "\n",
      " Test file no :  3\n",
      "Dataset has been successfully prepared\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc97172e0b88433da0259e83bcea5d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/8536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|████████████████| 10/10 [05:59<00:00, 35.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for training node embedding model :  3967.5005073547363\n",
      "<bound method NDFrame.head of           src  dest  label\n",
      "0        7690  3942      0\n",
      "1        7606  7611      1\n",
      "2        7484  7796      0\n",
      "3        5153  5176      1\n",
      "4        5404  6160      1\n",
      "...       ...   ...    ...\n",
      "1139397  4984  7320      1\n",
      "1139398  8402  8472      1\n",
      "1139399  7358  3593      0\n",
      "1139400  4978  1785      0\n",
      "1139401  5548  7535      1\n",
      "\n",
      "[1139402 rows x 3 columns]>\n",
      "x_train and x_test are ready\n",
      "Epoch 1/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.4040 - accuracy: 0.8281 - val_loss: 0.3955 - val_accuracy: 0.8306\n",
      "Epoch 2/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3853 - accuracy: 0.8376 - val_loss: 0.3840 - val_accuracy: 0.8382\n",
      "Epoch 3/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3809 - accuracy: 0.8399 - val_loss: 0.3820 - val_accuracy: 0.8377\n",
      "Epoch 4/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3784 - accuracy: 0.8408 - val_loss: 0.3794 - val_accuracy: 0.8408\n",
      "Epoch 5/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3762 - accuracy: 0.8418 - val_loss: 0.3765 - val_accuracy: 0.8411\n",
      "Epoch 6/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3746 - accuracy: 0.8427 - val_loss: 0.3767 - val_accuracy: 0.8403\n",
      "Epoch 7/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3733 - accuracy: 0.8431 - val_loss: 0.3734 - val_accuracy: 0.8423\n",
      "Epoch 8/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3725 - accuracy: 0.8434 - val_loss: 0.3741 - val_accuracy: 0.8416\n",
      "Epoch 9/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3718 - accuracy: 0.8436 - val_loss: 0.3750 - val_accuracy: 0.8418\n",
      "Epoch 10/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3712 - accuracy: 0.8439 - val_loss: 0.3842 - val_accuracy: 0.8358\n",
      "Epoch 11/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3707 - accuracy: 0.8443 - val_loss: 0.3743 - val_accuracy: 0.8430\n",
      "Epoch 12/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3703 - accuracy: 0.8444 - val_loss: 0.3707 - val_accuracy: 0.8429\n",
      "Epoch 13/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3697 - accuracy: 0.8447 - val_loss: 0.3728 - val_accuracy: 0.8425\n",
      "Epoch 14/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3694 - accuracy: 0.8447 - val_loss: 0.3721 - val_accuracy: 0.8433\n",
      "Epoch 15/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3691 - accuracy: 0.8449 - val_loss: 0.3736 - val_accuracy: 0.8416\n",
      "Epoch 16/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3687 - accuracy: 0.8452 - val_loss: 0.3715 - val_accuracy: 0.8437\n",
      "Epoch 17/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3683 - accuracy: 0.8454 - val_loss: 0.3751 - val_accuracy: 0.8397\n",
      "Epoch 18/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3682 - accuracy: 0.8455 - val_loss: 0.3740 - val_accuracy: 0.8440\n",
      "Epoch 19/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3680 - accuracy: 0.8456 - val_loss: 0.3715 - val_accuracy: 0.8425\n",
      "Epoch 20/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3679 - accuracy: 0.8455 - val_loss: 0.3792 - val_accuracy: 0.8376\n",
      "Epoch 21/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3676 - accuracy: 0.8457 - val_loss: 0.3695 - val_accuracy: 0.8440\n",
      "Epoch 22/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3673 - accuracy: 0.8460 - val_loss: 0.3793 - val_accuracy: 0.8371\n",
      "Epoch 23/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3672 - accuracy: 0.8457 - val_loss: 0.3698 - val_accuracy: 0.8434\n",
      "Epoch 24/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3669 - accuracy: 0.8458 - val_loss: 0.3699 - val_accuracy: 0.8443\n",
      "Epoch 25/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3668 - accuracy: 0.8460 - val_loss: 0.3705 - val_accuracy: 0.8443\n",
      "Epoch 26/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3668 - accuracy: 0.8459 - val_loss: 0.3694 - val_accuracy: 0.8430\n",
      "Epoch 27/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3667 - accuracy: 0.8462 - val_loss: 0.3699 - val_accuracy: 0.8446\n",
      "Epoch 28/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3664 - accuracy: 0.8460 - val_loss: 0.3718 - val_accuracy: 0.8449\n",
      "Epoch 29/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3664 - accuracy: 0.8461 - val_loss: 0.3698 - val_accuracy: 0.8428\n",
      "Epoch 30/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3663 - accuracy: 0.8463 - val_loss: 0.3693 - val_accuracy: 0.8441\n",
      "Epoch 31/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3661 - accuracy: 0.8462 - val_loss: 0.3702 - val_accuracy: 0.8445\n",
      "Epoch 32/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3660 - accuracy: 0.8464 - val_loss: 0.3694 - val_accuracy: 0.8454\n",
      "Epoch 33/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3659 - accuracy: 0.8463 - val_loss: 0.3682 - val_accuracy: 0.8442\n",
      "Epoch 34/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3659 - accuracy: 0.8463 - val_loss: 0.3676 - val_accuracy: 0.8447\n",
      "Epoch 35/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3657 - accuracy: 0.8465 - val_loss: 0.3677 - val_accuracy: 0.8451\n",
      "Epoch 36/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3657 - accuracy: 0.8466 - val_loss: 0.3693 - val_accuracy: 0.8433\n",
      "Epoch 37/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3656 - accuracy: 0.8465 - val_loss: 0.3688 - val_accuracy: 0.8432\n",
      "Epoch 38/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3656 - accuracy: 0.8464 - val_loss: 0.3693 - val_accuracy: 0.8454\n",
      "Epoch 39/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3654 - accuracy: 0.8466 - val_loss: 0.3740 - val_accuracy: 0.8439\n",
      "Epoch 40/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3654 - accuracy: 0.8467 - val_loss: 0.3698 - val_accuracy: 0.8435\n",
      "Epoch 41/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3653 - accuracy: 0.8466 - val_loss: 0.3692 - val_accuracy: 0.8448\n",
      "Epoch 42/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3653 - accuracy: 0.8465 - val_loss: 0.3672 - val_accuracy: 0.8441\n",
      "Epoch 43/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3652 - accuracy: 0.8466 - val_loss: 0.3678 - val_accuracy: 0.8455\n",
      "Epoch 44/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3651 - accuracy: 0.8465 - val_loss: 0.3706 - val_accuracy: 0.8416\n",
      "Epoch 45/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3651 - accuracy: 0.8469 - val_loss: 0.3696 - val_accuracy: 0.8448\n",
      "Epoch 46/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3650 - accuracy: 0.8467 - val_loss: 0.3675 - val_accuracy: 0.8447\n",
      "Epoch 47/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3651 - accuracy: 0.8467 - val_loss: 0.3677 - val_accuracy: 0.8444\n",
      "Epoch 48/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3650 - accuracy: 0.8468 - val_loss: 0.3700 - val_accuracy: 0.8450\n",
      "Epoch 49/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3650 - accuracy: 0.8467 - val_loss: 0.3696 - val_accuracy: 0.8423\n",
      "Epoch 50/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3649 - accuracy: 0.8468 - val_loss: 0.3682 - val_accuracy: 0.8444\n",
      "Epoch 51/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3649 - accuracy: 0.8468 - val_loss: 0.3717 - val_accuracy: 0.8445\n",
      "Epoch 52/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3647 - accuracy: 0.8468 - val_loss: 0.3714 - val_accuracy: 0.8444\n",
      "Epoch 53/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3648 - accuracy: 0.8467 - val_loss: 0.3669 - val_accuracy: 0.8444\n",
      "Epoch 54/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3647 - accuracy: 0.8469 - val_loss: 0.3701 - val_accuracy: 0.8448\n",
      "Epoch 55/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3647 - accuracy: 0.8469 - val_loss: 0.3719 - val_accuracy: 0.8408\n",
      "Epoch 56/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3646 - accuracy: 0.8469 - val_loss: 0.3688 - val_accuracy: 0.8453\n",
      "Epoch 57/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3646 - accuracy: 0.8470 - val_loss: 0.3761 - val_accuracy: 0.8401\n",
      "Epoch 58/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3645 - accuracy: 0.8470 - val_loss: 0.3682 - val_accuracy: 0.8454\n",
      "Epoch 59/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3644 - accuracy: 0.8471 - val_loss: 0.3667 - val_accuracy: 0.8443\n",
      "Epoch 60/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3644 - accuracy: 0.8469 - val_loss: 0.3736 - val_accuracy: 0.8447\n",
      "Epoch 61/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3644 - accuracy: 0.8470 - val_loss: 0.3677 - val_accuracy: 0.8449\n",
      "Epoch 62/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3643 - accuracy: 0.8470 - val_loss: 0.3674 - val_accuracy: 0.8443\n",
      "Epoch 63/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3644 - accuracy: 0.8470 - val_loss: 0.3688 - val_accuracy: 0.8431\n",
      "Epoch 64/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3643 - accuracy: 0.8470 - val_loss: 0.3668 - val_accuracy: 0.8450\n",
      "Epoch 65/100\n",
      "64092/64092 [==============================] - 171s 3ms/step - loss: 0.3642 - accuracy: 0.8471 - val_loss: 0.3657 - val_accuracy: 0.8458\n",
      "Epoch 66/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3642 - accuracy: 0.8470 - val_loss: 0.3682 - val_accuracy: 0.8422\n",
      "Epoch 67/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3642 - accuracy: 0.8471 - val_loss: 0.3665 - val_accuracy: 0.8452\n",
      "Epoch 68/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3642 - accuracy: 0.8470 - val_loss: 0.3667 - val_accuracy: 0.8445\n",
      "Epoch 69/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3642 - accuracy: 0.8470 - val_loss: 0.3673 - val_accuracy: 0.8452\n",
      "Epoch 70/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3641 - accuracy: 0.8471 - val_loss: 0.3664 - val_accuracy: 0.8443\n",
      "Epoch 71/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3641 - accuracy: 0.8471 - val_loss: 0.3695 - val_accuracy: 0.8425\n",
      "Epoch 72/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3640 - accuracy: 0.8472 - val_loss: 0.3666 - val_accuracy: 0.8448\n",
      "Epoch 73/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3640 - accuracy: 0.8469 - val_loss: 0.3674 - val_accuracy: 0.8439\n",
      "Epoch 74/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3639 - accuracy: 0.8472 - val_loss: 0.3670 - val_accuracy: 0.8453\n",
      "Epoch 75/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3639 - accuracy: 0.8473 - val_loss: 0.3670 - val_accuracy: 0.8452\n",
      "Epoch 76/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3638 - accuracy: 0.8473 - val_loss: 0.3672 - val_accuracy: 0.8449\n",
      "Epoch 77/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3639 - accuracy: 0.8471 - val_loss: 0.3659 - val_accuracy: 0.8451\n",
      "Epoch 78/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3639 - accuracy: 0.8470 - val_loss: 0.3734 - val_accuracy: 0.8447\n",
      "Epoch 79/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3639 - accuracy: 0.8472 - val_loss: 0.3666 - val_accuracy: 0.8446\n",
      "Epoch 80/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3637 - accuracy: 0.8471 - val_loss: 0.3714 - val_accuracy: 0.8443\n",
      "Epoch 81/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3638 - accuracy: 0.8472 - val_loss: 0.3694 - val_accuracy: 0.8415\n",
      "Epoch 82/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3637 - accuracy: 0.8472 - val_loss: 0.3666 - val_accuracy: 0.8442\n",
      "Epoch 83/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3637 - accuracy: 0.8474 - val_loss: 0.3661 - val_accuracy: 0.8450\n",
      "Epoch 84/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3637 - accuracy: 0.8474 - val_loss: 0.3663 - val_accuracy: 0.8440\n",
      "Epoch 85/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3636 - accuracy: 0.8473 - val_loss: 0.3664 - val_accuracy: 0.8451\n",
      "Epoch 86/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3637 - accuracy: 0.8471 - val_loss: 0.3673 - val_accuracy: 0.8447\n",
      "Epoch 87/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3636 - accuracy: 0.8473 - val_loss: 0.3659 - val_accuracy: 0.8447\n",
      "Epoch 88/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3636 - accuracy: 0.8474 - val_loss: 0.3695 - val_accuracy: 0.8448\n",
      "Epoch 89/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3635 - accuracy: 0.8472 - val_loss: 0.3676 - val_accuracy: 0.8449\n",
      "Epoch 90/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3635 - accuracy: 0.8474 - val_loss: 0.3671 - val_accuracy: 0.8455\n",
      "Epoch 91/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3635 - accuracy: 0.8475 - val_loss: 0.3655 - val_accuracy: 0.8445\n",
      "Epoch 92/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3635 - accuracy: 0.8473 - val_loss: 0.3728 - val_accuracy: 0.8445\n",
      "Epoch 93/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3634 - accuracy: 0.8474 - val_loss: 0.3719 - val_accuracy: 0.8445\n",
      "Epoch 94/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3634 - accuracy: 0.8474 - val_loss: 0.3662 - val_accuracy: 0.8451\n",
      "Epoch 95/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3634 - accuracy: 0.8473 - val_loss: 0.3672 - val_accuracy: 0.8455\n",
      "Epoch 96/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3634 - accuracy: 0.8473 - val_loss: 0.3658 - val_accuracy: 0.8448\n",
      "Epoch 97/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3633 - accuracy: 0.8475 - val_loss: 0.3650 - val_accuracy: 0.8451\n",
      "Epoch 98/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3633 - accuracy: 0.8473 - val_loss: 0.3659 - val_accuracy: 0.8433\n",
      "Epoch 99/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3632 - accuracy: 0.8476 - val_loss: 0.3675 - val_accuracy: 0.8448\n",
      "Epoch 100/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3632 - accuracy: 0.8475 - val_loss: 0.3691 - val_accuracy: 0.8449\n",
      "time taken for training :  18516.194984436035\n",
      "time taken for per epoch :  185.16194984436035\n",
      "\n",
      "\n",
      "\n",
      " Test file no :  4\n",
      "Dataset has been successfully prepared\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972342a711124d248ae804b3b9f16e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/8536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|████████████████| 10/10 [05:59<00:00, 35.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for training node embedding model :  3971.582831144333\n",
      "<bound method NDFrame.head of           src  dest  label\n",
      "0        4510   616      0\n",
      "1        5078  6620      1\n",
      "2        5523  7152      1\n",
      "3        5392  7443      1\n",
      "4          39   947      1\n",
      "...       ...   ...    ...\n",
      "1139397   245  2266      1\n",
      "1139398  3836  6023      0\n",
      "1139399  6444  8311      1\n",
      "1139400  6214  1934      0\n",
      "1139401  2593  5925      0\n",
      "\n",
      "[1139402 rows x 3 columns]>\n",
      "x_train and x_test are ready\n",
      "Epoch 1/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.4083 - accuracy: 0.8254 - val_loss: 0.3898 - val_accuracy: 0.8350\n",
      "Epoch 2/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3884 - accuracy: 0.8357 - val_loss: 0.3897 - val_accuracy: 0.8372\n",
      "Epoch 3/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3833 - accuracy: 0.8378 - val_loss: 0.3911 - val_accuracy: 0.8324\n",
      "Epoch 4/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3804 - accuracy: 0.8391 - val_loss: 0.3867 - val_accuracy: 0.8349\n",
      "Epoch 5/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3784 - accuracy: 0.8399 - val_loss: 0.3786 - val_accuracy: 0.8402\n",
      "Epoch 6/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3767 - accuracy: 0.8408 - val_loss: 0.3751 - val_accuracy: 0.8418\n",
      "Epoch 7/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3755 - accuracy: 0.8412 - val_loss: 0.3756 - val_accuracy: 0.8411\n",
      "Epoch 8/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3746 - accuracy: 0.8415 - val_loss: 0.3749 - val_accuracy: 0.8423\n",
      "Epoch 9/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3737 - accuracy: 0.8420 - val_loss: 0.3755 - val_accuracy: 0.8427\n",
      "Epoch 10/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3729 - accuracy: 0.8422 - val_loss: 0.3742 - val_accuracy: 0.8415\n",
      "Epoch 11/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3723 - accuracy: 0.8427 - val_loss: 0.3730 - val_accuracy: 0.8426\n",
      "Epoch 12/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3719 - accuracy: 0.8426 - val_loss: 0.3752 - val_accuracy: 0.8404\n",
      "Epoch 13/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3715 - accuracy: 0.8428 - val_loss: 0.3715 - val_accuracy: 0.8434\n",
      "Epoch 14/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3711 - accuracy: 0.8430 - val_loss: 0.3745 - val_accuracy: 0.8432\n",
      "Epoch 15/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3708 - accuracy: 0.8430 - val_loss: 0.3726 - val_accuracy: 0.8412\n",
      "Epoch 16/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3705 - accuracy: 0.8433 - val_loss: 0.3735 - val_accuracy: 0.8422\n",
      "Epoch 17/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3703 - accuracy: 0.8434 - val_loss: 0.3704 - val_accuracy: 0.8432\n",
      "Epoch 18/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3699 - accuracy: 0.8435 - val_loss: 0.3718 - val_accuracy: 0.8423\n",
      "Epoch 19/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3697 - accuracy: 0.8435 - val_loss: 0.3728 - val_accuracy: 0.8409\n",
      "Epoch 20/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3696 - accuracy: 0.8435 - val_loss: 0.3703 - val_accuracy: 0.8438\n",
      "Epoch 21/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3694 - accuracy: 0.8436 - val_loss: 0.3700 - val_accuracy: 0.8434\n",
      "Epoch 22/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3692 - accuracy: 0.8436 - val_loss: 0.3752 - val_accuracy: 0.8440\n",
      "Epoch 23/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3691 - accuracy: 0.8438 - val_loss: 0.3714 - val_accuracy: 0.8426\n",
      "Epoch 24/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3689 - accuracy: 0.8438 - val_loss: 0.3734 - val_accuracy: 0.8434\n",
      "Epoch 25/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3689 - accuracy: 0.8439 - val_loss: 0.3730 - val_accuracy: 0.8417\n",
      "Epoch 26/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3686 - accuracy: 0.8439 - val_loss: 0.3700 - val_accuracy: 0.8439\n",
      "Epoch 27/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3684 - accuracy: 0.8441 - val_loss: 0.3704 - val_accuracy: 0.8430\n",
      "Epoch 28/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3684 - accuracy: 0.8440 - val_loss: 0.3745 - val_accuracy: 0.8408\n",
      "Epoch 29/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3682 - accuracy: 0.8441 - val_loss: 0.3702 - val_accuracy: 0.8426\n",
      "Epoch 30/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3681 - accuracy: 0.8440 - val_loss: 0.3677 - val_accuracy: 0.8443\n",
      "Epoch 31/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3680 - accuracy: 0.8442 - val_loss: 0.3725 - val_accuracy: 0.8421\n",
      "Epoch 32/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3678 - accuracy: 0.8443 - val_loss: 0.3682 - val_accuracy: 0.8442\n",
      "Epoch 33/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3678 - accuracy: 0.8444 - val_loss: 0.3707 - val_accuracy: 0.8452\n",
      "Epoch 34/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3677 - accuracy: 0.8444 - val_loss: 0.3718 - val_accuracy: 0.8445\n",
      "Epoch 35/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3677 - accuracy: 0.8443 - val_loss: 0.3692 - val_accuracy: 0.8455\n",
      "Epoch 36/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3675 - accuracy: 0.8445 - val_loss: 0.3682 - val_accuracy: 0.8452\n",
      "Epoch 37/100\n",
      "64092/64092 [==============================] - 181s 3ms/step - loss: 0.3675 - accuracy: 0.8444 - val_loss: 0.3680 - val_accuracy: 0.8440\n",
      "Epoch 38/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3672 - accuracy: 0.8445 - val_loss: 0.3733 - val_accuracy: 0.8431\n",
      "Epoch 39/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3672 - accuracy: 0.8446 - val_loss: 0.3688 - val_accuracy: 0.8442\n",
      "Epoch 40/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3671 - accuracy: 0.8446 - val_loss: 0.3713 - val_accuracy: 0.8416\n",
      "Epoch 41/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3671 - accuracy: 0.8446 - val_loss: 0.3685 - val_accuracy: 0.8431\n",
      "Epoch 42/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3669 - accuracy: 0.8447 - val_loss: 0.3693 - val_accuracy: 0.8443\n",
      "Epoch 43/100\n",
      "64092/64092 [==============================] - 180s 3ms/step - loss: 0.3670 - accuracy: 0.8447 - val_loss: 0.3678 - val_accuracy: 0.8440\n",
      "Epoch 44/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3668 - accuracy: 0.8449 - val_loss: 0.3703 - val_accuracy: 0.8421\n",
      "Epoch 45/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3669 - accuracy: 0.8447 - val_loss: 0.3685 - val_accuracy: 0.8454\n",
      "Epoch 46/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3668 - accuracy: 0.8448 - val_loss: 0.3715 - val_accuracy: 0.8420\n",
      "Epoch 47/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3667 - accuracy: 0.8450 - val_loss: 0.3686 - val_accuracy: 0.8454\n",
      "Epoch 48/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3668 - accuracy: 0.8449 - val_loss: 0.3670 - val_accuracy: 0.8445\n",
      "Epoch 49/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3667 - accuracy: 0.8449 - val_loss: 0.3693 - val_accuracy: 0.8430\n",
      "Epoch 50/100\n",
      "64092/64092 [==============================] - 170s 3ms/step - loss: 0.3666 - accuracy: 0.8448 - val_loss: 0.3694 - val_accuracy: 0.8458\n",
      "Epoch 51/100\n",
      "64092/64092 [==============================] - 190s 3ms/step - loss: 0.3665 - accuracy: 0.8450 - val_loss: 0.3692 - val_accuracy: 0.8451\n",
      "Epoch 52/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3665 - accuracy: 0.8451 - val_loss: 0.3672 - val_accuracy: 0.8441\n",
      "Epoch 53/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3665 - accuracy: 0.8450 - val_loss: 0.3673 - val_accuracy: 0.8439\n",
      "Epoch 54/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3664 - accuracy: 0.8451 - val_loss: 0.3673 - val_accuracy: 0.8447\n",
      "Epoch 55/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3664 - accuracy: 0.8452 - val_loss: 0.3675 - val_accuracy: 0.8454\n",
      "Epoch 56/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3663 - accuracy: 0.8452 - val_loss: 0.3691 - val_accuracy: 0.8438\n",
      "Epoch 57/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3662 - accuracy: 0.8453 - val_loss: 0.3670 - val_accuracy: 0.8456\n",
      "Epoch 58/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3661 - accuracy: 0.8452 - val_loss: 0.3675 - val_accuracy: 0.8447\n",
      "Epoch 59/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3661 - accuracy: 0.8453 - val_loss: 0.3684 - val_accuracy: 0.8450\n",
      "Epoch 60/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3661 - accuracy: 0.8451 - val_loss: 0.3677 - val_accuracy: 0.8455\n",
      "Epoch 61/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3660 - accuracy: 0.8453 - val_loss: 0.3689 - val_accuracy: 0.8461\n",
      "Epoch 62/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3661 - accuracy: 0.8452 - val_loss: 0.3664 - val_accuracy: 0.8448\n",
      "Epoch 63/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3659 - accuracy: 0.8453 - val_loss: 0.3685 - val_accuracy: 0.8439\n",
      "Epoch 64/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3660 - accuracy: 0.8452 - val_loss: 0.3669 - val_accuracy: 0.8447\n",
      "Epoch 65/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3658 - accuracy: 0.8454 - val_loss: 0.3681 - val_accuracy: 0.8430\n",
      "Epoch 66/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3658 - accuracy: 0.8451 - val_loss: 0.3677 - val_accuracy: 0.8454\n",
      "Epoch 67/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3657 - accuracy: 0.8453 - val_loss: 0.3686 - val_accuracy: 0.8441\n",
      "Epoch 68/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3657 - accuracy: 0.8454 - val_loss: 0.3673 - val_accuracy: 0.8447\n",
      "Epoch 69/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3656 - accuracy: 0.8454 - val_loss: 0.3666 - val_accuracy: 0.8456\n",
      "Epoch 70/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3656 - accuracy: 0.8454 - val_loss: 0.3668 - val_accuracy: 0.8444\n",
      "Epoch 71/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3655 - accuracy: 0.8454 - val_loss: 0.3668 - val_accuracy: 0.8457\n",
      "Epoch 72/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3654 - accuracy: 0.8454 - val_loss: 0.3672 - val_accuracy: 0.8449\n",
      "Epoch 73/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3654 - accuracy: 0.8453 - val_loss: 0.3662 - val_accuracy: 0.8450\n",
      "Epoch 74/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3653 - accuracy: 0.8454 - val_loss: 0.3667 - val_accuracy: 0.8462\n",
      "Epoch 75/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3653 - accuracy: 0.8455 - val_loss: 0.3688 - val_accuracy: 0.8464\n",
      "Epoch 76/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3652 - accuracy: 0.8453 - val_loss: 0.3683 - val_accuracy: 0.8453\n",
      "Epoch 77/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3653 - accuracy: 0.8454 - val_loss: 0.3712 - val_accuracy: 0.8421\n",
      "Epoch 78/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3652 - accuracy: 0.8454 - val_loss: 0.3655 - val_accuracy: 0.8455\n",
      "Epoch 79/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3652 - accuracy: 0.8454 - val_loss: 0.3715 - val_accuracy: 0.8420\n",
      "Epoch 80/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3652 - accuracy: 0.8453 - val_loss: 0.3687 - val_accuracy: 0.8455\n",
      "Epoch 81/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3650 - accuracy: 0.8456 - val_loss: 0.3668 - val_accuracy: 0.8452\n",
      "Epoch 82/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3650 - accuracy: 0.8457 - val_loss: 0.3658 - val_accuracy: 0.8452\n",
      "Epoch 83/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3649 - accuracy: 0.8455 - val_loss: 0.3661 - val_accuracy: 0.8452\n",
      "Epoch 84/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3650 - accuracy: 0.8457 - val_loss: 0.3715 - val_accuracy: 0.8451\n",
      "Epoch 85/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3650 - accuracy: 0.8455 - val_loss: 0.3712 - val_accuracy: 0.8453\n",
      "Epoch 86/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3649 - accuracy: 0.8455 - val_loss: 0.3696 - val_accuracy: 0.8448\n",
      "Epoch 87/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3650 - accuracy: 0.8456 - val_loss: 0.3662 - val_accuracy: 0.8460\n",
      "Epoch 88/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3650 - accuracy: 0.8456 - val_loss: 0.3684 - val_accuracy: 0.8430\n",
      "Epoch 89/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3647 - accuracy: 0.8455 - val_loss: 0.3706 - val_accuracy: 0.8454\n",
      "Epoch 90/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3647 - accuracy: 0.8457 - val_loss: 0.3664 - val_accuracy: 0.8448\n",
      "Epoch 91/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3648 - accuracy: 0.8456 - val_loss: 0.3675 - val_accuracy: 0.8451\n",
      "Epoch 92/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3647 - accuracy: 0.8456 - val_loss: 0.3670 - val_accuracy: 0.8452\n",
      "Epoch 93/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3645 - accuracy: 0.8454 - val_loss: 0.3709 - val_accuracy: 0.8447\n",
      "Epoch 94/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3646 - accuracy: 0.8457 - val_loss: 0.3645 - val_accuracy: 0.8456\n",
      "Epoch 95/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3646 - accuracy: 0.8456 - val_loss: 0.3667 - val_accuracy: 0.8440\n",
      "Epoch 96/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3646 - accuracy: 0.8457 - val_loss: 0.3655 - val_accuracy: 0.8461\n",
      "Epoch 97/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3645 - accuracy: 0.8456 - val_loss: 0.3669 - val_accuracy: 0.8457\n",
      "Epoch 98/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3643 - accuracy: 0.8457 - val_loss: 0.3736 - val_accuracy: 0.8442\n",
      "Epoch 99/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3643 - accuracy: 0.8458 - val_loss: 0.3740 - val_accuracy: 0.8400\n",
      "Epoch 100/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3642 - accuracy: 0.8457 - val_loss: 0.3657 - val_accuracy: 0.8450\n",
      "time taken for training :  18448.39462041855\n",
      "time taken for per epoch :  184.4839462041855\n",
      "\n",
      "\n",
      "\n",
      " Test file no :  5\n",
      "Dataset has been successfully prepared\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d9b170f25742e69b153996b5dbfa29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/8536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|████████████████| 10/10 [06:02<00:00, 36.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for training node embedding model :  4006.973797559738\n",
      "<bound method NDFrame.head of           src  dest  label\n",
      "0        3024  8110      0\n",
      "1        6123  5646      0\n",
      "2        1246  7908      0\n",
      "3        4225  4979      0\n",
      "4        5024  5779      1\n",
      "...       ...   ...    ...\n",
      "1139397   598  1189      1\n",
      "1139398  5337  5422      1\n",
      "1139399  5390  5402      1\n",
      "1139400  4961  8369      1\n",
      "1139401  7435   599      0\n",
      "\n",
      "[1139402 rows x 3 columns]>\n",
      "x_train and x_test are ready\n",
      "Epoch 1/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.4077 - accuracy: 0.8272 - val_loss: 0.3905 - val_accuracy: 0.8358\n",
      "Epoch 2/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3878 - accuracy: 0.8369 - val_loss: 0.3845 - val_accuracy: 0.8387\n",
      "Epoch 3/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3821 - accuracy: 0.8394 - val_loss: 0.3832 - val_accuracy: 0.8389\n",
      "Epoch 4/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3790 - accuracy: 0.8407 - val_loss: 0.3810 - val_accuracy: 0.8402\n",
      "Epoch 5/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3769 - accuracy: 0.8415 - val_loss: 0.3772 - val_accuracy: 0.8399\n",
      "Epoch 6/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3754 - accuracy: 0.8422 - val_loss: 0.3753 - val_accuracy: 0.8426\n",
      "Epoch 7/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3741 - accuracy: 0.8427 - val_loss: 0.3758 - val_accuracy: 0.8420\n",
      "Epoch 8/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3733 - accuracy: 0.8429 - val_loss: 0.3755 - val_accuracy: 0.8397\n",
      "Epoch 9/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3724 - accuracy: 0.8431 - val_loss: 0.3788 - val_accuracy: 0.8428\n",
      "Epoch 10/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3717 - accuracy: 0.8432 - val_loss: 0.3713 - val_accuracy: 0.8420\n",
      "Epoch 11/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3712 - accuracy: 0.8436 - val_loss: 0.3731 - val_accuracy: 0.8416\n",
      "Epoch 12/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3705 - accuracy: 0.8437 - val_loss: 0.3737 - val_accuracy: 0.8416\n",
      "Epoch 13/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3701 - accuracy: 0.8437 - val_loss: 0.3735 - val_accuracy: 0.8433\n",
      "Epoch 14/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3698 - accuracy: 0.8439 - val_loss: 0.3728 - val_accuracy: 0.8419\n",
      "Epoch 15/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3694 - accuracy: 0.8442 - val_loss: 0.3702 - val_accuracy: 0.8423\n",
      "Epoch 16/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3691 - accuracy: 0.8441 - val_loss: 0.3738 - val_accuracy: 0.8394\n",
      "Epoch 17/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3688 - accuracy: 0.8443 - val_loss: 0.3716 - val_accuracy: 0.8441\n",
      "Epoch 18/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3683 - accuracy: 0.8446 - val_loss: 0.3708 - val_accuracy: 0.8443\n",
      "Epoch 19/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3682 - accuracy: 0.8445 - val_loss: 0.3713 - val_accuracy: 0.8413\n",
      "Epoch 20/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3680 - accuracy: 0.8448 - val_loss: 0.3694 - val_accuracy: 0.8434\n",
      "Epoch 21/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3678 - accuracy: 0.8447 - val_loss: 0.3703 - val_accuracy: 0.8424\n",
      "Epoch 22/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3675 - accuracy: 0.8450 - val_loss: 0.3696 - val_accuracy: 0.8432\n",
      "Epoch 23/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3674 - accuracy: 0.8449 - val_loss: 0.3684 - val_accuracy: 0.8453\n",
      "Epoch 24/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3672 - accuracy: 0.8450 - val_loss: 0.3685 - val_accuracy: 0.8439\n",
      "Epoch 25/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3671 - accuracy: 0.8451 - val_loss: 0.3692 - val_accuracy: 0.8430\n",
      "Epoch 26/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3669 - accuracy: 0.8449 - val_loss: 0.3685 - val_accuracy: 0.8440\n",
      "Epoch 27/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3667 - accuracy: 0.8451 - val_loss: 0.3674 - val_accuracy: 0.8443\n",
      "Epoch 28/100\n",
      "64092/64092 [==============================] - 180s 3ms/step - loss: 0.3667 - accuracy: 0.8452 - val_loss: 0.3686 - val_accuracy: 0.8442\n",
      "Epoch 29/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3664 - accuracy: 0.8453 - val_loss: 0.3681 - val_accuracy: 0.8436\n",
      "Epoch 30/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3665 - accuracy: 0.8453 - val_loss: 0.3688 - val_accuracy: 0.8448\n",
      "Epoch 31/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3662 - accuracy: 0.8454 - val_loss: 0.3676 - val_accuracy: 0.8437\n",
      "Epoch 32/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3661 - accuracy: 0.8453 - val_loss: 0.3683 - val_accuracy: 0.8453\n",
      "Epoch 33/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3660 - accuracy: 0.8455 - val_loss: 0.3684 - val_accuracy: 0.8442\n",
      "Epoch 34/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3659 - accuracy: 0.8454 - val_loss: 0.3705 - val_accuracy: 0.8418\n",
      "Epoch 35/100\n",
      "64092/64092 [==============================] - 176s 3ms/step - loss: 0.3658 - accuracy: 0.8457 - val_loss: 0.3683 - val_accuracy: 0.8422\n",
      "Epoch 36/100\n",
      "64092/64092 [==============================] - 189s 3ms/step - loss: 0.3657 - accuracy: 0.8455 - val_loss: 0.3666 - val_accuracy: 0.8448\n",
      "Epoch 37/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3656 - accuracy: 0.8456 - val_loss: 0.3682 - val_accuracy: 0.8442\n",
      "Epoch 38/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3656 - accuracy: 0.8457 - val_loss: 0.3683 - val_accuracy: 0.8461\n",
      "Epoch 39/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3655 - accuracy: 0.8456 - val_loss: 0.3712 - val_accuracy: 0.8453\n",
      "Epoch 40/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3654 - accuracy: 0.8456 - val_loss: 0.3687 - val_accuracy: 0.8456\n",
      "Epoch 41/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3652 - accuracy: 0.8458 - val_loss: 0.3660 - val_accuracy: 0.8453\n",
      "Epoch 42/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3652 - accuracy: 0.8456 - val_loss: 0.3681 - val_accuracy: 0.8428\n",
      "Epoch 43/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3651 - accuracy: 0.8457 - val_loss: 0.3672 - val_accuracy: 0.8437\n",
      "Epoch 44/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3652 - accuracy: 0.8458 - val_loss: 0.3659 - val_accuracy: 0.8450\n",
      "Epoch 45/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3649 - accuracy: 0.8457 - val_loss: 0.3650 - val_accuracy: 0.8455\n",
      "Epoch 46/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3648 - accuracy: 0.8461 - val_loss: 0.3685 - val_accuracy: 0.8453\n",
      "Epoch 47/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3648 - accuracy: 0.8459 - val_loss: 0.3682 - val_accuracy: 0.8464\n",
      "Epoch 48/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3648 - accuracy: 0.8457 - val_loss: 0.3671 - val_accuracy: 0.8456\n",
      "Epoch 49/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3647 - accuracy: 0.8460 - val_loss: 0.3658 - val_accuracy: 0.8460\n",
      "Epoch 50/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3646 - accuracy: 0.8459 - val_loss: 0.3660 - val_accuracy: 0.8449\n",
      "Epoch 51/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3646 - accuracy: 0.8461 - val_loss: 0.3680 - val_accuracy: 0.8458\n",
      "Epoch 52/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3645 - accuracy: 0.8461 - val_loss: 0.3671 - val_accuracy: 0.8462\n",
      "Epoch 53/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3644 - accuracy: 0.8460 - val_loss: 0.3661 - val_accuracy: 0.8448\n",
      "Epoch 54/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3644 - accuracy: 0.8461 - val_loss: 0.3661 - val_accuracy: 0.8446\n",
      "Epoch 55/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3644 - accuracy: 0.8460 - val_loss: 0.3683 - val_accuracy: 0.8458\n",
      "Epoch 56/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3642 - accuracy: 0.8462 - val_loss: 0.3661 - val_accuracy: 0.8446\n",
      "Epoch 57/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3643 - accuracy: 0.8460 - val_loss: 0.3662 - val_accuracy: 0.8463\n",
      "Epoch 58/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3642 - accuracy: 0.8461 - val_loss: 0.3660 - val_accuracy: 0.8448\n",
      "Epoch 59/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3642 - accuracy: 0.8461 - val_loss: 0.3669 - val_accuracy: 0.8452\n",
      "Epoch 60/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3642 - accuracy: 0.8461 - val_loss: 0.3650 - val_accuracy: 0.8449\n",
      "Epoch 61/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3641 - accuracy: 0.8462 - val_loss: 0.3663 - val_accuracy: 0.8448\n",
      "Epoch 62/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3640 - accuracy: 0.8462 - val_loss: 0.3661 - val_accuracy: 0.8465\n",
      "Epoch 63/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3639 - accuracy: 0.8463 - val_loss: 0.3670 - val_accuracy: 0.8449\n",
      "Epoch 64/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3640 - accuracy: 0.8463 - val_loss: 0.3681 - val_accuracy: 0.8460\n",
      "Epoch 65/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3639 - accuracy: 0.8464 - val_loss: 0.3681 - val_accuracy: 0.8465\n",
      "Epoch 66/100\n",
      "64092/64092 [==============================] - 183s 3ms/step - loss: 0.3639 - accuracy: 0.8465 - val_loss: 0.3666 - val_accuracy: 0.8434\n",
      "Epoch 67/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3639 - accuracy: 0.8463 - val_loss: 0.3670 - val_accuracy: 0.8463\n",
      "Epoch 68/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3638 - accuracy: 0.8463 - val_loss: 0.3686 - val_accuracy: 0.8459\n",
      "Epoch 69/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3638 - accuracy: 0.8464 - val_loss: 0.3657 - val_accuracy: 0.8462\n",
      "Epoch 70/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3638 - accuracy: 0.8463 - val_loss: 0.3678 - val_accuracy: 0.8458\n",
      "Epoch 71/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3637 - accuracy: 0.8464 - val_loss: 0.3656 - val_accuracy: 0.8449\n",
      "Epoch 72/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3636 - accuracy: 0.8465 - val_loss: 0.3705 - val_accuracy: 0.8406\n",
      "Epoch 73/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3637 - accuracy: 0.8465 - val_loss: 0.3656 - val_accuracy: 0.8458\n",
      "Epoch 74/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3636 - accuracy: 0.8465 - val_loss: 0.3674 - val_accuracy: 0.8459\n",
      "Epoch 75/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3635 - accuracy: 0.8467 - val_loss: 0.3648 - val_accuracy: 0.8444\n",
      "Epoch 76/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3634 - accuracy: 0.8467 - val_loss: 0.3663 - val_accuracy: 0.8460\n",
      "Epoch 77/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3635 - accuracy: 0.8466 - val_loss: 0.3670 - val_accuracy: 0.8441\n",
      "Epoch 78/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3634 - accuracy: 0.8466 - val_loss: 0.3646 - val_accuracy: 0.8458\n",
      "Epoch 79/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3634 - accuracy: 0.8467 - val_loss: 0.3661 - val_accuracy: 0.8442\n",
      "Epoch 80/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3635 - accuracy: 0.8466 - val_loss: 0.3666 - val_accuracy: 0.8436\n",
      "Epoch 81/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3633 - accuracy: 0.8467 - val_loss: 0.3668 - val_accuracy: 0.8447\n",
      "Epoch 82/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3633 - accuracy: 0.8467 - val_loss: 0.3670 - val_accuracy: 0.8449\n",
      "Epoch 83/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3632 - accuracy: 0.8467 - val_loss: 0.3671 - val_accuracy: 0.8434\n",
      "Epoch 84/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3632 - accuracy: 0.8467 - val_loss: 0.3646 - val_accuracy: 0.8459\n",
      "Epoch 85/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3632 - accuracy: 0.8466 - val_loss: 0.3675 - val_accuracy: 0.8422\n",
      "Epoch 86/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3632 - accuracy: 0.8467 - val_loss: 0.3688 - val_accuracy: 0.8459\n",
      "Epoch 87/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3631 - accuracy: 0.8468 - val_loss: 0.3704 - val_accuracy: 0.8408\n",
      "Epoch 88/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3630 - accuracy: 0.8467 - val_loss: 0.3667 - val_accuracy: 0.8464\n",
      "Epoch 89/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3631 - accuracy: 0.8468 - val_loss: 0.3673 - val_accuracy: 0.8448\n",
      "Epoch 90/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3631 - accuracy: 0.8467 - val_loss: 0.3639 - val_accuracy: 0.8465\n",
      "Epoch 91/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3630 - accuracy: 0.8467 - val_loss: 0.3646 - val_accuracy: 0.8453\n",
      "Epoch 92/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3631 - accuracy: 0.8469 - val_loss: 0.3654 - val_accuracy: 0.8454\n",
      "Epoch 93/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3629 - accuracy: 0.8469 - val_loss: 0.3679 - val_accuracy: 0.8459\n",
      "Epoch 94/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3629 - accuracy: 0.8469 - val_loss: 0.3665 - val_accuracy: 0.8451\n",
      "Epoch 95/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3630 - accuracy: 0.8466 - val_loss: 0.3697 - val_accuracy: 0.8432\n",
      "Epoch 96/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3629 - accuracy: 0.8467 - val_loss: 0.3659 - val_accuracy: 0.8468\n",
      "Epoch 97/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3628 - accuracy: 0.8469 - val_loss: 0.3644 - val_accuracy: 0.8456\n",
      "Epoch 98/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3628 - accuracy: 0.8469 - val_loss: 0.3642 - val_accuracy: 0.8461\n",
      "Epoch 99/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3630 - accuracy: 0.8466 - val_loss: 0.3690 - val_accuracy: 0.8457\n",
      "Epoch 100/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3629 - accuracy: 0.8467 - val_loss: 0.3660 - val_accuracy: 0.8464\n",
      "time taken for training :  18506.48039984703\n",
      "time taken for per epoch :  185.0648039984703\n",
      "\n",
      "\n",
      "\n",
      " Test file no :  6\n",
      "Dataset has been successfully prepared\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922d6dad04324726a9e4ae91e0a08db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/8536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|████████████████| 10/10 [06:02<00:00, 36.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for training node embedding model :  4008.9718639850616\n",
      "<bound method NDFrame.head of           src  dest  label\n",
      "0        5218  5293      1\n",
      "1        7450  8287      1\n",
      "2        5289  5740      1\n",
      "3        5954  2216      0\n",
      "4          96  8427      0\n",
      "...       ...   ...    ...\n",
      "1139397  7365   103      0\n",
      "1139398  6359  3035      0\n",
      "1139399  5276  1914      0\n",
      "1139400  5934  6210      1\n",
      "1139401  6562   605      0\n",
      "\n",
      "[1139402 rows x 3 columns]>\n",
      "x_train and x_test are ready\n",
      "Epoch 1/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.4068 - accuracy: 0.8273 - val_loss: 0.3975 - val_accuracy: 0.8350\n",
      "Epoch 2/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3844 - accuracy: 0.8388 - val_loss: 0.3856 - val_accuracy: 0.8385\n",
      "Epoch 3/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3796 - accuracy: 0.8406 - val_loss: 0.3814 - val_accuracy: 0.8390\n",
      "Epoch 4/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3770 - accuracy: 0.8421 - val_loss: 0.3803 - val_accuracy: 0.8385\n",
      "Epoch 5/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3751 - accuracy: 0.8429 - val_loss: 0.3774 - val_accuracy: 0.8408\n",
      "Epoch 6/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3736 - accuracy: 0.8434 - val_loss: 0.3805 - val_accuracy: 0.8408\n",
      "Epoch 7/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3726 - accuracy: 0.8440 - val_loss: 0.3847 - val_accuracy: 0.8361\n",
      "Epoch 8/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3715 - accuracy: 0.8443 - val_loss: 0.3797 - val_accuracy: 0.8420\n",
      "Epoch 9/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3709 - accuracy: 0.8447 - val_loss: 0.3749 - val_accuracy: 0.8424\n",
      "Epoch 10/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3701 - accuracy: 0.8449 - val_loss: 0.3755 - val_accuracy: 0.8430\n",
      "Epoch 11/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3696 - accuracy: 0.8451 - val_loss: 0.3722 - val_accuracy: 0.8423\n",
      "Epoch 12/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3692 - accuracy: 0.8453 - val_loss: 0.3742 - val_accuracy: 0.8416\n",
      "Epoch 13/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3688 - accuracy: 0.8453 - val_loss: 0.3717 - val_accuracy: 0.8426\n",
      "Epoch 14/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3685 - accuracy: 0.8454 - val_loss: 0.3722 - val_accuracy: 0.8431\n",
      "Epoch 15/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3681 - accuracy: 0.8456 - val_loss: 0.3722 - val_accuracy: 0.8436\n",
      "Epoch 16/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3677 - accuracy: 0.8458 - val_loss: 0.3717 - val_accuracy: 0.8428\n",
      "Epoch 17/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3674 - accuracy: 0.8459 - val_loss: 0.3841 - val_accuracy: 0.8350\n",
      "Epoch 18/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3672 - accuracy: 0.8458 - val_loss: 0.3728 - val_accuracy: 0.8435\n",
      "Epoch 19/100\n",
      "64092/64092 [==============================] - 172s 3ms/step - loss: 0.3669 - accuracy: 0.8459 - val_loss: 0.3745 - val_accuracy: 0.8432\n",
      "Epoch 20/100\n",
      "64092/64092 [==============================] - 190s 3ms/step - loss: 0.3667 - accuracy: 0.8460 - val_loss: 0.3706 - val_accuracy: 0.8430\n",
      "Epoch 21/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3665 - accuracy: 0.8460 - val_loss: 0.3733 - val_accuracy: 0.8430\n",
      "Epoch 22/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3662 - accuracy: 0.8461 - val_loss: 0.3720 - val_accuracy: 0.8419\n",
      "Epoch 23/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3662 - accuracy: 0.8462 - val_loss: 0.3699 - val_accuracy: 0.8438\n",
      "Epoch 24/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3659 - accuracy: 0.8461 - val_loss: 0.3730 - val_accuracy: 0.8439\n",
      "Epoch 25/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3657 - accuracy: 0.8464 - val_loss: 0.3727 - val_accuracy: 0.8436\n",
      "Epoch 26/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3657 - accuracy: 0.8463 - val_loss: 0.3708 - val_accuracy: 0.8434\n",
      "Epoch 27/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3655 - accuracy: 0.8464 - val_loss: 0.3708 - val_accuracy: 0.8441\n",
      "Epoch 28/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3654 - accuracy: 0.8464 - val_loss: 0.3711 - val_accuracy: 0.8439\n",
      "Epoch 29/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3653 - accuracy: 0.8464 - val_loss: 0.3689 - val_accuracy: 0.8448\n",
      "Epoch 30/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3651 - accuracy: 0.8462 - val_loss: 0.3690 - val_accuracy: 0.8426\n",
      "Epoch 31/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3651 - accuracy: 0.8466 - val_loss: 0.3704 - val_accuracy: 0.8426\n",
      "Epoch 32/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3649 - accuracy: 0.8466 - val_loss: 0.3723 - val_accuracy: 0.8407\n",
      "Epoch 33/100\n",
      "64092/64092 [==============================] - 189s 3ms/step - loss: 0.3648 - accuracy: 0.8465 - val_loss: 0.3689 - val_accuracy: 0.8447\n",
      "Epoch 34/100\n",
      "64092/64092 [==============================] - 189s 3ms/step - loss: 0.3647 - accuracy: 0.8464 - val_loss: 0.3718 - val_accuracy: 0.8423\n",
      "Epoch 35/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3645 - accuracy: 0.8466 - val_loss: 0.3693 - val_accuracy: 0.8436\n",
      "Epoch 36/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3644 - accuracy: 0.8467 - val_loss: 0.3696 - val_accuracy: 0.8423\n",
      "Epoch 37/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3643 - accuracy: 0.8468 - val_loss: 0.3688 - val_accuracy: 0.8434\n",
      "Epoch 38/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3643 - accuracy: 0.8469 - val_loss: 0.3715 - val_accuracy: 0.8441\n",
      "Epoch 39/100\n",
      "64092/64092 [==============================] - 188s 3ms/step - loss: 0.3642 - accuracy: 0.8467 - val_loss: 0.3715 - val_accuracy: 0.8410\n",
      "Epoch 40/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3641 - accuracy: 0.8468 - val_loss: 0.3692 - val_accuracy: 0.8440\n",
      "Epoch 41/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3641 - accuracy: 0.8466 - val_loss: 0.3677 - val_accuracy: 0.8438\n",
      "Epoch 42/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3640 - accuracy: 0.8470 - val_loss: 0.3707 - val_accuracy: 0.8416\n",
      "Epoch 43/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3640 - accuracy: 0.8468 - val_loss: 0.3691 - val_accuracy: 0.8443\n",
      "Epoch 44/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3638 - accuracy: 0.8468 - val_loss: 0.3687 - val_accuracy: 0.8443\n",
      "Epoch 45/100\n",
      "64092/64092 [==============================] - 187s 3ms/step - loss: 0.3639 - accuracy: 0.8468 - val_loss: 0.3698 - val_accuracy: 0.8421\n",
      "Epoch 46/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3637 - accuracy: 0.8469 - val_loss: 0.3701 - val_accuracy: 0.8440\n",
      "Epoch 47/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3636 - accuracy: 0.8467 - val_loss: 0.3671 - val_accuracy: 0.8447\n",
      "Epoch 48/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3636 - accuracy: 0.8468 - val_loss: 0.3675 - val_accuracy: 0.8445\n",
      "Epoch 49/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3635 - accuracy: 0.8469 - val_loss: 0.3687 - val_accuracy: 0.8445\n",
      "Epoch 50/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3635 - accuracy: 0.8470 - val_loss: 0.3707 - val_accuracy: 0.8450\n",
      "Epoch 51/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3634 - accuracy: 0.8469 - val_loss: 0.3760 - val_accuracy: 0.8434\n",
      "Epoch 52/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3634 - accuracy: 0.8471 - val_loss: 0.3678 - val_accuracy: 0.8450\n",
      "Epoch 53/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3633 - accuracy: 0.8471 - val_loss: 0.3679 - val_accuracy: 0.8443\n",
      "Epoch 54/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3632 - accuracy: 0.8471 - val_loss: 0.3668 - val_accuracy: 0.8444\n",
      "Epoch 55/100\n",
      "64092/64092 [==============================] - 184s 3ms/step - loss: 0.3633 - accuracy: 0.8468 - val_loss: 0.3684 - val_accuracy: 0.8445\n",
      "Epoch 56/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3632 - accuracy: 0.8470 - val_loss: 0.3702 - val_accuracy: 0.8444\n",
      "Epoch 57/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3631 - accuracy: 0.8471 - val_loss: 0.3670 - val_accuracy: 0.8445\n",
      "Epoch 58/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3631 - accuracy: 0.8470 - val_loss: 0.3758 - val_accuracy: 0.8437\n",
      "Epoch 59/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3630 - accuracy: 0.8472 - val_loss: 0.3684 - val_accuracy: 0.8429\n",
      "Epoch 60/100\n",
      "64092/64092 [==============================] - 209s 3ms/step - loss: 0.3630 - accuracy: 0.8470 - val_loss: 0.3695 - val_accuracy: 0.8429\n",
      "Epoch 61/100\n",
      "64092/64092 [==============================] - 208s 3ms/step - loss: 0.3629 - accuracy: 0.8472 - val_loss: 0.3675 - val_accuracy: 0.8445\n",
      "Epoch 62/100\n",
      "64092/64092 [==============================] - 209s 3ms/step - loss: 0.3630 - accuracy: 0.8471 - val_loss: 0.3720 - val_accuracy: 0.8438\n",
      "Epoch 63/100\n",
      "64092/64092 [==============================] - 208s 3ms/step - loss: 0.3628 - accuracy: 0.8472 - val_loss: 0.3708 - val_accuracy: 0.8450\n",
      "Epoch 64/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3628 - accuracy: 0.8471 - val_loss: 0.3662 - val_accuracy: 0.8444\n",
      "Epoch 65/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3627 - accuracy: 0.8473 - val_loss: 0.3680 - val_accuracy: 0.8440\n",
      "Epoch 66/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3628 - accuracy: 0.8472 - val_loss: 0.3700 - val_accuracy: 0.8421\n",
      "Epoch 67/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3626 - accuracy: 0.8472 - val_loss: 0.3682 - val_accuracy: 0.8441\n",
      "Epoch 68/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3626 - accuracy: 0.8472 - val_loss: 0.3690 - val_accuracy: 0.8449\n",
      "Epoch 69/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3626 - accuracy: 0.8473 - val_loss: 0.3679 - val_accuracy: 0.8434\n",
      "Epoch 70/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3625 - accuracy: 0.8474 - val_loss: 0.3707 - val_accuracy: 0.8414\n",
      "Epoch 71/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3626 - accuracy: 0.8473 - val_loss: 0.3674 - val_accuracy: 0.8452\n",
      "Epoch 72/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3625 - accuracy: 0.8473 - val_loss: 0.3668 - val_accuracy: 0.8439\n",
      "Epoch 73/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3624 - accuracy: 0.8475 - val_loss: 0.3673 - val_accuracy: 0.8441\n",
      "Epoch 74/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3625 - accuracy: 0.8476 - val_loss: 0.3668 - val_accuracy: 0.8443\n",
      "Epoch 75/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3625 - accuracy: 0.8472 - val_loss: 0.3658 - val_accuracy: 0.8450\n",
      "Epoch 76/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3623 - accuracy: 0.8473 - val_loss: 0.3670 - val_accuracy: 0.8450\n",
      "Epoch 77/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3624 - accuracy: 0.8474 - val_loss: 0.3672 - val_accuracy: 0.8437\n",
      "Epoch 78/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3624 - accuracy: 0.8475 - val_loss: 0.3679 - val_accuracy: 0.8455\n",
      "Epoch 79/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3622 - accuracy: 0.8475 - val_loss: 0.3671 - val_accuracy: 0.8450\n",
      "Epoch 80/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3623 - accuracy: 0.8475 - val_loss: 0.3668 - val_accuracy: 0.8450\n",
      "Epoch 81/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3622 - accuracy: 0.8473 - val_loss: 0.3679 - val_accuracy: 0.8456\n",
      "Epoch 82/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3621 - accuracy: 0.8475 - val_loss: 0.3759 - val_accuracy: 0.8379\n",
      "Epoch 83/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3623 - accuracy: 0.8475 - val_loss: 0.3687 - val_accuracy: 0.8439\n",
      "Epoch 84/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3621 - accuracy: 0.8473 - val_loss: 0.3672 - val_accuracy: 0.8456\n",
      "Epoch 85/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3621 - accuracy: 0.8476 - val_loss: 0.3707 - val_accuracy: 0.8438\n",
      "Epoch 86/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3620 - accuracy: 0.8473 - val_loss: 0.3687 - val_accuracy: 0.8428\n",
      "Epoch 87/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3620 - accuracy: 0.8474 - val_loss: 0.3667 - val_accuracy: 0.8444\n",
      "Epoch 88/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3619 - accuracy: 0.8473 - val_loss: 0.3656 - val_accuracy: 0.8455\n",
      "Epoch 89/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3620 - accuracy: 0.8476 - val_loss: 0.3685 - val_accuracy: 0.8459\n",
      "Epoch 90/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3619 - accuracy: 0.8474 - val_loss: 0.3681 - val_accuracy: 0.8447\n",
      "Epoch 91/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3620 - accuracy: 0.8476 - val_loss: 0.3687 - val_accuracy: 0.8443\n",
      "Epoch 92/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3619 - accuracy: 0.8477 - val_loss: 0.3664 - val_accuracy: 0.8444\n",
      "Epoch 93/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3618 - accuracy: 0.8477 - val_loss: 0.3663 - val_accuracy: 0.8447\n",
      "Epoch 94/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3618 - accuracy: 0.8478 - val_loss: 0.3685 - val_accuracy: 0.8427\n",
      "Epoch 95/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3617 - accuracy: 0.8476 - val_loss: 0.3658 - val_accuracy: 0.8458\n",
      "Epoch 96/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3617 - accuracy: 0.8477 - val_loss: 0.3694 - val_accuracy: 0.8452\n",
      "Epoch 97/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3616 - accuracy: 0.8478 - val_loss: 0.3694 - val_accuracy: 0.8422\n",
      "Epoch 98/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3617 - accuracy: 0.8476 - val_loss: 0.3667 - val_accuracy: 0.8444\n",
      "Epoch 99/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3618 - accuracy: 0.8478 - val_loss: 0.3672 - val_accuracy: 0.8437\n",
      "Epoch 100/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3616 - accuracy: 0.8478 - val_loss: 0.3674 - val_accuracy: 0.8447\n",
      "time taken for training :  19446.251611232758\n",
      "time taken for per epoch :  194.46251611232756\n",
      "\n",
      "\n",
      "\n",
      " Test file no :  7\n",
      "Dataset has been successfully prepared\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8039412f19499c92ea9d8cc7b07fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/8536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|████████████████| 10/10 [04:28<00:00, 26.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for training node embedding model :  3847.3280358314514\n",
      "<bound method NDFrame.head of           src  dest  label\n",
      "0        1149  6119      0\n",
      "1        1763  1245      0\n",
      "2        1603  5532      0\n",
      "3        6288  7546      1\n",
      "4         133  1442      1\n",
      "...       ...   ...    ...\n",
      "1139397  2795  1378      0\n",
      "1139398  6109  5661      0\n",
      "1139399  5689  6544      1\n",
      "1139400  3697  5190      0\n",
      "1139401  5544  7434      1\n",
      "\n",
      "[1139402 rows x 3 columns]>\n",
      "x_train and x_test are ready\n",
      "Epoch 1/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.4068 - accuracy: 0.8253 - val_loss: 0.3869 - val_accuracy: 0.8351\n",
      "Epoch 2/100\n",
      "64092/64092 [==============================] - 185s 3ms/step - loss: 0.3869 - accuracy: 0.8356 - val_loss: 0.3830 - val_accuracy: 0.8411\n",
      "Epoch 3/100\n",
      "64092/64092 [==============================] - 181s 3ms/step - loss: 0.3815 - accuracy: 0.8384 - val_loss: 0.3759 - val_accuracy: 0.8424\n",
      "Epoch 4/100\n",
      "64092/64092 [==============================] - 182s 3ms/step - loss: 0.3784 - accuracy: 0.8395 - val_loss: 0.3793 - val_accuracy: 0.8370\n",
      "Epoch 5/100\n",
      "64092/64092 [==============================] - 200s 3ms/step - loss: 0.3761 - accuracy: 0.8408 - val_loss: 0.3703 - val_accuracy: 0.8432\n",
      "Epoch 6/100\n",
      "64092/64092 [==============================] - 200s 3ms/step - loss: 0.3745 - accuracy: 0.8413 - val_loss: 0.3691 - val_accuracy: 0.8438\n",
      "Epoch 7/100\n",
      "64092/64092 [==============================] - 200s 3ms/step - loss: 0.3733 - accuracy: 0.8417 - val_loss: 0.3745 - val_accuracy: 0.8421\n",
      "Epoch 8/100\n",
      "64092/64092 [==============================] - 198s 3ms/step - loss: 0.3724 - accuracy: 0.8423 - val_loss: 0.3711 - val_accuracy: 0.8419\n",
      "Epoch 9/100\n",
      "64092/64092 [==============================] - 197s 3ms/step - loss: 0.3715 - accuracy: 0.8426 - val_loss: 0.3667 - val_accuracy: 0.8443\n",
      "Epoch 10/100\n",
      "64092/64092 [==============================] - 198s 3ms/step - loss: 0.3711 - accuracy: 0.8427 - val_loss: 0.3675 - val_accuracy: 0.8452\n",
      "Epoch 11/100\n",
      "64092/64092 [==============================] - 198s 3ms/step - loss: 0.3706 - accuracy: 0.8431 - val_loss: 0.3675 - val_accuracy: 0.8433\n",
      "Epoch 12/100\n",
      "64092/64092 [==============================] - 197s 3ms/step - loss: 0.3702 - accuracy: 0.8435 - val_loss: 0.3730 - val_accuracy: 0.8426\n",
      "Epoch 13/100\n",
      "64092/64092 [==============================] - 198s 3ms/step - loss: 0.3697 - accuracy: 0.8436 - val_loss: 0.3698 - val_accuracy: 0.8446\n",
      "Epoch 14/100\n",
      "64092/64092 [==============================] - 199s 3ms/step - loss: 0.3696 - accuracy: 0.8439 - val_loss: 0.3680 - val_accuracy: 0.8439\n",
      "Epoch 15/100\n",
      "64092/64092 [==============================] - 198s 3ms/step - loss: 0.3692 - accuracy: 0.8438 - val_loss: 0.3690 - val_accuracy: 0.8454\n",
      "Epoch 16/100\n",
      "64092/64092 [==============================] - 199s 3ms/step - loss: 0.3690 - accuracy: 0.8441 - val_loss: 0.3671 - val_accuracy: 0.8431\n",
      "Epoch 17/100\n",
      "64092/64092 [==============================] - 200s 3ms/step - loss: 0.3687 - accuracy: 0.8442 - val_loss: 0.3664 - val_accuracy: 0.8442\n",
      "Epoch 18/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3686 - accuracy: 0.8440 - val_loss: 0.3674 - val_accuracy: 0.8445\n",
      "Epoch 19/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3686 - accuracy: 0.8443 - val_loss: 0.3657 - val_accuracy: 0.8458\n",
      "Epoch 20/100\n",
      "64092/64092 [==============================] - 200s 3ms/step - loss: 0.3683 - accuracy: 0.8442 - val_loss: 0.3694 - val_accuracy: 0.8413\n",
      "Epoch 21/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3680 - accuracy: 0.8444 - val_loss: 0.3657 - val_accuracy: 0.8444\n",
      "Epoch 22/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3679 - accuracy: 0.8444 - val_loss: 0.3670 - val_accuracy: 0.8446\n",
      "Epoch 23/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3678 - accuracy: 0.8446 - val_loss: 0.3658 - val_accuracy: 0.8442\n",
      "Epoch 24/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3677 - accuracy: 0.8445 - val_loss: 0.3649 - val_accuracy: 0.8460\n",
      "Epoch 25/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3674 - accuracy: 0.8445 - val_loss: 0.3664 - val_accuracy: 0.8432\n",
      "Epoch 26/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3674 - accuracy: 0.8447 - val_loss: 0.3673 - val_accuracy: 0.8462\n",
      "Epoch 27/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3672 - accuracy: 0.8448 - val_loss: 0.3697 - val_accuracy: 0.8414\n",
      "Epoch 28/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3671 - accuracy: 0.8447 - val_loss: 0.3645 - val_accuracy: 0.8454\n",
      "Epoch 29/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3671 - accuracy: 0.8448 - val_loss: 0.3645 - val_accuracy: 0.8459\n",
      "Epoch 30/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3670 - accuracy: 0.8450 - val_loss: 0.3673 - val_accuracy: 0.8428\n",
      "Epoch 31/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3668 - accuracy: 0.8447 - val_loss: 0.3659 - val_accuracy: 0.8458\n",
      "Epoch 32/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3666 - accuracy: 0.8451 - val_loss: 0.3651 - val_accuracy: 0.8460\n",
      "Epoch 33/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3666 - accuracy: 0.8449 - val_loss: 0.3645 - val_accuracy: 0.8455\n",
      "Epoch 34/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3665 - accuracy: 0.8450 - val_loss: 0.3688 - val_accuracy: 0.8452\n",
      "Epoch 35/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3664 - accuracy: 0.8450 - val_loss: 0.3664 - val_accuracy: 0.8442\n",
      "Epoch 36/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3662 - accuracy: 0.8450 - val_loss: 0.3654 - val_accuracy: 0.8455\n",
      "Epoch 37/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3662 - accuracy: 0.8451 - val_loss: 0.3650 - val_accuracy: 0.8454\n",
      "Epoch 38/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3661 - accuracy: 0.8452 - val_loss: 0.3651 - val_accuracy: 0.8462\n",
      "Epoch 39/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3660 - accuracy: 0.8451 - val_loss: 0.3678 - val_accuracy: 0.8460\n",
      "Epoch 40/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3660 - accuracy: 0.8453 - val_loss: 0.3643 - val_accuracy: 0.8461\n",
      "Epoch 41/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3658 - accuracy: 0.8455 - val_loss: 0.3680 - val_accuracy: 0.8428\n",
      "Epoch 42/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3660 - accuracy: 0.8454 - val_loss: 0.3641 - val_accuracy: 0.8451\n",
      "Epoch 43/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3658 - accuracy: 0.8454 - val_loss: 0.3641 - val_accuracy: 0.8462\n",
      "Epoch 44/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3657 - accuracy: 0.8452 - val_loss: 0.3652 - val_accuracy: 0.8458\n",
      "Epoch 45/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3657 - accuracy: 0.8453 - val_loss: 0.3632 - val_accuracy: 0.8463\n",
      "Epoch 46/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3656 - accuracy: 0.8454 - val_loss: 0.3643 - val_accuracy: 0.8469\n",
      "Epoch 47/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3656 - accuracy: 0.8453 - val_loss: 0.3635 - val_accuracy: 0.8464\n",
      "Epoch 48/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3655 - accuracy: 0.8454 - val_loss: 0.3638 - val_accuracy: 0.8465\n",
      "Epoch 49/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3655 - accuracy: 0.8455 - val_loss: 0.3644 - val_accuracy: 0.8450\n",
      "Epoch 50/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3655 - accuracy: 0.8455 - val_loss: 0.3672 - val_accuracy: 0.8466\n",
      "Epoch 51/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3653 - accuracy: 0.8456 - val_loss: 0.3642 - val_accuracy: 0.8461\n",
      "Epoch 52/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3652 - accuracy: 0.8455 - val_loss: 0.3652 - val_accuracy: 0.8449\n",
      "Epoch 53/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3652 - accuracy: 0.8454 - val_loss: 0.3646 - val_accuracy: 0.8462\n",
      "Epoch 54/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3652 - accuracy: 0.8454 - val_loss: 0.3669 - val_accuracy: 0.8469\n",
      "Epoch 55/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3652 - accuracy: 0.8454 - val_loss: 0.3631 - val_accuracy: 0.8459\n",
      "Epoch 56/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3652 - accuracy: 0.8457 - val_loss: 0.3663 - val_accuracy: 0.8438\n",
      "Epoch 57/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3651 - accuracy: 0.8455 - val_loss: 0.3644 - val_accuracy: 0.8458\n",
      "Epoch 58/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3651 - accuracy: 0.8455 - val_loss: 0.3627 - val_accuracy: 0.8465\n",
      "Epoch 59/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3651 - accuracy: 0.8457 - val_loss: 0.3640 - val_accuracy: 0.8450\n",
      "Epoch 60/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3650 - accuracy: 0.8457 - val_loss: 0.3641 - val_accuracy: 0.8454\n",
      "Epoch 61/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3649 - accuracy: 0.8458 - val_loss: 0.3639 - val_accuracy: 0.8458\n",
      "Epoch 62/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3649 - accuracy: 0.8458 - val_loss: 0.3628 - val_accuracy: 0.8465\n",
      "Epoch 63/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3648 - accuracy: 0.8457 - val_loss: 0.3664 - val_accuracy: 0.8466\n",
      "Epoch 64/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3648 - accuracy: 0.8457 - val_loss: 0.3637 - val_accuracy: 0.8459\n",
      "Epoch 65/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3647 - accuracy: 0.8459 - val_loss: 0.3635 - val_accuracy: 0.8472\n",
      "Epoch 66/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3647 - accuracy: 0.8459 - val_loss: 0.3644 - val_accuracy: 0.8452\n",
      "Epoch 67/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3647 - accuracy: 0.8459 - val_loss: 0.3631 - val_accuracy: 0.8461\n",
      "Epoch 68/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3647 - accuracy: 0.8458 - val_loss: 0.3633 - val_accuracy: 0.8464\n",
      "Epoch 69/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3647 - accuracy: 0.8457 - val_loss: 0.3652 - val_accuracy: 0.8467\n",
      "Epoch 70/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3645 - accuracy: 0.8460 - val_loss: 0.3651 - val_accuracy: 0.8451\n",
      "Epoch 71/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3646 - accuracy: 0.8458 - val_loss: 0.3643 - val_accuracy: 0.8468\n",
      "Epoch 72/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3645 - accuracy: 0.8459 - val_loss: 0.3645 - val_accuracy: 0.8467\n",
      "Epoch 73/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3644 - accuracy: 0.8460 - val_loss: 0.3645 - val_accuracy: 0.8445\n",
      "Epoch 74/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3644 - accuracy: 0.8460 - val_loss: 0.3631 - val_accuracy: 0.8457\n",
      "Epoch 75/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3643 - accuracy: 0.8459 - val_loss: 0.3651 - val_accuracy: 0.8434\n",
      "Epoch 76/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3643 - accuracy: 0.8459 - val_loss: 0.3633 - val_accuracy: 0.8468\n",
      "Epoch 77/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3644 - accuracy: 0.8458 - val_loss: 0.3620 - val_accuracy: 0.8467\n",
      "Epoch 78/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3643 - accuracy: 0.8460 - val_loss: 0.3631 - val_accuracy: 0.8457\n",
      "Epoch 79/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3642 - accuracy: 0.8460 - val_loss: 0.3643 - val_accuracy: 0.8476\n",
      "Epoch 80/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3642 - accuracy: 0.8460 - val_loss: 0.3635 - val_accuracy: 0.8474\n",
      "Epoch 81/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3641 - accuracy: 0.8461 - val_loss: 0.3633 - val_accuracy: 0.8479\n",
      "Epoch 82/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3640 - accuracy: 0.8461 - val_loss: 0.3636 - val_accuracy: 0.8471\n",
      "Epoch 83/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3640 - accuracy: 0.8462 - val_loss: 0.3634 - val_accuracy: 0.8474\n",
      "Epoch 84/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3641 - accuracy: 0.8459 - val_loss: 0.3632 - val_accuracy: 0.8464\n",
      "Epoch 85/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3640 - accuracy: 0.8458 - val_loss: 0.3630 - val_accuracy: 0.8474\n",
      "Epoch 86/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3640 - accuracy: 0.8460 - val_loss: 0.3655 - val_accuracy: 0.8467\n",
      "Epoch 87/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3640 - accuracy: 0.8463 - val_loss: 0.3626 - val_accuracy: 0.8473\n",
      "Epoch 88/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3639 - accuracy: 0.8461 - val_loss: 0.3652 - val_accuracy: 0.8460\n",
      "Epoch 89/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3640 - accuracy: 0.8461 - val_loss: 0.3627 - val_accuracy: 0.8461\n",
      "Epoch 90/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3639 - accuracy: 0.8459 - val_loss: 0.3623 - val_accuracy: 0.8462\n",
      "Epoch 91/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3638 - accuracy: 0.8462 - val_loss: 0.3650 - val_accuracy: 0.8457\n",
      "Epoch 92/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3639 - accuracy: 0.8461 - val_loss: 0.3621 - val_accuracy: 0.8469\n",
      "Epoch 93/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3638 - accuracy: 0.8461 - val_loss: 0.3629 - val_accuracy: 0.8454\n",
      "Epoch 94/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3638 - accuracy: 0.8462 - val_loss: 0.3629 - val_accuracy: 0.8459\n",
      "Epoch 95/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3637 - accuracy: 0.8461 - val_loss: 0.3654 - val_accuracy: 0.8471\n",
      "Epoch 96/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3637 - accuracy: 0.8463 - val_loss: 0.3627 - val_accuracy: 0.8456\n",
      "Epoch 97/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3637 - accuracy: 0.8463 - val_loss: 0.3666 - val_accuracy: 0.8430\n",
      "Epoch 98/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3637 - accuracy: 0.8463 - val_loss: 0.3621 - val_accuracy: 0.8471\n",
      "Epoch 99/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3637 - accuracy: 0.8461 - val_loss: 0.3639 - val_accuracy: 0.8464\n",
      "Epoch 100/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3636 - accuracy: 0.8461 - val_loss: 0.3632 - val_accuracy: 0.8474\n",
      "time taken for training :  20193.26433157921\n",
      "time taken for per epoch :  201.9326433157921\n",
      "\n",
      "\n",
      "\n",
      " Test file no :  8\n",
      "Dataset has been successfully prepared\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9029e097104c44b4a2cd469378eda23c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/8536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|████████████████| 10/10 [06:05<00:00, 36.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for training node embedding model :  3656.319500684738\n",
      "<bound method NDFrame.head of           src  dest  label\n",
      "0          56  3002      1\n",
      "1        7360  7394      1\n",
      "2        2417  5397      0\n",
      "3        8362  8386      1\n",
      "4        4936  7136      1\n",
      "...       ...   ...    ...\n",
      "1139397  5148  7380      1\n",
      "1139398  4176  6431      0\n",
      "1139399  6951  6223      0\n",
      "1139400  7671  4495      0\n",
      "1139401   634  5311      0\n",
      "\n",
      "[1139402 rows x 3 columns]>\n",
      "x_train and x_test are ready\n",
      "Epoch 1/100\n",
      "64092/64092 [==============================] - 211s 3ms/step - loss: 0.4109 - accuracy: 0.8263 - val_loss: 0.3906 - val_accuracy: 0.8403\n",
      "Epoch 2/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3889 - accuracy: 0.8370 - val_loss: 0.3832 - val_accuracy: 0.8437\n",
      "Epoch 3/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3841 - accuracy: 0.8390 - val_loss: 0.3827 - val_accuracy: 0.8427\n",
      "Epoch 4/100\n",
      "64092/64092 [==============================] - 208s 3ms/step - loss: 0.3815 - accuracy: 0.8398 - val_loss: 0.3790 - val_accuracy: 0.8445\n",
      "Epoch 5/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3791 - accuracy: 0.8407 - val_loss: 0.3770 - val_accuracy: 0.8427\n",
      "Epoch 6/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3775 - accuracy: 0.8410 - val_loss: 0.3752 - val_accuracy: 0.8443\n",
      "Epoch 7/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3760 - accuracy: 0.8418 - val_loss: 0.3735 - val_accuracy: 0.8445\n",
      "Epoch 8/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3750 - accuracy: 0.8421 - val_loss: 0.3731 - val_accuracy: 0.8441\n",
      "Epoch 9/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3739 - accuracy: 0.8425 - val_loss: 0.3721 - val_accuracy: 0.8446\n",
      "Epoch 10/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3733 - accuracy: 0.8428 - val_loss: 0.3700 - val_accuracy: 0.8454\n",
      "Epoch 11/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3727 - accuracy: 0.8427 - val_loss: 0.3696 - val_accuracy: 0.8454\n",
      "Epoch 12/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3721 - accuracy: 0.8432 - val_loss: 0.3708 - val_accuracy: 0.8445\n",
      "Epoch 13/100\n",
      "64092/64092 [==============================] - 208s 3ms/step - loss: 0.3715 - accuracy: 0.8434 - val_loss: 0.3691 - val_accuracy: 0.8448\n",
      "Epoch 14/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3712 - accuracy: 0.8434 - val_loss: 0.3678 - val_accuracy: 0.8467\n",
      "Epoch 15/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3708 - accuracy: 0.8437 - val_loss: 0.3724 - val_accuracy: 0.8463\n",
      "Epoch 16/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3705 - accuracy: 0.8436 - val_loss: 0.3683 - val_accuracy: 0.8466\n",
      "Epoch 17/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3701 - accuracy: 0.8437 - val_loss: 0.3687 - val_accuracy: 0.8469\n",
      "Epoch 18/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3699 - accuracy: 0.8439 - val_loss: 0.3690 - val_accuracy: 0.8458\n",
      "Epoch 19/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3698 - accuracy: 0.8440 - val_loss: 0.3692 - val_accuracy: 0.8469\n",
      "Epoch 20/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3696 - accuracy: 0.8441 - val_loss: 0.3692 - val_accuracy: 0.8461\n",
      "Epoch 21/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3695 - accuracy: 0.8441 - val_loss: 0.3693 - val_accuracy: 0.8471\n",
      "Epoch 22/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3692 - accuracy: 0.8443 - val_loss: 0.3727 - val_accuracy: 0.8436\n",
      "Epoch 23/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3691 - accuracy: 0.8441 - val_loss: 0.3683 - val_accuracy: 0.8474\n",
      "Epoch 24/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3689 - accuracy: 0.8442 - val_loss: 0.3677 - val_accuracy: 0.8459\n",
      "Epoch 25/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3687 - accuracy: 0.8443 - val_loss: 0.3701 - val_accuracy: 0.8448\n",
      "Epoch 26/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3686 - accuracy: 0.8443 - val_loss: 0.3670 - val_accuracy: 0.8462\n",
      "Epoch 27/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3684 - accuracy: 0.8443 - val_loss: 0.3679 - val_accuracy: 0.8471\n",
      "Epoch 28/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3682 - accuracy: 0.8445 - val_loss: 0.3714 - val_accuracy: 0.8430\n",
      "Epoch 29/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3681 - accuracy: 0.8444 - val_loss: 0.3670 - val_accuracy: 0.8473\n",
      "Epoch 30/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3679 - accuracy: 0.8445 - val_loss: 0.3680 - val_accuracy: 0.8453\n",
      "Epoch 31/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3678 - accuracy: 0.8445 - val_loss: 0.3668 - val_accuracy: 0.8460\n",
      "Epoch 32/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3677 - accuracy: 0.8445 - val_loss: 0.3668 - val_accuracy: 0.8473\n",
      "Epoch 33/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3676 - accuracy: 0.8444 - val_loss: 0.3674 - val_accuracy: 0.8460\n",
      "Epoch 34/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3675 - accuracy: 0.8446 - val_loss: 0.3668 - val_accuracy: 0.8477\n",
      "Epoch 35/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3674 - accuracy: 0.8446 - val_loss: 0.3650 - val_accuracy: 0.8482\n",
      "Epoch 36/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3673 - accuracy: 0.8448 - val_loss: 0.3653 - val_accuracy: 0.8478\n",
      "Epoch 37/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3673 - accuracy: 0.8445 - val_loss: 0.3664 - val_accuracy: 0.8456\n",
      "Epoch 38/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3671 - accuracy: 0.8450 - val_loss: 0.3670 - val_accuracy: 0.8471\n",
      "Epoch 39/100\n",
      "64092/64092 [==============================] - 209s 3ms/step - loss: 0.3670 - accuracy: 0.8449 - val_loss: 0.3662 - val_accuracy: 0.8469\n",
      "Epoch 40/100\n",
      "64092/64092 [==============================] - 208s 3ms/step - loss: 0.3668 - accuracy: 0.8449 - val_loss: 0.3658 - val_accuracy: 0.8459\n",
      "Epoch 41/100\n",
      "64092/64092 [==============================] - 209s 3ms/step - loss: 0.3668 - accuracy: 0.8450 - val_loss: 0.3661 - val_accuracy: 0.8478\n",
      "Epoch 42/100\n",
      "64092/64092 [==============================] - 209s 3ms/step - loss: 0.3667 - accuracy: 0.8450 - val_loss: 0.3659 - val_accuracy: 0.8470\n",
      "Epoch 43/100\n",
      "64092/64092 [==============================] - 208s 3ms/step - loss: 0.3667 - accuracy: 0.8449 - val_loss: 0.3655 - val_accuracy: 0.8464\n",
      "Epoch 44/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3667 - accuracy: 0.8448 - val_loss: 0.3656 - val_accuracy: 0.8475\n",
      "Epoch 45/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3667 - accuracy: 0.8448 - val_loss: 0.3640 - val_accuracy: 0.8475\n",
      "Epoch 46/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3666 - accuracy: 0.8451 - val_loss: 0.3653 - val_accuracy: 0.8475\n",
      "Epoch 47/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3665 - accuracy: 0.8449 - val_loss: 0.3679 - val_accuracy: 0.8459\n",
      "Epoch 48/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3664 - accuracy: 0.8449 - val_loss: 0.3660 - val_accuracy: 0.8479\n",
      "Epoch 49/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3664 - accuracy: 0.8450 - val_loss: 0.3690 - val_accuracy: 0.8438\n",
      "Epoch 50/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3663 - accuracy: 0.8449 - val_loss: 0.3657 - val_accuracy: 0.8473\n",
      "Epoch 51/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3662 - accuracy: 0.8449 - val_loss: 0.3664 - val_accuracy: 0.8483\n",
      "Epoch 52/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3662 - accuracy: 0.8450 - val_loss: 0.3650 - val_accuracy: 0.8470\n",
      "Epoch 53/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3661 - accuracy: 0.8451 - val_loss: 0.3637 - val_accuracy: 0.8478\n",
      "Epoch 54/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3661 - accuracy: 0.8452 - val_loss: 0.3649 - val_accuracy: 0.8476\n",
      "Epoch 55/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3661 - accuracy: 0.8452 - val_loss: 0.3661 - val_accuracy: 0.8469\n",
      "Epoch 56/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3660 - accuracy: 0.8452 - val_loss: 0.3647 - val_accuracy: 0.8468\n",
      "Epoch 57/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3660 - accuracy: 0.8451 - val_loss: 0.3718 - val_accuracy: 0.8473\n",
      "Epoch 58/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3658 - accuracy: 0.8451 - val_loss: 0.3655 - val_accuracy: 0.8459\n",
      "Epoch 59/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3660 - accuracy: 0.8452 - val_loss: 0.3649 - val_accuracy: 0.8467\n",
      "Epoch 60/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3658 - accuracy: 0.8454 - val_loss: 0.3664 - val_accuracy: 0.8459\n",
      "Epoch 61/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3658 - accuracy: 0.8451 - val_loss: 0.3678 - val_accuracy: 0.8477\n",
      "Epoch 62/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3656 - accuracy: 0.8454 - val_loss: 0.3635 - val_accuracy: 0.8475\n",
      "Epoch 63/100\n",
      "64092/64092 [==============================] - 190s 3ms/step - loss: 0.3657 - accuracy: 0.8452 - val_loss: 0.3653 - val_accuracy: 0.8482\n",
      "Epoch 64/100\n",
      "64092/64092 [==============================] - 193s 3ms/step - loss: 0.3655 - accuracy: 0.8454 - val_loss: 0.3680 - val_accuracy: 0.8490\n",
      "Epoch 65/100\n",
      "64092/64092 [==============================] - 194s 3ms/step - loss: 0.3655 - accuracy: 0.8453 - val_loss: 0.3640 - val_accuracy: 0.8474\n",
      "Epoch 66/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3655 - accuracy: 0.8454 - val_loss: 0.3648 - val_accuracy: 0.8475\n",
      "Epoch 67/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3655 - accuracy: 0.8454 - val_loss: 0.3627 - val_accuracy: 0.8480\n",
      "Epoch 68/100\n",
      "64092/64092 [==============================] - 219s 3ms/step - loss: 0.3654 - accuracy: 0.8454 - val_loss: 0.3701 - val_accuracy: 0.8481\n",
      "Epoch 69/100\n",
      "64092/64092 [==============================] - 219s 3ms/step - loss: 0.3654 - accuracy: 0.8454 - val_loss: 0.3634 - val_accuracy: 0.8473\n",
      "Epoch 70/100\n",
      "64092/64092 [==============================] - 219s 3ms/step - loss: 0.3654 - accuracy: 0.8454 - val_loss: 0.3660 - val_accuracy: 0.8460\n",
      "Epoch 71/100\n",
      "64092/64092 [==============================] - 218s 3ms/step - loss: 0.3653 - accuracy: 0.8453 - val_loss: 0.3638 - val_accuracy: 0.8490\n",
      "Epoch 72/100\n",
      "64092/64092 [==============================] - 218s 3ms/step - loss: 0.3654 - accuracy: 0.8456 - val_loss: 0.3649 - val_accuracy: 0.8476\n",
      "Epoch 73/100\n",
      "64092/64092 [==============================] - 218s 3ms/step - loss: 0.3653 - accuracy: 0.8454 - val_loss: 0.3657 - val_accuracy: 0.8462\n",
      "Epoch 74/100\n",
      "64092/64092 [==============================] - 218s 3ms/step - loss: 0.3653 - accuracy: 0.8455 - val_loss: 0.3632 - val_accuracy: 0.8489\n",
      "Epoch 75/100\n",
      "64092/64092 [==============================] - 218s 3ms/step - loss: 0.3652 - accuracy: 0.8453 - val_loss: 0.3660 - val_accuracy: 0.8483\n",
      "Epoch 76/100\n",
      "64092/64092 [==============================] - 218s 3ms/step - loss: 0.3651 - accuracy: 0.8455 - val_loss: 0.3641 - val_accuracy: 0.8490\n",
      "Epoch 77/100\n",
      "64092/64092 [==============================] - 217s 3ms/step - loss: 0.3652 - accuracy: 0.8454 - val_loss: 0.3643 - val_accuracy: 0.8466\n",
      "Epoch 78/100\n",
      "64092/64092 [==============================] - 217s 3ms/step - loss: 0.3651 - accuracy: 0.8456 - val_loss: 0.3648 - val_accuracy: 0.8472\n",
      "Epoch 79/100\n",
      "64092/64092 [==============================] - 218s 3ms/step - loss: 0.3651 - accuracy: 0.8455 - val_loss: 0.3655 - val_accuracy: 0.8465\n",
      "Epoch 80/100\n",
      "64092/64092 [==============================] - 217s 3ms/step - loss: 0.3650 - accuracy: 0.8456 - val_loss: 0.3665 - val_accuracy: 0.8483\n",
      "Epoch 81/100\n",
      "64092/64092 [==============================] - 217s 3ms/step - loss: 0.3651 - accuracy: 0.8456 - val_loss: 0.3642 - val_accuracy: 0.8477\n",
      "Epoch 82/100\n",
      "64092/64092 [==============================] - 217s 3ms/step - loss: 0.3650 - accuracy: 0.8456 - val_loss: 0.3651 - val_accuracy: 0.8486\n",
      "Epoch 83/100\n",
      "64092/64092 [==============================] - 217s 3ms/step - loss: 0.3649 - accuracy: 0.8457 - val_loss: 0.3640 - val_accuracy: 0.8471\n",
      "Epoch 84/100\n",
      "64092/64092 [==============================] - 218s 3ms/step - loss: 0.3650 - accuracy: 0.8456 - val_loss: 0.3637 - val_accuracy: 0.8485\n",
      "Epoch 85/100\n",
      "64092/64092 [==============================] - 217s 3ms/step - loss: 0.3648 - accuracy: 0.8458 - val_loss: 0.3649 - val_accuracy: 0.8468\n",
      "Epoch 86/100\n",
      "64092/64092 [==============================] - 217s 3ms/step - loss: 0.3649 - accuracy: 0.8458 - val_loss: 0.3645 - val_accuracy: 0.8458\n",
      "Epoch 87/100\n",
      "64092/64092 [==============================] - 217s 3ms/step - loss: 0.3649 - accuracy: 0.8456 - val_loss: 0.3643 - val_accuracy: 0.8484\n",
      "Epoch 88/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3649 - accuracy: 0.8458 - val_loss: 0.3640 - val_accuracy: 0.8469\n",
      "Epoch 89/100\n",
      "64092/64092 [==============================] - 189s 3ms/step - loss: 0.3648 - accuracy: 0.8458 - val_loss: 0.3647 - val_accuracy: 0.8483\n",
      "Epoch 90/100\n",
      "64092/64092 [==============================] - 189s 3ms/step - loss: 0.3648 - accuracy: 0.8459 - val_loss: 0.3649 - val_accuracy: 0.8484\n",
      "Epoch 91/100\n",
      "64092/64092 [==============================] - 190s 3ms/step - loss: 0.3648 - accuracy: 0.8458 - val_loss: 0.3644 - val_accuracy: 0.8472\n",
      "Epoch 92/100\n",
      "64092/64092 [==============================] - 189s 3ms/step - loss: 0.3647 - accuracy: 0.8459 - val_loss: 0.3650 - val_accuracy: 0.8490\n",
      "Epoch 93/100\n",
      "64092/64092 [==============================] - 190s 3ms/step - loss: 0.3647 - accuracy: 0.8458 - val_loss: 0.3635 - val_accuracy: 0.8490\n",
      "Epoch 94/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3648 - accuracy: 0.8458 - val_loss: 0.3651 - val_accuracy: 0.8483\n",
      "Epoch 95/100\n",
      "64092/64092 [==============================] - 186s 3ms/step - loss: 0.3646 - accuracy: 0.8459 - val_loss: 0.3632 - val_accuracy: 0.8491\n",
      "Epoch 96/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3646 - accuracy: 0.8456 - val_loss: 0.3659 - val_accuracy: 0.8460\n",
      "Epoch 97/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3646 - accuracy: 0.8457 - val_loss: 0.3667 - val_accuracy: 0.8459\n",
      "Epoch 98/100\n",
      "64092/64092 [==============================] - 213s 3ms/step - loss: 0.3646 - accuracy: 0.8459 - val_loss: 0.3640 - val_accuracy: 0.8491\n",
      "Epoch 99/100\n",
      "64092/64092 [==============================] - 213s 3ms/step - loss: 0.3646 - accuracy: 0.8456 - val_loss: 0.3642 - val_accuracy: 0.8494\n",
      "Epoch 100/100\n",
      "64092/64092 [==============================] - 211s 3ms/step - loss: 0.3646 - accuracy: 0.8459 - val_loss: 0.3647 - val_accuracy: 0.8474\n",
      "time taken for training :  20695.888483285904\n",
      "time taken for per epoch :  206.95888483285904\n",
      "\n",
      "\n",
      "\n",
      " Test file no :  9\n",
      "Dataset has been successfully prepared\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ec39fdafbf4de2acc9500e93fd68d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/8536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|████████████████| 10/10 [06:08<00:00, 36.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for training node embedding model :  4054.587105512619\n",
      "<bound method NDFrame.head of           src  dest  label\n",
      "0          36  2575      1\n",
      "1        2495  3836      0\n",
      "2         591  2171      1\n",
      "3        2381   413      0\n",
      "4        5550  5564      1\n",
      "...       ...   ...    ...\n",
      "1139397  5773  5406      0\n",
      "1139398  8105  8109      0\n",
      "1139399  5683  6910      1\n",
      "1139400  6084  7120      1\n",
      "1139401  3456  4520      0\n",
      "\n",
      "[1139402 rows x 3 columns]>\n",
      "x_train and x_test are ready\n",
      "Epoch 1/100\n",
      "64092/64092 [==============================] - 224s 3ms/step - loss: 0.4102 - accuracy: 0.8254 - val_loss: 0.3926 - val_accuracy: 0.8352\n",
      "Epoch 2/100\n",
      "64092/64092 [==============================] - 220s 3ms/step - loss: 0.3866 - accuracy: 0.8372 - val_loss: 0.3850 - val_accuracy: 0.8388\n",
      "Epoch 3/100\n",
      "64092/64092 [==============================] - 222s 3ms/step - loss: 0.3811 - accuracy: 0.8394 - val_loss: 0.3836 - val_accuracy: 0.8404\n",
      "Epoch 4/100\n",
      "64092/64092 [==============================] - 222s 3ms/step - loss: 0.3780 - accuracy: 0.8406 - val_loss: 0.3781 - val_accuracy: 0.8412\n",
      "Epoch 5/100\n",
      "64092/64092 [==============================] - 222s 3ms/step - loss: 0.3758 - accuracy: 0.8414 - val_loss: 0.3827 - val_accuracy: 0.8371\n",
      "Epoch 6/100\n",
      "64092/64092 [==============================] - 216s 3ms/step - loss: 0.3746 - accuracy: 0.8420 - val_loss: 0.3777 - val_accuracy: 0.8425\n",
      "Epoch 7/100\n",
      "64092/64092 [==============================] - 217s 3ms/step - loss: 0.3737 - accuracy: 0.8424 - val_loss: 0.3751 - val_accuracy: 0.8420\n",
      "Epoch 8/100\n",
      "64092/64092 [==============================] - 216s 3ms/step - loss: 0.3729 - accuracy: 0.8428 - val_loss: 0.3758 - val_accuracy: 0.8422\n",
      "Epoch 9/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3722 - accuracy: 0.8429 - val_loss: 0.3758 - val_accuracy: 0.8415\n",
      "Epoch 10/100\n",
      "64092/64092 [==============================] - 216s 3ms/step - loss: 0.3716 - accuracy: 0.8433 - val_loss: 0.3757 - val_accuracy: 0.8430\n",
      "Epoch 11/100\n",
      "64092/64092 [==============================] - 217s 3ms/step - loss: 0.3711 - accuracy: 0.8433 - val_loss: 0.3721 - val_accuracy: 0.8447\n",
      "Epoch 12/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3707 - accuracy: 0.8438 - val_loss: 0.3735 - val_accuracy: 0.8427\n",
      "Epoch 13/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3704 - accuracy: 0.8437 - val_loss: 0.3722 - val_accuracy: 0.8432\n",
      "Epoch 14/100\n",
      "64092/64092 [==============================] - 216s 3ms/step - loss: 0.3701 - accuracy: 0.8438 - val_loss: 0.3720 - val_accuracy: 0.8432\n",
      "Epoch 15/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3697 - accuracy: 0.8440 - val_loss: 0.3769 - val_accuracy: 0.8406\n",
      "Epoch 16/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3695 - accuracy: 0.8439 - val_loss: 0.3748 - val_accuracy: 0.8442\n",
      "Epoch 17/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3692 - accuracy: 0.8440 - val_loss: 0.3747 - val_accuracy: 0.8424\n",
      "Epoch 18/100\n",
      "64092/64092 [==============================] - 216s 3ms/step - loss: 0.3689 - accuracy: 0.8441 - val_loss: 0.3727 - val_accuracy: 0.8420\n",
      "Epoch 19/100\n",
      "64092/64092 [==============================] - 216s 3ms/step - loss: 0.3686 - accuracy: 0.8441 - val_loss: 0.3706 - val_accuracy: 0.8434\n",
      "Epoch 20/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3684 - accuracy: 0.8443 - val_loss: 0.3750 - val_accuracy: 0.8441\n",
      "Epoch 21/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3683 - accuracy: 0.8446 - val_loss: 0.3715 - val_accuracy: 0.8446\n",
      "Epoch 22/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3680 - accuracy: 0.8445 - val_loss: 0.3703 - val_accuracy: 0.8440\n",
      "Epoch 23/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3678 - accuracy: 0.8446 - val_loss: 0.3721 - val_accuracy: 0.8452\n",
      "Epoch 24/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3676 - accuracy: 0.8447 - val_loss: 0.3716 - val_accuracy: 0.8447\n",
      "Epoch 25/100\n",
      "64092/64092 [==============================] - 220s 3ms/step - loss: 0.3675 - accuracy: 0.8449 - val_loss: 0.3711 - val_accuracy: 0.8439\n",
      "Epoch 26/100\n",
      "64092/64092 [==============================] - 216s 3ms/step - loss: 0.3672 - accuracy: 0.8449 - val_loss: 0.3717 - val_accuracy: 0.8450\n",
      "Epoch 27/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3671 - accuracy: 0.8449 - val_loss: 0.3711 - val_accuracy: 0.8425\n",
      "Epoch 28/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3671 - accuracy: 0.8450 - val_loss: 0.3713 - val_accuracy: 0.8456\n",
      "Epoch 29/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3669 - accuracy: 0.8452 - val_loss: 0.3718 - val_accuracy: 0.8444\n",
      "Epoch 30/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3668 - accuracy: 0.8449 - val_loss: 0.3707 - val_accuracy: 0.8434\n",
      "Epoch 31/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3667 - accuracy: 0.8451 - val_loss: 0.3760 - val_accuracy: 0.8440\n",
      "Epoch 32/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3666 - accuracy: 0.8452 - val_loss: 0.3702 - val_accuracy: 0.8452\n",
      "Epoch 33/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3665 - accuracy: 0.8453 - val_loss: 0.3697 - val_accuracy: 0.8454\n",
      "Epoch 34/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3663 - accuracy: 0.8454 - val_loss: 0.3727 - val_accuracy: 0.8423\n",
      "Epoch 35/100\n",
      "64092/64092 [==============================] - 218s 3ms/step - loss: 0.3662 - accuracy: 0.8454 - val_loss: 0.3719 - val_accuracy: 0.8448\n",
      "Epoch 36/100\n",
      "64092/64092 [==============================] - 218s 3ms/step - loss: 0.3662 - accuracy: 0.8454 - val_loss: 0.3721 - val_accuracy: 0.8421\n",
      "Epoch 37/100\n",
      "64092/64092 [==============================] - 218s 3ms/step - loss: 0.3660 - accuracy: 0.8456 - val_loss: 0.3684 - val_accuracy: 0.8459\n",
      "Epoch 38/100\n",
      "64092/64092 [==============================] - 218s 3ms/step - loss: 0.3658 - accuracy: 0.8457 - val_loss: 0.3699 - val_accuracy: 0.8451\n",
      "Epoch 39/100\n",
      "64092/64092 [==============================] - 217s 3ms/step - loss: 0.3658 - accuracy: 0.8456 - val_loss: 0.3690 - val_accuracy: 0.8452\n",
      "Epoch 40/100\n",
      "64092/64092 [==============================] - 217s 3ms/step - loss: 0.3657 - accuracy: 0.8458 - val_loss: 0.3695 - val_accuracy: 0.8447\n",
      "Epoch 41/100\n",
      "64092/64092 [==============================] - 217s 3ms/step - loss: 0.3655 - accuracy: 0.8458 - val_loss: 0.3698 - val_accuracy: 0.8452\n",
      "Epoch 42/100\n",
      "64092/64092 [==============================] - 217s 3ms/step - loss: 0.3655 - accuracy: 0.8457 - val_loss: 0.3691 - val_accuracy: 0.8454\n",
      "Epoch 43/100\n",
      "64092/64092 [==============================] - 217s 3ms/step - loss: 0.3654 - accuracy: 0.8459 - val_loss: 0.3688 - val_accuracy: 0.8447\n",
      "Epoch 44/100\n",
      "64092/64092 [==============================] - 217s 3ms/step - loss: 0.3654 - accuracy: 0.8456 - val_loss: 0.3684 - val_accuracy: 0.8461\n",
      "Epoch 45/100\n",
      "64092/64092 [==============================] - 217s 3ms/step - loss: 0.3653 - accuracy: 0.8458 - val_loss: 0.3711 - val_accuracy: 0.8456\n",
      "Epoch 46/100\n",
      "64092/64092 [==============================] - 216s 3ms/step - loss: 0.3653 - accuracy: 0.8457 - val_loss: 0.3694 - val_accuracy: 0.8448\n",
      "Epoch 47/100\n",
      "64092/64092 [==============================] - 217s 3ms/step - loss: 0.3651 - accuracy: 0.8460 - val_loss: 0.3738 - val_accuracy: 0.8454\n",
      "Epoch 48/100\n",
      "64092/64092 [==============================] - 216s 3ms/step - loss: 0.3651 - accuracy: 0.8459 - val_loss: 0.3694 - val_accuracy: 0.8448\n",
      "Epoch 49/100\n",
      "64092/64092 [==============================] - 216s 3ms/step - loss: 0.3650 - accuracy: 0.8461 - val_loss: 0.3691 - val_accuracy: 0.8463\n",
      "Epoch 50/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3650 - accuracy: 0.8460 - val_loss: 0.3770 - val_accuracy: 0.8394\n",
      "Epoch 51/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3650 - accuracy: 0.8460 - val_loss: 0.3685 - val_accuracy: 0.8451\n",
      "Epoch 52/100\n",
      "64092/64092 [==============================] - 216s 3ms/step - loss: 0.3650 - accuracy: 0.8460 - val_loss: 0.3695 - val_accuracy: 0.8456\n",
      "Epoch 53/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3649 - accuracy: 0.8459 - val_loss: 0.3706 - val_accuracy: 0.8435\n",
      "Epoch 54/100\n",
      "64092/64092 [==============================] - 216s 3ms/step - loss: 0.3648 - accuracy: 0.8460 - val_loss: 0.3690 - val_accuracy: 0.8448\n",
      "Epoch 55/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3647 - accuracy: 0.8461 - val_loss: 0.3706 - val_accuracy: 0.8458\n",
      "Epoch 56/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3646 - accuracy: 0.8461 - val_loss: 0.3711 - val_accuracy: 0.8460\n",
      "Epoch 57/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3646 - accuracy: 0.8463 - val_loss: 0.3731 - val_accuracy: 0.8461\n",
      "Epoch 58/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3646 - accuracy: 0.8463 - val_loss: 0.3684 - val_accuracy: 0.8463\n",
      "Epoch 59/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3645 - accuracy: 0.8463 - val_loss: 0.3684 - val_accuracy: 0.8468\n",
      "Epoch 60/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3644 - accuracy: 0.8463 - val_loss: 0.3676 - val_accuracy: 0.8460\n",
      "Epoch 61/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3644 - accuracy: 0.8465 - val_loss: 0.3692 - val_accuracy: 0.8449\n",
      "Epoch 62/100\n",
      "64092/64092 [==============================] - 215s 3ms/step - loss: 0.3644 - accuracy: 0.8462 - val_loss: 0.3690 - val_accuracy: 0.8459\n",
      "Epoch 63/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3643 - accuracy: 0.8464 - val_loss: 0.3696 - val_accuracy: 0.8461\n",
      "Epoch 64/100\n",
      "64092/64092 [==============================] - 212s 3ms/step - loss: 0.3643 - accuracy: 0.8463 - val_loss: 0.3690 - val_accuracy: 0.8449\n",
      "Epoch 65/100\n",
      "64092/64092 [==============================] - 210s 3ms/step - loss: 0.3643 - accuracy: 0.8464 - val_loss: 0.3745 - val_accuracy: 0.8458\n",
      "Epoch 66/100\n",
      "64092/64092 [==============================] - 211s 3ms/step - loss: 0.3641 - accuracy: 0.8465 - val_loss: 0.3701 - val_accuracy: 0.8449\n",
      "Epoch 67/100\n",
      "64092/64092 [==============================] - 212s 3ms/step - loss: 0.3641 - accuracy: 0.8463 - val_loss: 0.3679 - val_accuracy: 0.8464\n",
      "Epoch 68/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3640 - accuracy: 0.8464 - val_loss: 0.3700 - val_accuracy: 0.8452\n",
      "Epoch 69/100\n",
      "64092/64092 [==============================] - 216s 3ms/step - loss: 0.3641 - accuracy: 0.8465 - val_loss: 0.3690 - val_accuracy: 0.8455\n",
      "Epoch 70/100\n",
      "64092/64092 [==============================] - 217s 3ms/step - loss: 0.3640 - accuracy: 0.8464 - val_loss: 0.3681 - val_accuracy: 0.8459\n",
      "Epoch 71/100\n",
      "64092/64092 [==============================] - 217s 3ms/step - loss: 0.3640 - accuracy: 0.8465 - val_loss: 0.3711 - val_accuracy: 0.8432\n",
      "Epoch 72/100\n",
      "64092/64092 [==============================] - 214s 3ms/step - loss: 0.3638 - accuracy: 0.8466 - val_loss: 0.3689 - val_accuracy: 0.8470\n",
      "Epoch 73/100\n",
      "64092/64092 [==============================] - 208s 3ms/step - loss: 0.3638 - accuracy: 0.8466 - val_loss: 0.3692 - val_accuracy: 0.8454\n",
      "Epoch 74/100\n",
      "64092/64092 [==============================] - 200s 3ms/step - loss: 0.3638 - accuracy: 0.8465 - val_loss: 0.3746 - val_accuracy: 0.8461\n",
      "Epoch 75/100\n",
      "64092/64092 [==============================] - 199s 3ms/step - loss: 0.3638 - accuracy: 0.8465 - val_loss: 0.3686 - val_accuracy: 0.8456\n",
      "Epoch 76/100\n",
      "64092/64092 [==============================] - 199s 3ms/step - loss: 0.3638 - accuracy: 0.8465 - val_loss: 0.3716 - val_accuracy: 0.8429\n",
      "Epoch 77/100\n",
      "64092/64092 [==============================] - 200s 3ms/step - loss: 0.3638 - accuracy: 0.8466 - val_loss: 0.3682 - val_accuracy: 0.8463\n",
      "Epoch 78/100\n",
      "64092/64092 [==============================] - 199s 3ms/step - loss: 0.3637 - accuracy: 0.8466 - val_loss: 0.3677 - val_accuracy: 0.8458\n",
      "Epoch 79/100\n",
      "64092/64092 [==============================] - 199s 3ms/step - loss: 0.3637 - accuracy: 0.8465 - val_loss: 0.3703 - val_accuracy: 0.8446\n",
      "Epoch 80/100\n",
      "64092/64092 [==============================] - 199s 3ms/step - loss: 0.3638 - accuracy: 0.8465 - val_loss: 0.3704 - val_accuracy: 0.8438\n",
      "Epoch 81/100\n",
      "64092/64092 [==============================] - 199s 3ms/step - loss: 0.3638 - accuracy: 0.8466 - val_loss: 0.3675 - val_accuracy: 0.8463\n",
      "Epoch 82/100\n",
      "64092/64092 [==============================] - 199s 3ms/step - loss: 0.3636 - accuracy: 0.8468 - val_loss: 0.3687 - val_accuracy: 0.8474\n",
      "Epoch 83/100\n",
      "64092/64092 [==============================] - 198s 3ms/step - loss: 0.3636 - accuracy: 0.8467 - val_loss: 0.3697 - val_accuracy: 0.8466\n",
      "Epoch 84/100\n",
      "64092/64092 [==============================] - 198s 3ms/step - loss: 0.3634 - accuracy: 0.8467 - val_loss: 0.3686 - val_accuracy: 0.8470\n",
      "Epoch 85/100\n",
      "64092/64092 [==============================] - 198s 3ms/step - loss: 0.3635 - accuracy: 0.8468 - val_loss: 0.3688 - val_accuracy: 0.8468\n",
      "Epoch 86/100\n",
      "64092/64092 [==============================] - 199s 3ms/step - loss: 0.3635 - accuracy: 0.8466 - val_loss: 0.3703 - val_accuracy: 0.8472\n",
      "Epoch 87/100\n",
      "64092/64092 [==============================] - 198s 3ms/step - loss: 0.3635 - accuracy: 0.8467 - val_loss: 0.3678 - val_accuracy: 0.8461\n",
      "Epoch 88/100\n",
      "64092/64092 [==============================] - 198s 3ms/step - loss: 0.3635 - accuracy: 0.8468 - val_loss: 0.3708 - val_accuracy: 0.8467\n",
      "Epoch 89/100\n",
      "64092/64092 [==============================] - 198s 3ms/step - loss: 0.3634 - accuracy: 0.8467 - val_loss: 0.3682 - val_accuracy: 0.8465\n",
      "Epoch 90/100\n",
      "64092/64092 [==============================] - 198s 3ms/step - loss: 0.3635 - accuracy: 0.8468 - val_loss: 0.3673 - val_accuracy: 0.8459\n",
      "Epoch 91/100\n",
      "64092/64092 [==============================] - 198s 3ms/step - loss: 0.3634 - accuracy: 0.8467 - val_loss: 0.3692 - val_accuracy: 0.8453\n",
      "Epoch 92/100\n",
      "64092/64092 [==============================] - 198s 3ms/step - loss: 0.3634 - accuracy: 0.8469 - val_loss: 0.3679 - val_accuracy: 0.8458\n",
      "Epoch 93/100\n",
      "64092/64092 [==============================] - 199s 3ms/step - loss: 0.3634 - accuracy: 0.8466 - val_loss: 0.3690 - val_accuracy: 0.8445\n",
      "Epoch 94/100\n",
      "64092/64092 [==============================] - 200s 3ms/step - loss: 0.3634 - accuracy: 0.8467 - val_loss: 0.3706 - val_accuracy: 0.8453\n",
      "Epoch 95/100\n",
      "64092/64092 [==============================] - 199s 3ms/step - loss: 0.3633 - accuracy: 0.8468 - val_loss: 0.3703 - val_accuracy: 0.8436\n",
      "Epoch 96/100\n",
      "64092/64092 [==============================] - 199s 3ms/step - loss: 0.3634 - accuracy: 0.8467 - val_loss: 0.3693 - val_accuracy: 0.8468\n",
      "Epoch 97/100\n",
      "64092/64092 [==============================] - 199s 3ms/step - loss: 0.3632 - accuracy: 0.8469 - val_loss: 0.3693 - val_accuracy: 0.8465\n",
      "Epoch 98/100\n",
      "64092/64092 [==============================] - 199s 3ms/step - loss: 0.3632 - accuracy: 0.8468 - val_loss: 0.3678 - val_accuracy: 0.8474\n",
      "Epoch 99/100\n",
      "64092/64092 [==============================] - 199s 3ms/step - loss: 0.3633 - accuracy: 0.8468 - val_loss: 0.3690 - val_accuracy: 0.8464\n",
      "Epoch 100/100\n",
      "64092/64092 [==============================] - 199s 3ms/step - loss: 0.3631 - accuracy: 0.8467 - val_loss: 0.3673 - val_accuracy: 0.8470\n",
      "time taken for training :  21122.417823076248\n",
      "time taken for per epoch :  211.22417823076248\n",
      "\n",
      "\n",
      "\n",
      " Test file no :  10\n",
      "Dataset has been successfully prepared\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5646f8b610844ffaaaca5901631e9be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/8536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|████████████████| 10/10 [04:24<00:00, 26.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for training node embedding model :  3597.5214138031006\n",
      "<bound method NDFrame.head of           src  dest  label\n",
      "0        5069  6945      1\n",
      "1          91  2162      1\n",
      "2        5715  5931      1\n",
      "3         655  2548      0\n",
      "4        5918  7522      0\n",
      "...       ...   ...    ...\n",
      "1139397   286  5977      1\n",
      "1139398  2702  6214      0\n",
      "1139399    60  1049      1\n",
      "1139400  1697  1436      0\n",
      "1139401  8284  7522      0\n",
      "\n",
      "[1139402 rows x 3 columns]>\n",
      "x_train and x_test are ready\n",
      "Epoch 1/100\n",
      "64092/64092 [==============================] - 430s 6ms/step - loss: 0.4116 - accuracy: 0.8240 - val_loss: 0.3922 - val_accuracy: 0.8338\n",
      "Epoch 2/100\n",
      "64092/64092 [==============================] - 351s 5ms/step - loss: 0.3879 - accuracy: 0.8359 - val_loss: 0.3833 - val_accuracy: 0.8374\n",
      "Epoch 3/100\n",
      "64092/64092 [==============================] - 344s 5ms/step - loss: 0.3814 - accuracy: 0.8385 - val_loss: 0.3811 - val_accuracy: 0.8371\n",
      "Epoch 4/100\n",
      "64092/64092 [==============================] - 347s 5ms/step - loss: 0.3782 - accuracy: 0.8401 - val_loss: 0.3764 - val_accuracy: 0.8414\n",
      "Epoch 5/100\n",
      "64092/64092 [==============================] - 316s 5ms/step - loss: 0.3760 - accuracy: 0.8411 - val_loss: 0.3775 - val_accuracy: 0.8389\n",
      "Epoch 6/100\n",
      "64092/64092 [==============================] - 270s 4ms/step - loss: 0.3749 - accuracy: 0.8415 - val_loss: 0.3770 - val_accuracy: 0.8403\n",
      "Epoch 7/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3738 - accuracy: 0.8419 - val_loss: 0.3761 - val_accuracy: 0.8399\n",
      "Epoch 8/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3731 - accuracy: 0.8422 - val_loss: 0.3733 - val_accuracy: 0.8406\n",
      "Epoch 9/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3724 - accuracy: 0.8424 - val_loss: 0.3740 - val_accuracy: 0.8424\n",
      "Epoch 10/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3718 - accuracy: 0.8428 - val_loss: 0.3722 - val_accuracy: 0.8423\n",
      "Epoch 11/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3713 - accuracy: 0.8428 - val_loss: 0.3720 - val_accuracy: 0.8423\n",
      "Epoch 12/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3710 - accuracy: 0.8431 - val_loss: 0.3759 - val_accuracy: 0.8389\n",
      "Epoch 13/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3708 - accuracy: 0.8430 - val_loss: 0.3719 - val_accuracy: 0.8409\n",
      "Epoch 14/100\n",
      "64092/64092 [==============================] - 200s 3ms/step - loss: 0.3704 - accuracy: 0.8433 - val_loss: 0.3713 - val_accuracy: 0.8409\n",
      "Epoch 15/100\n",
      "64092/64092 [==============================] - 200s 3ms/step - loss: 0.3701 - accuracy: 0.8435 - val_loss: 0.3702 - val_accuracy: 0.8438\n",
      "Epoch 16/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3698 - accuracy: 0.8437 - val_loss: 0.3696 - val_accuracy: 0.8433\n",
      "Epoch 17/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3695 - accuracy: 0.8436 - val_loss: 0.3717 - val_accuracy: 0.8422\n",
      "Epoch 18/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3694 - accuracy: 0.8439 - val_loss: 0.3701 - val_accuracy: 0.8433\n",
      "Epoch 19/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3692 - accuracy: 0.8438 - val_loss: 0.3703 - val_accuracy: 0.8431\n",
      "Epoch 20/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3691 - accuracy: 0.8441 - val_loss: 0.3705 - val_accuracy: 0.8440\n",
      "Epoch 21/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3686 - accuracy: 0.8441 - val_loss: 0.3704 - val_accuracy: 0.8436\n",
      "Epoch 22/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3686 - accuracy: 0.8442 - val_loss: 0.3708 - val_accuracy: 0.8434\n",
      "Epoch 23/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3684 - accuracy: 0.8441 - val_loss: 0.3709 - val_accuracy: 0.8431\n",
      "Epoch 24/100\n",
      "64092/64092 [==============================] - 200s 3ms/step - loss: 0.3681 - accuracy: 0.8443 - val_loss: 0.3731 - val_accuracy: 0.8423\n",
      "Epoch 25/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3681 - accuracy: 0.8445 - val_loss: 0.3708 - val_accuracy: 0.8424\n",
      "Epoch 26/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3680 - accuracy: 0.8443 - val_loss: 0.3683 - val_accuracy: 0.8437\n",
      "Epoch 27/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3679 - accuracy: 0.8444 - val_loss: 0.3690 - val_accuracy: 0.8442\n",
      "Epoch 28/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3677 - accuracy: 0.8445 - val_loss: 0.3707 - val_accuracy: 0.8420\n",
      "Epoch 29/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3677 - accuracy: 0.8445 - val_loss: 0.3711 - val_accuracy: 0.8415\n",
      "Epoch 30/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3676 - accuracy: 0.8444 - val_loss: 0.3703 - val_accuracy: 0.8430\n",
      "Epoch 31/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3675 - accuracy: 0.8445 - val_loss: 0.3829 - val_accuracy: 0.8351\n",
      "Epoch 32/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3673 - accuracy: 0.8446 - val_loss: 0.3683 - val_accuracy: 0.8441\n",
      "Epoch 33/100\n",
      "64092/64092 [==============================] - 200s 3ms/step - loss: 0.3673 - accuracy: 0.8444 - val_loss: 0.3696 - val_accuracy: 0.8448\n",
      "Epoch 34/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3672 - accuracy: 0.8447 - val_loss: 0.3728 - val_accuracy: 0.8443\n",
      "Epoch 35/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3671 - accuracy: 0.8447 - val_loss: 0.3685 - val_accuracy: 0.8431\n",
      "Epoch 36/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3670 - accuracy: 0.8448 - val_loss: 0.3706 - val_accuracy: 0.8418\n",
      "Epoch 37/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3670 - accuracy: 0.8449 - val_loss: 0.3705 - val_accuracy: 0.8430\n",
      "Epoch 38/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3669 - accuracy: 0.8447 - val_loss: 0.3694 - val_accuracy: 0.8449\n",
      "Epoch 39/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3669 - accuracy: 0.8449 - val_loss: 0.3690 - val_accuracy: 0.8437\n",
      "Epoch 40/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3667 - accuracy: 0.8447 - val_loss: 0.3685 - val_accuracy: 0.8447\n",
      "Epoch 41/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3667 - accuracy: 0.8447 - val_loss: 0.3720 - val_accuracy: 0.8450\n",
      "Epoch 42/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3666 - accuracy: 0.8450 - val_loss: 0.3686 - val_accuracy: 0.8445\n",
      "Epoch 43/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3665 - accuracy: 0.8447 - val_loss: 0.3688 - val_accuracy: 0.8432\n",
      "Epoch 44/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3665 - accuracy: 0.8451 - val_loss: 0.3695 - val_accuracy: 0.8445\n",
      "Epoch 45/100\n",
      "64092/64092 [==============================] - 207s 3ms/step - loss: 0.3664 - accuracy: 0.8450 - val_loss: 0.3693 - val_accuracy: 0.8436\n",
      "Epoch 46/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3663 - accuracy: 0.8451 - val_loss: 0.3687 - val_accuracy: 0.8429\n",
      "Epoch 47/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3663 - accuracy: 0.8452 - val_loss: 0.3770 - val_accuracy: 0.8380\n",
      "Epoch 48/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3661 - accuracy: 0.8452 - val_loss: 0.3834 - val_accuracy: 0.8413\n",
      "Epoch 49/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3660 - accuracy: 0.8451 - val_loss: 0.3721 - val_accuracy: 0.8412\n",
      "Epoch 50/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3660 - accuracy: 0.8452 - val_loss: 0.3676 - val_accuracy: 0.8453\n",
      "Epoch 51/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3658 - accuracy: 0.8451 - val_loss: 0.3670 - val_accuracy: 0.8450\n",
      "Epoch 52/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3655 - accuracy: 0.8452 - val_loss: 0.3713 - val_accuracy: 0.8449\n",
      "Epoch 53/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3653 - accuracy: 0.8453 - val_loss: 0.3700 - val_accuracy: 0.8449\n",
      "Epoch 54/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3654 - accuracy: 0.8453 - val_loss: 0.3673 - val_accuracy: 0.8448\n",
      "Epoch 55/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3650 - accuracy: 0.8452 - val_loss: 0.3693 - val_accuracy: 0.8422\n",
      "Epoch 56/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3651 - accuracy: 0.8453 - val_loss: 0.3709 - val_accuracy: 0.8428\n",
      "Epoch 57/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3651 - accuracy: 0.8455 - val_loss: 0.3695 - val_accuracy: 0.8444\n",
      "Epoch 58/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3649 - accuracy: 0.8456 - val_loss: 0.3679 - val_accuracy: 0.8452\n",
      "Epoch 59/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3649 - accuracy: 0.8455 - val_loss: 0.3668 - val_accuracy: 0.8453\n",
      "Epoch 60/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3649 - accuracy: 0.8454 - val_loss: 0.3729 - val_accuracy: 0.8398\n",
      "Epoch 61/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3649 - accuracy: 0.8455 - val_loss: 0.3705 - val_accuracy: 0.8450\n",
      "Epoch 62/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3648 - accuracy: 0.8455 - val_loss: 0.3674 - val_accuracy: 0.8454\n",
      "Epoch 63/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3647 - accuracy: 0.8458 - val_loss: 0.3707 - val_accuracy: 0.8455\n",
      "Epoch 64/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3646 - accuracy: 0.8456 - val_loss: 0.3686 - val_accuracy: 0.8447\n",
      "Epoch 65/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3645 - accuracy: 0.8457 - val_loss: 0.3694 - val_accuracy: 0.8449\n",
      "Epoch 66/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3645 - accuracy: 0.8457 - val_loss: 0.3666 - val_accuracy: 0.8451\n",
      "Epoch 67/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3645 - accuracy: 0.8456 - val_loss: 0.3671 - val_accuracy: 0.8459\n",
      "Epoch 68/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3645 - accuracy: 0.8456 - val_loss: 0.3669 - val_accuracy: 0.8456\n",
      "Epoch 69/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3644 - accuracy: 0.8457 - val_loss: 0.3662 - val_accuracy: 0.8451\n",
      "Epoch 70/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3644 - accuracy: 0.8457 - val_loss: 0.3690 - val_accuracy: 0.8425\n",
      "Epoch 71/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3643 - accuracy: 0.8457 - val_loss: 0.3704 - val_accuracy: 0.8414\n",
      "Epoch 72/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3643 - accuracy: 0.8457 - val_loss: 0.3671 - val_accuracy: 0.8444\n",
      "Epoch 73/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3643 - accuracy: 0.8457 - val_loss: 0.3656 - val_accuracy: 0.8457\n",
      "Epoch 74/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3644 - accuracy: 0.8457 - val_loss: 0.3667 - val_accuracy: 0.8441\n",
      "Epoch 75/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3642 - accuracy: 0.8457 - val_loss: 0.3672 - val_accuracy: 0.8447\n",
      "Epoch 76/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3642 - accuracy: 0.8457 - val_loss: 0.3671 - val_accuracy: 0.8441\n",
      "Epoch 77/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3643 - accuracy: 0.8458 - val_loss: 0.3664 - val_accuracy: 0.8456\n",
      "Epoch 78/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3642 - accuracy: 0.8460 - val_loss: 0.3782 - val_accuracy: 0.8429\n",
      "Epoch 79/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3641 - accuracy: 0.8459 - val_loss: 0.3667 - val_accuracy: 0.8445\n",
      "Epoch 80/100\n",
      "64092/64092 [==============================] - 205s 3ms/step - loss: 0.3642 - accuracy: 0.8459 - val_loss: 0.3718 - val_accuracy: 0.8448\n",
      "Epoch 81/100\n",
      "64092/64092 [==============================] - 206s 3ms/step - loss: 0.3641 - accuracy: 0.8460 - val_loss: 0.3683 - val_accuracy: 0.8449\n",
      "Epoch 82/100\n",
      "64092/64092 [==============================] - 204s 3ms/step - loss: 0.3641 - accuracy: 0.8458 - val_loss: 0.3672 - val_accuracy: 0.8451\n",
      "Epoch 83/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3640 - accuracy: 0.8459 - val_loss: 0.3677 - val_accuracy: 0.8445\n",
      "Epoch 84/100\n",
      "64092/64092 [==============================] - 203s 3ms/step - loss: 0.3641 - accuracy: 0.8459 - val_loss: 0.3682 - val_accuracy: 0.8452\n",
      "Epoch 85/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3640 - accuracy: 0.8458 - val_loss: 0.3670 - val_accuracy: 0.8452\n",
      "Epoch 86/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3640 - accuracy: 0.8459 - val_loss: 0.3654 - val_accuracy: 0.8449\n",
      "Epoch 87/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3640 - accuracy: 0.8460 - val_loss: 0.3672 - val_accuracy: 0.8441\n",
      "Epoch 88/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3639 - accuracy: 0.8460 - val_loss: 0.3668 - val_accuracy: 0.8442\n",
      "Epoch 89/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3640 - accuracy: 0.8459 - val_loss: 0.3681 - val_accuracy: 0.8445\n",
      "Epoch 90/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3638 - accuracy: 0.8459 - val_loss: 0.3662 - val_accuracy: 0.8445\n",
      "Epoch 91/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3638 - accuracy: 0.8459 - val_loss: 0.3667 - val_accuracy: 0.8456\n",
      "Epoch 92/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3638 - accuracy: 0.8459 - val_loss: 0.3669 - val_accuracy: 0.8446\n",
      "Epoch 93/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3639 - accuracy: 0.8461 - val_loss: 0.3664 - val_accuracy: 0.8452\n",
      "Epoch 94/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3638 - accuracy: 0.8460 - val_loss: 0.3675 - val_accuracy: 0.8441\n",
      "Epoch 95/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3638 - accuracy: 0.8460 - val_loss: 0.3676 - val_accuracy: 0.8453\n",
      "Epoch 96/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3638 - accuracy: 0.8459 - val_loss: 0.3686 - val_accuracy: 0.8425\n",
      "Epoch 97/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3637 - accuracy: 0.8462 - val_loss: 0.3707 - val_accuracy: 0.8453\n",
      "Epoch 98/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3635 - accuracy: 0.8462 - val_loss: 0.3765 - val_accuracy: 0.8438\n",
      "Epoch 99/100\n",
      "64092/64092 [==============================] - 201s 3ms/step - loss: 0.3637 - accuracy: 0.8461 - val_loss: 0.3671 - val_accuracy: 0.8433\n",
      "Epoch 100/100\n",
      "64092/64092 [==============================] - 202s 3ms/step - loss: 0.3637 - accuracy: 0.8462 - val_loss: 0.3684 - val_accuracy: 0.8431\n",
      "time taken for training :  21116.61230492592\n",
      "time taken for per epoch :  211.1661230492592\n"
     ]
    }
   ],
   "source": [
    "for split_no in range(1,11,1):\n",
    "    test_file_no = split_no\n",
    "    print(\"\\n\\n\\n Test file no : \",test_file_no)\n",
    "    #creating training and testing dataset\n",
    "    train_df = pd.DataFrame()\n",
    "    #test_df = pd.DataFrame()\n",
    "    for i in range(1,11,1):\n",
    "        if i != test_file_no:\n",
    "            df = pd.read_csv(dir_path+\"/WSJ_positive_edges_split_\"+str(i)+\".csv\") \n",
    "            train_df = train_df.append(df, ignore_index=True)\n",
    "            del df\n",
    "        else:\n",
    "            test_df = pd.read_csv(dir_path+\"/WSJ_positive_edges_split_\"+str(i)+\".csv\")\n",
    "            neg_df = pd.read_csv(dir_path+\"/WSJ_negative_edges_split_\"+str(i)+\".csv\")\n",
    "            test_df = test_df.append(neg_df, ignore_index=True)\n",
    "            del neg_df\n",
    "            \n",
    "    train_df = train_df.drop(['layer', 'weight',\"sign\"], axis=1)\n",
    "    #test_df = test_df.drop(['layer', 'weight',\"sign\"], axis=1)\n",
    "    \n",
    "    #making node_id variables continuous\n",
    "    train_df['src'] = [temp_node_no[i] for i in train_df['src']]\n",
    "    train_df['dest'] = [temp_node_no[i] for i in train_df['dest']]\n",
    "    test_df['src'] = [temp_node_no[i] for i in test_df['src']]\n",
    "    test_df['dest'] = [temp_node_no[i] for i in test_df['dest']]\n",
    "    \n",
    "    print(\"Dataset has been successfully prepared\")\n",
    "    # creating training graph\n",
    "    edge_list = [(train_df['src'][i],train_df['dest'][i]) for i in train_df.index]\n",
    "    G = nx.MultiGraph()\n",
    "    G.add_edges_from(edge_list)\n",
    "    \n",
    "    curr = time.time()\n",
    "    #training n2v node embedding model\n",
    "    g_emb = n2v(G, dimensions=64)\n",
    "\n",
    "    WINDOW = 1 # Node2Vec fit window\n",
    "    MIN_COUNT = 1 # Node2Vec min. count\n",
    "    BATCH_WORDS = 4 # Node2Vec batch words\n",
    "\n",
    "    mdl = g_emb.fit(\n",
    "        window=WINDOW,\n",
    "        min_count=MIN_COUNT,\n",
    "        batch_words=BATCH_WORDS\n",
    "    )\n",
    "    \n",
    "    timetaken = time.time()-curr\n",
    "    print(\"time taken for training node embedding model : \",timetaken)\n",
    "    mdl.save(\"my_\"+str(dbname)+\"_N2V_node_embedding_model_\"+str(test_file_no)+\".model\")\n",
    "    #adding negative edges to train_df\n",
    "    train_df = pd.DataFrame()\n",
    "    for i in range(1,11,1):\n",
    "        if i != test_file_no:\n",
    "            df = pd.read_csv(dir_path+\"/WSJ_positive_edges_split_\"+str(i)+\".csv\") \n",
    "            train_df = train_df.append(df, ignore_index=True)\n",
    "            df = pd.read_csv(dir_path+\"/WSJ_negative_edges_split_\"+str(i)+\".csv\")\n",
    "            train_df = train_df.append(df, ignore_index=True)\n",
    "            del df\n",
    "    train_df = train_df.drop(['layer', 'weight',\"sign\"], axis=1)\n",
    "    train_df['src'] = [temp_node_no[i] for i in train_df['src']]\n",
    "    train_df['dest'] = [temp_node_no[i] for i in train_df['dest']]\n",
    "    train_df.loc[train_df['label'] == -1, \"label\"] = 0\n",
    "    train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "    print(train_df.head)\n",
    "    # creating x_train\n",
    "    X_train = [(mdl.wv.get_vector(train_df['src'][i]) + mdl.wv.get_vector(train_df['dest'][i])) for i in train_df.index]\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(train_df['label'])\n",
    "    del train_df\n",
    "    \n",
    "    # creating x_test\n",
    "    #test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "    #X_test = [(mdl.wv.get_vector(test_df['src'][i]) + mdl.wv.get_vector(test_df['dest'][i])) for i in test_df.index]\n",
    "    #pickle.dump(X_test,open(\"n2v_\"+str(dbname)+\"_X_test_whole_\"+str(test_file_no)+\".csv\",\"wb\"))\n",
    "    #X_test = np.array(X_test)\n",
    "    #y_test = list(test_df['label'])\n",
    "    del test_df\n",
    "    \n",
    "    print(\"x_train and x_test are ready\")\n",
    "    # creating keras model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu')) # Add an input shape! (features,)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    curr = time.time()\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, validation_split=0.10, epochs=epochs, batch_size=16,verbose=1)\n",
    "\n",
    "    timetaken = time.time()-curr\n",
    "    print(\"time taken for training : \",timetaken)\n",
    "    print(\"time taken for per epoch : \",timetaken/epochs)\n",
    "    \n",
    "    model.save(\"my_\"+str(dbname)+\"_N2V_model_\"+str(test_file_no)+\".keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55acedc1",
   "metadata": {},
   "source": [
    "# rough draft of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a25793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"WSJ split data files\"\n",
    "test_file_no = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39063e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ae5d777dec2f>:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  test_df = test_df.append(neg_df, ignore_index=True)\n",
      "<ipython-input-5-ae5d777dec2f>:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-5-ae5d777dec2f>:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-5-ae5d777dec2f>:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-5-ae5d777dec2f>:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-5-ae5d777dec2f>:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-5-ae5d777dec2f>:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-5-ae5d777dec2f>:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-5-ae5d777dec2f>:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-5-ae5d777dec2f>:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dest</th>\n",
       "      <th>layer</th>\n",
       "      <th>weight</th>\n",
       "      <th>sign</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5046</td>\n",
       "      <td>8395</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100036</td>\n",
       "      <td>103501</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100670</td>\n",
       "      <td>102593</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>870</td>\n",
       "      <td>5764</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5036</td>\n",
       "      <td>6048</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569695</th>\n",
       "      <td>100442</td>\n",
       "      <td>100451</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569696</th>\n",
       "      <td>5338</td>\n",
       "      <td>8134</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569697</th>\n",
       "      <td>100075</td>\n",
       "      <td>100086</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569698</th>\n",
       "      <td>5082</td>\n",
       "      <td>5400</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569699</th>\n",
       "      <td>101385</td>\n",
       "      <td>103235</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569700 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           src    dest  layer  weight  sign  label\n",
       "0         5046    8395     12       2  -2.0      1\n",
       "1       100036  103501      3      27  -2.0      1\n",
       "2       100670  102593      3       2  -2.0      1\n",
       "3          870    5764      2      33  -1.0      1\n",
       "4         5036    6048     12       7  -2.0      1\n",
       "...        ...     ...    ...     ...   ...    ...\n",
       "569695  100442  100451      3       4  -2.0      1\n",
       "569696    5338    8134     12       3  -2.0      1\n",
       "569697  100075  100086      3       5  -2.0      1\n",
       "569698    5082    5400     12       2  -2.0      1\n",
       "569699  101385  103235      3       3  -2.0      1\n",
       "\n",
       "[569700 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "for i in range(1,11,1):\n",
    "    if i != test_file_no:\n",
    "        df = pd.read_csv(dir_path+\"/WSJ_positive_edges_split_\"+str(i)+\".csv\") \n",
    "        train_df = train_df.append(df, ignore_index=True)\n",
    "        del df\n",
    "    else:\n",
    "        test_df = pd.read_csv(dir_path+\"/WSJ_positive_edges_split_\"+str(i)+\".csv\")\n",
    "        neg_df = pd.read_csv(dir_path+\"/WSJ_negative_edges_split_\"+str(i)+\".csv\")\n",
    "        test_df = test_df.append(neg_df, ignore_index=True)\n",
    "        del neg_df\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cbf13e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['layer', 'weight',\"sign\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0c6490c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dest</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100329</td>\n",
       "      <td>101979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100746</td>\n",
       "      <td>100788</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5024</td>\n",
       "      <td>8029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100405</td>\n",
       "      <td>103390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100205</td>\n",
       "      <td>100259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      src    dest  label\n",
       "0  100329  101979      1\n",
       "1  100746  100788      1\n",
       "2    5024    8029      1\n",
       "3  100405  103390      1\n",
       "4  100205  100259      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = test_df.drop(['layer', 'weight',\"sign\"], axis=1)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "873a40b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique nodes found till train_df:  8536\n"
     ]
    }
   ],
   "source": [
    "# converting nodes to continuous variable\n",
    "temp_node_no = {}\n",
    "id = 0\n",
    "for i in np.unique(train_df[['src', 'dest']].values):\n",
    "    temp_node_no[i] = id\n",
    "    id += 1\n",
    "print(\"total unique nodes found till train_df: \",id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "738e3328",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['src'] = [temp_node_no[i] for i in train_df['src']]\n",
    "train_df['dest'] = [temp_node_no[i] for i in train_df['dest']]\n",
    "test_df['src'] = [temp_node_no[i] for i in test_df['src']]\n",
    "test_df['dest'] = [temp_node_no[i] for i in test_df['dest']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cf69833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating training graph\n",
    "edge_list = [(train_df['src'][i],train_df['dest'][i]) for i in train_df.index]\n",
    "G = nx.MultiGraph()\n",
    "G.add_edges_from(edge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c8c07fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29514bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a10390c7901478eac8baa4fdcac291b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/8536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [06:35<00:00, 39.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6   \\\n",
      "74    0.066213 -0.087268 -0.160592  0.561564 -0.053954  0.517867  1.757313   \n",
      "3423 -0.756973 -0.708204 -0.233035  0.840388  0.914142 -0.429827  1.208549   \n",
      "4921 -0.090328 -0.784583  0.783312  0.461973  0.655650 -0.031383  0.340182   \n",
      "8386 -0.102974 -0.580768 -0.139828  1.530549 -0.714675  0.597381  0.192185   \n",
      "5555  0.756856 -1.469142  0.481359  0.932975  0.577899  0.809864  1.089535   \n",
      "\n",
      "            7         8         9         10        11        12        13  \\\n",
      "74    0.057634  0.470260 -0.801055 -0.672506 -0.564250 -0.413633 -0.110114   \n",
      "3423 -1.844603  0.637675  0.623564 -0.494655  0.312868  0.391652 -0.275188   \n",
      "4921  0.009983 -0.715256 -0.478891 -0.807956  0.320143 -0.184014 -0.465778   \n",
      "8386 -2.274364 -0.173700  0.053018 -2.846182  0.484979  1.219140 -1.585759   \n",
      "5555 -0.271014 -1.360325  0.463972  0.147455 -0.262793  1.564479 -0.049630   \n",
      "\n",
      "            14        15  \n",
      "74   -0.373733 -1.602690  \n",
      "3423 -0.476330 -0.606898  \n",
      "4921  0.356695  0.117681  \n",
      "8386 -0.361186  0.630669  \n",
      "5555  0.229272  0.351356  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "g_emb = n2v(G, dimensions=16)\n",
    "\n",
    "WINDOW = 1 # Node2Vec fit window\n",
    "MIN_COUNT = 1 # Node2Vec min. count\n",
    "BATCH_WORDS = 4 # Node2Vec batch words\n",
    "\n",
    "mdl = g_emb.fit(\n",
    "    window=WINDOW,\n",
    "    min_count=MIN_COUNT,\n",
    "    batch_words=BATCH_WORDS\n",
    ")\n",
    "\n",
    "# create embeddings dataframe\n",
    "emb_df = (\n",
    "    pd.DataFrame(\n",
    "        [mdl.wv.get_vector(str(n)) for n in G.nodes()],\n",
    "        index = G.nodes\n",
    "    )\n",
    ")\n",
    "\n",
    "print(emb_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867f3a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "3:27-3:31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1a98af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( mdl, open( \"mdl_1.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4161f224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df['src'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e634dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "del emb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ef07a1",
   "metadata": {},
   "source": [
    "# final code for creating training and testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98194f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.26640213, -0.61832184,  0.8166052 ,  0.4864245 ,  0.6819291 ,\n",
       "        0.7843016 ,  0.61891556,  0.5080065 , -0.8787431 ,  0.0074712 ,\n",
       "       -0.15300506, -0.2796761 , -0.12839389, -0.27083758, -0.18696621,\n",
       "        0.35777766], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.wv.get_vector(74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58362662",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-46-1a7f55301f01>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-46-1a7f55301f01>:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-46-1a7f55301f01>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-46-1a7f55301f01>:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-46-1a7f55301f01>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-46-1a7f55301f01>:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-46-1a7f55301f01>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-46-1a7f55301f01>:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-46-1a7f55301f01>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-46-1a7f55301f01>:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-46-1a7f55301f01>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-46-1a7f55301f01>:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-46-1a7f55301f01>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-46-1a7f55301f01>:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-46-1a7f55301f01>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-46-1a7f55301f01>:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-46-1a7f55301f01>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n",
      "<ipython-input-46-1a7f55301f01>:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame()\n",
    "test_file_no = 1\n",
    "dir_path = \"WSJ split data files\"\n",
    "for i in range(1,11,1):\n",
    "    if i != test_file_no:\n",
    "        df = pd.read_csv(dir_path+\"/WSJ_positive_edges_split_\"+str(i)+\".csv\") \n",
    "        train_df = train_df.append(df, ignore_index=True)\n",
    "        df = pd.read_csv(dir_path+\"/WSJ_negative_edges_split_\"+str(i)+\".csv\")\n",
    "        train_df = train_df.append(df, ignore_index=True)\n",
    "        del df\n",
    "train_df = train_df.drop(['layer', 'weight',\"sign\"], axis=1)\n",
    "train_df['src'] = [temp_node_no[i] for i in train_df['src']]\n",
    "train_df['dest'] = [temp_node_no[i] for i in train_df['dest']]\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# creating x_train\n",
    "X_train = [(mdl.wv.get_vector(train_df['src'][i]) + mdl.wv.get_vector(train_df['dest'][i])) for i in train_df.index]\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(train_df['label'])\n",
    "\n",
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c75bbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# creating x_train\n",
    "X_test = [(mdl.wv.get_vector(test_df['src'][i]) + mdl.wv.get_vector(test_df['dest'][i])) for i in test_df.index]\n",
    "X_test = np.array(X_test)\n",
    "y_test = list(test_df['label'])\n",
    "\n",
    "del test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7eaeee5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56970.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)*0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "056ea370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56970, 16)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = X_train[0:56970]\n",
    "y_val = y_train[0:56970]\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f829e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[56970:]\n",
    "y_train = y_train[56970:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3fcd2f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1139400, 16)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "262ce02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16023/16023 - 16s - loss: -3.0435e+05 - accuracy: 0.0274 - val_loss: -1.0635e+06 - val_accuracy: 0.0257 - 16s/epoch - 976us/step\n",
      "Epoch 2/100\n",
      "16023/16023 - 14s - loss: -3.2776e+06 - accuracy: 0.0261 - val_loss: -6.4844e+06 - val_accuracy: 0.0269 - 14s/epoch - 845us/step\n",
      "Epoch 3/100\n",
      "16023/16023 - 14s - loss: -1.2235e+07 - accuracy: 0.0261 - val_loss: -1.9426e+07 - val_accuracy: 0.0258 - 14s/epoch - 865us/step\n",
      "Epoch 4/100\n",
      "16023/16023 - 15s - loss: -3.0173e+07 - accuracy: 0.0257 - val_loss: -4.2837e+07 - val_accuracy: 0.0253 - 15s/epoch - 947us/step\n",
      "Epoch 5/100\n",
      "16023/16023 - 17s - loss: -6.0158e+07 - accuracy: 0.0255 - val_loss: -7.9737e+07 - val_accuracy: 0.0252 - 17s/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "16023/16023 - 18s - loss: -1.0520e+08 - accuracy: 0.0254 - val_loss: -1.3318e+08 - val_accuracy: 0.0246 - 18s/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "16023/16023 - 16s - loss: -1.6821e+08 - accuracy: 0.0251 - val_loss: -2.0602e+08 - val_accuracy: 0.0249 - 16s/epoch - 970us/step\n",
      "Epoch 8/100\n",
      "16023/16023 - 16s - loss: -2.5249e+08 - accuracy: 0.0252 - val_loss: -3.0165e+08 - val_accuracy: 0.0246 - 16s/epoch - 977us/step\n",
      "Epoch 9/100\n",
      "16023/16023 - 17s - loss: -3.6084e+08 - accuracy: 0.0253 - val_loss: -4.2279e+08 - val_accuracy: 0.0239 - 17s/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "16023/16023 - 15s - loss: -4.9594e+08 - accuracy: 0.0248 - val_loss: -5.7204e+08 - val_accuracy: 0.0241 - 15s/epoch - 907us/step\n",
      "Epoch 11/100\n",
      "16023/16023 - 15s - loss: -6.6127e+08 - accuracy: 0.0248 - val_loss: -7.5303e+08 - val_accuracy: 0.0242 - 15s/epoch - 936us/step\n",
      "Epoch 12/100\n",
      "16023/16023 - 15s - loss: -8.5958e+08 - accuracy: 0.0251 - val_loss: -9.6825e+08 - val_accuracy: 0.0239 - 15s/epoch - 951us/step\n",
      "Epoch 13/100\n",
      "16023/16023 - 15s - loss: -1.0933e+09 - accuracy: 0.0248 - val_loss: -1.2206e+09 - val_accuracy: 0.0242 - 15s/epoch - 911us/step\n",
      "Epoch 14/100\n",
      "16023/16023 - 15s - loss: -1.3666e+09 - accuracy: 0.0249 - val_loss: -1.5135e+09 - val_accuracy: 0.0240 - 15s/epoch - 918us/step\n",
      "Epoch 15/100\n",
      "16023/16023 - 14s - loss: -1.6816e+09 - accuracy: 0.0249 - val_loss: -1.8496e+09 - val_accuracy: 0.0238 - 14s/epoch - 875us/step\n",
      "Epoch 16/100\n",
      "16023/16023 - 15s - loss: -2.0408e+09 - accuracy: 0.0247 - val_loss: -2.2311e+09 - val_accuracy: 0.0239 - 15s/epoch - 922us/step\n",
      "Epoch 17/100\n",
      "16023/16023 - 14s - loss: -2.4473e+09 - accuracy: 0.0247 - val_loss: -2.6617e+09 - val_accuracy: 0.0240 - 14s/epoch - 877us/step\n",
      "Epoch 18/100\n",
      "16023/16023 - 14s - loss: -2.9051e+09 - accuracy: 0.0247 - val_loss: -3.1454e+09 - val_accuracy: 0.0239 - 14s/epoch - 878us/step\n",
      "Epoch 19/100\n",
      "16023/16023 - 16s - loss: -3.4171e+09 - accuracy: 0.0247 - val_loss: -3.6834e+09 - val_accuracy: 0.0237 - 16s/epoch - 985us/step\n",
      "Epoch 20/100\n",
      "16023/16023 - 14s - loss: -3.9858e+09 - accuracy: 0.0246 - val_loss: -4.2797e+09 - val_accuracy: 0.0237 - 14s/epoch - 877us/step\n",
      "Epoch 21/100\n",
      "16023/16023 - 15s - loss: -4.6129e+09 - accuracy: 0.0246 - val_loss: -4.9356e+09 - val_accuracy: 0.0238 - 15s/epoch - 916us/step\n",
      "Epoch 22/100\n",
      "16023/16023 - 14s - loss: -5.3023e+09 - accuracy: 0.0245 - val_loss: -5.6574e+09 - val_accuracy: 0.0237 - 14s/epoch - 892us/step\n",
      "Epoch 23/100\n",
      "16023/16023 - 14s - loss: -6.0579e+09 - accuracy: 0.0245 - val_loss: -6.4431e+09 - val_accuracy: 0.0237 - 14s/epoch - 902us/step\n",
      "Epoch 24/100\n",
      "16023/16023 - 14s - loss: -6.8797e+09 - accuracy: 0.0244 - val_loss: -7.2990e+09 - val_accuracy: 0.0238 - 14s/epoch - 878us/step\n",
      "Epoch 25/100\n",
      "16023/16023 - 15s - loss: -7.7745e+09 - accuracy: 0.0245 - val_loss: -8.2277e+09 - val_accuracy: 0.0237 - 15s/epoch - 922us/step\n",
      "Epoch 26/100\n",
      "16023/16023 - 14s - loss: -8.7415e+09 - accuracy: 0.0244 - val_loss: -9.2322e+09 - val_accuracy: 0.0237 - 14s/epoch - 895us/step\n",
      "Epoch 27/100\n",
      "16023/16023 - 14s - loss: -9.7879e+09 - accuracy: 0.0245 - val_loss: -1.0314e+10 - val_accuracy: 0.0237 - 14s/epoch - 892us/step\n",
      "Epoch 28/100\n",
      "16023/16023 - 14s - loss: -1.0911e+10 - accuracy: 0.0245 - val_loss: -1.1476e+10 - val_accuracy: 0.0237 - 14s/epoch - 879us/step\n",
      "Epoch 29/100\n",
      "16023/16023 - 15s - loss: -1.2121e+10 - accuracy: 0.0245 - val_loss: -1.2725e+10 - val_accuracy: 0.0236 - 15s/epoch - 906us/step\n",
      "Epoch 30/100\n",
      "16023/16023 - 14s - loss: -1.3415e+10 - accuracy: 0.0244 - val_loss: -1.4060e+10 - val_accuracy: 0.0236 - 14s/epoch - 853us/step\n",
      "Epoch 31/100\n",
      "16023/16023 - 14s - loss: -1.4796e+10 - accuracy: 0.0244 - val_loss: -1.5484e+10 - val_accuracy: 0.0237 - 14s/epoch - 881us/step\n",
      "Epoch 32/100\n",
      "16023/16023 - 17s - loss: -1.6272e+10 - accuracy: 0.0244 - val_loss: -1.7006e+10 - val_accuracy: 0.0237 - 17s/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "16023/16023 - 18s - loss: -1.7845e+10 - accuracy: 0.0245 - val_loss: -1.8623e+10 - val_accuracy: 0.0236 - 18s/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "16023/16023 - 16s - loss: -1.9517e+10 - accuracy: 0.0244 - val_loss: -2.0338e+10 - val_accuracy: 0.0236 - 16s/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "16023/16023 - 16s - loss: -2.1285e+10 - accuracy: 0.0244 - val_loss: -2.2153e+10 - val_accuracy: 0.0236 - 16s/epoch - 1ms/step\n",
      "Epoch 36/100\n",
      "16023/16023 - 15s - loss: -2.3157e+10 - accuracy: 0.0244 - val_loss: -2.4076e+10 - val_accuracy: 0.0236 - 15s/epoch - 912us/step\n",
      "Epoch 37/100\n",
      "16023/16023 - 14s - loss: -2.5137e+10 - accuracy: 0.0244 - val_loss: -2.6106e+10 - val_accuracy: 0.0235 - 14s/epoch - 881us/step\n",
      "Epoch 38/100\n",
      "16023/16023 - 16s - loss: -2.7226e+10 - accuracy: 0.0243 - val_loss: -2.8244e+10 - val_accuracy: 0.0236 - 16s/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "16023/16023 - 15s - loss: -2.9427e+10 - accuracy: 0.0244 - val_loss: -3.0497e+10 - val_accuracy: 0.0235 - 15s/epoch - 950us/step\n",
      "Epoch 40/100\n",
      "16023/16023 - 15s - loss: -3.1742e+10 - accuracy: 0.0243 - val_loss: -3.2868e+10 - val_accuracy: 0.0236 - 15s/epoch - 935us/step\n",
      "Epoch 41/100\n",
      "16023/16023 - 15s - loss: -3.4177e+10 - accuracy: 0.0244 - val_loss: -3.5357e+10 - val_accuracy: 0.0235 - 15s/epoch - 942us/step\n",
      "Epoch 42/100\n",
      "16023/16023 - 15s - loss: -3.6736e+10 - accuracy: 0.0244 - val_loss: -3.7972e+10 - val_accuracy: 0.0234 - 15s/epoch - 922us/step\n",
      "Epoch 43/100\n",
      "16023/16023 - 15s - loss: -3.9415e+10 - accuracy: 0.0243 - val_loss: -4.0713e+10 - val_accuracy: 0.0235 - 15s/epoch - 951us/step\n",
      "Epoch 44/100\n",
      "16023/16023 - 14s - loss: -4.2226e+10 - accuracy: 0.0243 - val_loss: -4.3578e+10 - val_accuracy: 0.0235 - 14s/epoch - 900us/step\n",
      "Epoch 45/100\n",
      "16023/16023 - 14s - loss: -4.5171e+10 - accuracy: 0.0243 - val_loss: -4.6576e+10 - val_accuracy: 0.0234 - 14s/epoch - 887us/step\n",
      "Epoch 46/100\n",
      "16023/16023 - 16s - loss: -4.8236e+10 - accuracy: 0.0243 - val_loss: -4.9708e+10 - val_accuracy: 0.0234 - 16s/epoch - 981us/step\n",
      "Epoch 47/100\n",
      "16023/16023 - 16s - loss: -5.1441e+10 - accuracy: 0.0243 - val_loss: -5.2969e+10 - val_accuracy: 0.0234 - 16s/epoch - 993us/step\n",
      "Epoch 48/100\n",
      "16023/16023 - 15s - loss: -5.4786e+10 - accuracy: 0.0243 - val_loss: -5.6382e+10 - val_accuracy: 0.0234 - 15s/epoch - 937us/step\n",
      "Epoch 49/100\n",
      "16023/16023 - 16s - loss: -5.8275e+10 - accuracy: 0.0243 - val_loss: -5.9929e+10 - val_accuracy: 0.0234 - 16s/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "16023/16023 - 17s - loss: -6.1901e+10 - accuracy: 0.0242 - val_loss: -6.3626e+10 - val_accuracy: 0.0234 - 17s/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "16023/16023 - 15s - loss: -6.5679e+10 - accuracy: 0.0242 - val_loss: -6.7470e+10 - val_accuracy: 0.0234 - 15s/epoch - 931us/step\n",
      "Epoch 52/100\n",
      "16023/16023 - 15s - loss: -6.9607e+10 - accuracy: 0.0242 - val_loss: -7.1466e+10 - val_accuracy: 0.0234 - 15s/epoch - 936us/step\n",
      "Epoch 53/100\n",
      "16023/16023 - 14s - loss: -7.3691e+10 - accuracy: 0.0243 - val_loss: -7.5614e+10 - val_accuracy: 0.0234 - 14s/epoch - 874us/step\n",
      "Epoch 54/100\n",
      "16023/16023 - 15s - loss: -7.7933e+10 - accuracy: 0.0243 - val_loss: -7.9925e+10 - val_accuracy: 0.0235 - 15s/epoch - 921us/step\n",
      "Epoch 55/100\n",
      "16023/16023 - 15s - loss: -8.2329e+10 - accuracy: 0.0243 - val_loss: -8.4399e+10 - val_accuracy: 0.0234 - 15s/epoch - 913us/step\n",
      "Epoch 56/100\n",
      "16023/16023 - 15s - loss: -8.6896e+10 - accuracy: 0.0242 - val_loss: -8.9031e+10 - val_accuracy: 0.0234 - 15s/epoch - 934us/step\n",
      "Epoch 57/100\n",
      "16023/16023 - 15s - loss: -9.1616e+10 - accuracy: 0.0243 - val_loss: -9.3820e+10 - val_accuracy: 0.0234 - 15s/epoch - 913us/step\n",
      "Epoch 58/100\n",
      "16023/16023 - 16s - loss: -9.6498e+10 - accuracy: 0.0242 - val_loss: -9.8787e+10 - val_accuracy: 0.0234 - 16s/epoch - 975us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "16023/16023 - 15s - loss: -1.0157e+11 - accuracy: 0.0242 - val_loss: -1.0393e+11 - val_accuracy: 0.0234 - 15s/epoch - 936us/step\n",
      "Epoch 60/100\n",
      "16023/16023 - 16s - loss: -1.0680e+11 - accuracy: 0.0242 - val_loss: -1.0924e+11 - val_accuracy: 0.0234 - 16s/epoch - 977us/step\n",
      "Epoch 61/100\n",
      "16023/16023 - 14s - loss: -1.1223e+11 - accuracy: 0.0242 - val_loss: -1.1475e+11 - val_accuracy: 0.0234 - 14s/epoch - 896us/step\n",
      "Epoch 62/100\n",
      "16023/16023 - 16s - loss: -1.1783e+11 - accuracy: 0.0242 - val_loss: -1.2042e+11 - val_accuracy: 0.0234 - 16s/epoch - 981us/step\n",
      "Epoch 63/100\n",
      "16023/16023 - 16s - loss: -1.2361e+11 - accuracy: 0.0242 - val_loss: -1.2628e+11 - val_accuracy: 0.0234 - 16s/epoch - 974us/step\n",
      "Epoch 64/100\n",
      "16023/16023 - 15s - loss: -1.2958e+11 - accuracy: 0.0242 - val_loss: -1.3233e+11 - val_accuracy: 0.0234 - 15s/epoch - 912us/step\n",
      "Epoch 65/100\n",
      "16023/16023 - 15s - loss: -1.3573e+11 - accuracy: 0.0242 - val_loss: -1.3857e+11 - val_accuracy: 0.0234 - 15s/epoch - 924us/step\n",
      "Epoch 66/100\n",
      "16023/16023 - 14s - loss: -1.4209e+11 - accuracy: 0.0242 - val_loss: -1.4501e+11 - val_accuracy: 0.0233 - 14s/epoch - 880us/step\n",
      "Epoch 67/100\n",
      "16023/16023 - 14s - loss: -1.4863e+11 - accuracy: 0.0242 - val_loss: -1.5163e+11 - val_accuracy: 0.0233 - 14s/epoch - 880us/step\n",
      "Epoch 68/100\n",
      "16023/16023 - 15s - loss: -1.5537e+11 - accuracy: 0.0242 - val_loss: -1.5844e+11 - val_accuracy: 0.0233 - 15s/epoch - 935us/step\n",
      "Epoch 69/100\n",
      "16023/16023 - 15s - loss: -1.6231e+11 - accuracy: 0.0241 - val_loss: -1.6548e+11 - val_accuracy: 0.0233 - 15s/epoch - 958us/step\n",
      "Epoch 70/100\n",
      "16023/16023 - 14s - loss: -1.6946e+11 - accuracy: 0.0242 - val_loss: -1.7271e+11 - val_accuracy: 0.0233 - 14s/epoch - 889us/step\n",
      "Epoch 71/100\n",
      "16023/16023 - 14s - loss: -1.7681e+11 - accuracy: 0.0241 - val_loss: -1.8015e+11 - val_accuracy: 0.0233 - 14s/epoch - 879us/step\n",
      "Epoch 72/100\n",
      "16023/16023 - 15s - loss: -1.8435e+11 - accuracy: 0.0241 - val_loss: -1.8778e+11 - val_accuracy: 0.0233 - 15s/epoch - 960us/step\n",
      "Epoch 73/100\n",
      "16023/16023 - 14s - loss: -1.9212e+11 - accuracy: 0.0241 - val_loss: -1.9565e+11 - val_accuracy: 0.0233 - 14s/epoch - 900us/step\n",
      "Epoch 74/100\n",
      "16023/16023 - 15s - loss: -2.0011e+11 - accuracy: 0.0241 - val_loss: -2.0373e+11 - val_accuracy: 0.0233 - 15s/epoch - 918us/step\n",
      "Epoch 75/100\n",
      "16023/16023 - 14s - loss: -2.0833e+11 - accuracy: 0.0241 - val_loss: -2.1203e+11 - val_accuracy: 0.0233 - 14s/epoch - 859us/step\n",
      "Epoch 76/100\n",
      "16023/16023 - 15s - loss: -2.1676e+11 - accuracy: 0.0241 - val_loss: -2.2056e+11 - val_accuracy: 0.0233 - 15s/epoch - 917us/step\n",
      "Epoch 77/100\n",
      "16023/16023 - 14s - loss: -2.2541e+11 - accuracy: 0.0241 - val_loss: -2.2930e+11 - val_accuracy: 0.0233 - 14s/epoch - 894us/step\n",
      "Epoch 78/100\n",
      "16023/16023 - 14s - loss: -2.3429e+11 - accuracy: 0.0241 - val_loss: -2.3829e+11 - val_accuracy: 0.0233 - 14s/epoch - 884us/step\n",
      "Epoch 79/100\n",
      "16023/16023 - 14s - loss: -2.4341e+11 - accuracy: 0.0241 - val_loss: -2.4749e+11 - val_accuracy: 0.0233 - 14s/epoch - 899us/step\n",
      "Epoch 80/100\n",
      "16023/16023 - 14s - loss: -2.5275e+11 - accuracy: 0.0241 - val_loss: -2.5692e+11 - val_accuracy: 0.0233 - 14s/epoch - 867us/step\n",
      "Epoch 81/100\n",
      "16023/16023 - 14s - loss: -2.6232e+11 - accuracy: 0.0242 - val_loss: -2.6660e+11 - val_accuracy: 0.0233 - 14s/epoch - 864us/step\n",
      "Epoch 82/100\n",
      "16023/16023 - 14s - loss: -2.7214e+11 - accuracy: 0.0241 - val_loss: -2.7650e+11 - val_accuracy: 0.0233 - 14s/epoch - 892us/step\n",
      "Epoch 83/100\n",
      "16023/16023 - 15s - loss: -2.8218e+11 - accuracy: 0.0241 - val_loss: -2.8665e+11 - val_accuracy: 0.0233 - 15s/epoch - 915us/step\n",
      "Epoch 84/100\n",
      "16023/16023 - 14s - loss: -2.9248e+11 - accuracy: 0.0242 - val_loss: -2.9705e+11 - val_accuracy: 0.0233 - 14s/epoch - 869us/step\n",
      "Epoch 85/100\n",
      "16023/16023 - 15s - loss: -3.0301e+11 - accuracy: 0.0241 - val_loss: -3.0769e+11 - val_accuracy: 0.0233 - 15s/epoch - 907us/step\n",
      "Epoch 86/100\n",
      "16023/16023 - 14s - loss: -3.1383e+11 - accuracy: 0.0241 - val_loss: -3.1860e+11 - val_accuracy: 0.0233 - 14s/epoch - 870us/step\n",
      "Epoch 87/100\n",
      "16023/16023 - 15s - loss: -3.2487e+11 - accuracy: 0.0241 - val_loss: -3.2975e+11 - val_accuracy: 0.0234 - 15s/epoch - 927us/step\n",
      "Epoch 88/100\n",
      "16023/16023 - 14s - loss: -3.3618e+11 - accuracy: 0.0241 - val_loss: -3.4116e+11 - val_accuracy: 0.0233 - 14s/epoch - 880us/step\n",
      "Epoch 89/100\n",
      "16023/16023 - 15s - loss: -3.4773e+11 - accuracy: 0.0241 - val_loss: -3.5282e+11 - val_accuracy: 0.0233 - 15s/epoch - 908us/step\n",
      "Epoch 90/100\n",
      "16023/16023 - 14s - loss: -3.5957e+11 - accuracy: 0.0242 - val_loss: -3.6476e+11 - val_accuracy: 0.0233 - 14s/epoch - 871us/step\n",
      "Epoch 91/100\n",
      "16023/16023 - 14s - loss: -3.7171e+11 - accuracy: 0.0242 - val_loss: -3.7700e+11 - val_accuracy: 0.0233 - 14s/epoch - 903us/step\n",
      "Epoch 92/100\n",
      "16023/16023 - 14s - loss: -3.8407e+11 - accuracy: 0.0241 - val_loss: -3.8947e+11 - val_accuracy: 0.0233 - 14s/epoch - 899us/step\n",
      "Epoch 93/100\n",
      "16023/16023 - 14s - loss: -3.9672e+11 - accuracy: 0.0241 - val_loss: -4.0223e+11 - val_accuracy: 0.0233 - 14s/epoch - 876us/step\n",
      "Epoch 94/100\n",
      "16023/16023 - 14s - loss: -4.0962e+11 - accuracy: 0.0241 - val_loss: -4.1521e+11 - val_accuracy: 0.0232 - 14s/epoch - 902us/step\n",
      "Epoch 95/100\n",
      "16023/16023 - 16s - loss: -4.2279e+11 - accuracy: 0.0241 - val_loss: -4.2851e+11 - val_accuracy: 0.0232 - 16s/epoch - 985us/step\n",
      "Epoch 96/100\n",
      "16023/16023 - 14s - loss: -4.3625e+11 - accuracy: 0.0241 - val_loss: -4.4208e+11 - val_accuracy: 0.0232 - 14s/epoch - 893us/step\n",
      "Epoch 97/100\n",
      "16023/16023 - 14s - loss: -4.4996e+11 - accuracy: 0.0241 - val_loss: -4.5590e+11 - val_accuracy: 0.0232 - 14s/epoch - 904us/step\n",
      "Epoch 98/100\n",
      "16023/16023 - 15s - loss: -4.6398e+11 - accuracy: 0.0241 - val_loss: -4.7004e+11 - val_accuracy: 0.0232 - 15s/epoch - 939us/step\n",
      "Epoch 99/100\n",
      "16023/16023 - 15s - loss: -4.7830e+11 - accuracy: 0.0240 - val_loss: -4.8449e+11 - val_accuracy: 0.0232 - 15s/epoch - 923us/step\n",
      "Epoch 100/100\n",
      "16023/16023 - 14s - loss: -4.9293e+11 - accuracy: 0.0241 - val_loss: -4.9923e+11 - val_accuracy: 0.0232 - 14s/epoch - 904us/step\n",
      "time taken for training :  1484.9691498279572\n",
      "time taken for per epoch :  14.849691498279572\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import time\n",
    " \n",
    "epochs = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_shape=(X_train.shape[1],), activation='relu')) # Add an input shape! (features,)\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "curr = time.time()\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_split=0.10, epochs=epochs, batch_size=64,verbose=2)\n",
    "\n",
    "timetaken = time.time()-curr\n",
    "print(\"time taken for training : \",timetaken)\n",
    "print(\"time taken for per epoch : \",timetaken/epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9e99ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: n2v_classficatio_1/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"n2v_classficatio_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5dc90dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_N2V_model_1.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bb49be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = []\n",
    "test_df = []\n",
    "for file_no in range(1,11,1):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
